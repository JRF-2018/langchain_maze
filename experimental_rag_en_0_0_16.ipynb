{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experimental RAG Implementation using MemoryBanditWorkflow (LangChain 1.x)\n",
        "\n",
        "(Version: 0.0.16.3)\n",
        "\n",
        "## Overview\n",
        "\n",
        "`MemoryBanditWorkflow` is an agent framework developed based on experiences with the Bear-Sword Maze problem. It has been updated to support LangChain 1.x and introduces `subtool_do`, a feature equivalent to modern concepts like \"skills\" or \"toolboxes.\"\n",
        "\n",
        "Although it originated as part of a maze-solving project, I aimed to design it as a versatile framework. This project represents an attempt to build a RAG (Retrieval-Augmented Generation) agent to demonstrate that the framework is indeed capable of general-purpose tasks.\n",
        "\n",
        "## The Idea of RagAgent\n",
        "\n",
        "For more details on the core concepts of `MemoryBanditWorkflow` and the \"Sub-tools\" idea, please refer to the following notebook (in English):\n",
        "\n",
        "《langchain_maze_en_0_0_15.ipynb - JRF-2018/langchain_maze》  \n",
        "https://github.com/JRF-2018/langchain_maze/blob/master/langchain_maze_en_0_0_15.ipynb\n",
        "\n",
        "In essence, `MemoryBanditWorkflow` provides integrated memory, bandit, and workflow functions. This project uses those features as-is to define a child class called `RagAgent`.\n",
        "\n",
        "Note that implementing a full semantic search backend was cumbersome for this experiment, so the backend logic is \"simulated\" by the AI—essentially having the LLM perform database spoofing.\n",
        "\n",
        "The original maze problem that served as the foundation for `MemoryBanditWorkflow` can be traced here (in Japanese):\n",
        "\n",
        "《JRF-2018/langchain_maze: Bear-Sword Maze Problem Revisited》  \n",
        "https://github.com/JRF-2018/langchain_maze\n",
        "\n",
        "While multi-agent systems are currently the trend for RAG architectures, this implementation runs strictly in a linear, single-threaded sequence. To truly implement a multi-agent approach, one would need to use `asyncio` or a formal vector database for memory. However, such extensions are beyond the current scope. The primary goal here is to demonstrate that RAG can be successfully implemented on top of `the MemoryBanditWorkflow` framework; hence, there is no claim of novelty regarding the RAG logic itself.\n",
        "\n",
        "## Links to Previous Versions (Japanese)\n",
        "\n",
        "《experimental_rag_0_0_2.ipynb - JRF-2018/langchain_maze》  \n",
        "https://github.com/JRF-2018/langchain_maze/blob/master/experimental_rag_0_0_2.ipynb\n",
        "\n",
        "《experimental_rag_0.0.16.2.ipynb - GitHub Gist》  \n",
        "https://gist.github.com/JRF-2018/f4f9565095611aea2ab1b24be6596145\n",
        "\n",
        "## Changes from Previous Versions\n",
        "\n",
        "  * **LangChain 1.x Support**: Addressed type errors originating from the specific implementation details of Pydantic v2 and Gemini. It is currently operational, but as these are stopgap measures, future stability is not guaranteed.\n",
        "\n",
        "  * **Sub-tools**: Introduced `subtool_do` and `subtool_show`, which allow the agent to store tools and use them only after reading their descriptions. What is displayed by `subtool_show` is roughly equivalent to a `SKILL.md` file in other agent frameworks.\n",
        "\n",
        "  * **0.0.16.2**: Fixed minor bugs found in 0.0.16.1.\n",
        "\n",
        "  * **0.0.16.3**: Full translation of the interface and documentation into English.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "### Findings from the initial experiment (v0.0.16.1):\n",
        "\n",
        "The system was tested with `gemini-2.5-flash-lite`, and the final execution was performed by `gemini-3-flash-preview`. During the process, I discovered an infinite loop caused by my own mistake; I stopped the execution, fixed the bug, and resumed. I have provided the logs from that resumed session to manage API costs.\n",
        "\n",
        "The execution of sub-tools proved difficult for the agent initially; it failed to complete the thesis using the `/thesis` sub-tools on the first attempt. However, after specifically \"nudging\" the agent to use the sub-tools, it was able to reach completion.\n",
        "\n",
        "Whether due to these factors or others, while the content was handled, I felt the structural quality was actually better in the previous version. Still, as a verification experiment for `MemoryBanditWorkflow` and sub-tools, I believe the results are acceptable.\n",
        "\n",
        "### Findings from v0.0.16.2:\n",
        "\n",
        "Perhaps because I explicitly instructed the agent in the prompt to utilize the `/thesis` sub-toolset, the process was much smoother, and the agent wrote the entire thesis in one go. My impression was that I would have liked the research phase to be a bit longer, but for a proof of concept, it works perfectly fine.\n",
        "\n",
        "### Findings from v0.0.16.3:\n",
        "\n",
        "The system appears to function correctly in English as well.\n",
        "\n",
        "Please note that due to the inherent lack of reproducibility in LLM outputs and to manage costs, I have not re-run the process from scratch for this documentation. (^^;\n",
        "\n",
        "## Author\n",
        "\n",
        "JRF ( http://jrf.cocolog-nifty.com/statuses , Twitter (X): @jion_rockford )\n",
        "\n",
        "## License\n",
        "\n",
        "Since the code is relatively short, I intended for my parts to be in the Public Domain. If you have concerns, please treat it under the MIT License.\n",
        "\n",
        "This was developed with significant guidance from various AIs (Gemini, ChatGPT, Claude, and Grok).\n"
      ],
      "metadata": {
        "id": "p8QNK04mhC1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation\n",
        "\n",
        "First, we will import the necessary libraries."
      ],
      "metadata": {
        "id": "8RKcr4bdFno6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain langchain-google-genai duckduckgo-search langchain-community beautifulsoup4 ddgs\n"
      ],
      "metadata": {
        "id": "pq5sY-oF7N3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d80a2aa-c705-4cc4-b0c2-603c284ea866"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.1/500.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing Gemini. If you import your Gemini API key from Google AI Studio into your environment secrets, a secret named GOOGLE_API_KEY should be created. We will use that."
      ],
      "metadata": {
        "id": "wnYGb0gNwZgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from google.colab import userdata\n",
        "\n",
        "#os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "llm = init_chat_model(\n",
        "    \"google_genai:gemini-3-flash-preview\",\n",
        "    google_api_key=userdata.get('GOOGLE_API_KEY'),\n",
        "#    thinking_level=\"low\", # for gemini-3.0\n",
        "#    thinking_budget=0, # for gemini-2.5\n",
        ")\n",
        "emb_llm = GoogleGenerativeAIEmbeddings(\n",
        "    model='gemini-embedding-001',\n",
        "    google_api_key=userdata.get('GOOGLE_API_KEY'),\n",
        ")\n"
      ],
      "metadata": {
        "id": "QY6crr6eTzZh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing whether we can access Gemini properly."
      ],
      "metadata": {
        "id": "TRFFiT3_q0iA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Helper function to extract text content (Required for compatibility with Gemini 3)\n",
        "def get_content_text(content):\n",
        "    if isinstance(content, list):\n",
        "        texts = []\n",
        "        for item in content:\n",
        "            if isinstance(item, dict):\n",
        "                if item.get('type') == 'text':\n",
        "                    texts.append(item.get('text', ''))\n",
        "            elif isinstance(item, str):\n",
        "                texts.append(item)\n",
        "        return \"\".join(texts)\n",
        "    return content\n",
        "\n",
        "response = llm.invoke([HumanMessage(content=\"Please tell me the features of the Gemini model.\")])\n",
        "print(get_content_text(response.content))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItiWcNrW6uin",
        "outputId": "39f1f8e9-fffa-4c5b-ee65-b5a4ea91a1e8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google’s Gemini is a family of multimodal large language models developed by Google DeepMind. It was built from the ground up to be \"natively multimodal,\" meaning it can understand and operate across text, code, audio, image, and video.\n",
            "\n",
            "Here are the key features of the Gemini model:\n",
            "\n",
            "### 1. Native Multimodality\n",
            "Unlike older models that were trained on text and then \"bolted on\" to image or audio encoders, Gemini was trained on multiple formats simultaneously from the start.\n",
            "*   **Deep Understanding:** It can seamlessly reason across different types of input. For example, you can show it a video of a physics experiment and ask it to explain the concepts or predict what happens next.\n",
            "*   **Cross-Modal Reasoning:** It can \"see\" an image and write code to recreate it, or listen to an audio file and summarize it in text.\n",
            "\n",
            "### 2. Massive Context Window\n",
            "One of Gemini’s most significant competitive advantages (specifically in the 1.5 Pro and Flash versions) is its massive context window.\n",
            "*   **Capacity:** It supports up to **1 million to 2 million tokens**.\n",
            "*   **What this means:** You can upload an entire hour of video, 11 hours of audio, codebases with over 30,000 lines, or documents over 700,000 words in a single prompt. It can then find specific information or \"reason\" across that entire dataset.\n",
            "\n",
            "### 3. Model Tiers (Sizes for Every Use)\n",
            "Gemini is offered in several versions optimized for different tasks:\n",
            "*   **Gemini Ultra:** The largest and most capable model, designed for highly complex tasks (reasoning, coding, and nuance).\n",
            "*   **Gemini Pro:** A versatile, mid-sized model optimized to scale across a wide range of tasks. It powers the standard Gemini chatbot.\n",
            "*   **Gemini Flash:** A newer, lightweight model designed for speed and efficiency at a lower cost, while maintaining high intelligence.\n",
            "*   **Gemini Nano:** An efficient model designed to run **on-device** (e.g., on Pixel 8/9 or Samsung S24). This allows for privacy and offline use without needing a cloud connection.\n",
            "\n",
            "### 4. Advanced Reasoning and Coding\n",
            "*   **Complex Problem Solving:** Gemini excels at math and logic. It performs at a high level on benchmarks like MMLU (Massive Multitask Language Understanding).\n",
            "*   **AlphaCode 2:** Gemini uses a specialized version of its engine for competitive programming. It is highly proficient in languages like Python, Java, C++, and Go.\n",
            "*   **Scientific Discovery:** It can filter through thousands of pages of research papers to extract data and find correlations that humans might miss.\n",
            "\n",
            "### 5. Integration with Google Ecosystem\n",
            "Gemini is deeply integrated into Google’s existing products:\n",
            "*   **Extensions:** It can pull real-time information from your **Gmail, Google Drive, Maps, and YouTube**. For example, you can ask, \"Find the flight details from my email and add them to my calendar.\"\n",
            "*   **Android Integration:** On mobile, Gemini is replacing Google Assistant as a more capable, conversational AI that can interact with the apps on your screen.\n",
            "\n",
            "### 6. High Efficiency and Speed\n",
            "With the introduction of **Gemini 1.5**, Google moved to a \"Mixture-of-Experts\" (MoE) architecture. \n",
            "*   Instead of activating the entire neural network for every prompt, it only activates the most relevant \"expert\" pathways.\n",
            "*   This makes the model significantly faster and more efficient than previous versions.\n",
            "\n",
            "### 7. Safety and Ethics\n",
            "Google emphasizes \"Red Teaming\" (testing for vulnerabilities) and safety filters.\n",
            "*   The models are built with protections against generating hate speech, sexually explicit content, and dangerous instructions.\n",
            "*   It includes a **\"Double Check\"** feature in the Gemini app that uses Google Search to verify whether the AI’s response is supported or contradicted by web sources.\n",
            "\n",
            "### Summary Comparison: Gemini vs. Others\n",
            "While models like GPT-4 are excellent at reasoning, **Gemini’s \"killer feature\" is its 2-million-token context window and its deep integration with Google’s data apps.** This makes it particularly powerful for researchers, developers, and power users who work with massive amounts of information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also test the embedding vectors."
      ],
      "metadata": {
        "id": "kQVRXx5u6BvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb_llm.embed_query(\"This is a test.\")[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7VL19OI7StU",
        "outputId": "1216418f-07a5-4341-b076-6d38765286cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.019542728, 0.0036680987, 0.0044811117, -0.069937535, 0.0015621887]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing basic modules."
      ],
      "metadata": {
        "id": "pmz5ixRRGx8C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zmonotIShAgD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "from pprint import pprint\n",
        "from time import sleep\n",
        "import pickle\n",
        "np.set_printoptions(legacy='1.25')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the following code for save/load functionality."
      ],
      "metadata": {
        "id": "XPsfEZT8Peh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAG_AGENT_SAVE = \"rag-agent.pickle\""
      ],
      "metadata": {
        "id": "-vBMYCs4PMyk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with the required libraries."
      ],
      "metadata": {
        "id": "w_HJPnvAHcbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import ValidationError\n",
        "from typing import List, Dict, Any, Tuple, Union\n",
        "from textwrap import dedent\n",
        "import datetime\n",
        "import copy\n",
        "import inspect\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Import LangChain components\n",
        "from langchain_core.tools import tool, Tool\n",
        "from langchain.agents.middleware import SummarizationMiddleware\n",
        "from langchain.agents.middleware.summarization import DEFAULT_SUMMARY_PROMPT\n",
        "from langchain.agents import create_agent\n",
        "#from langgraph.prebuilt import create_react_agent\n",
        "#from langchain_core.messages.utils import count_tokens_approximately\n",
        "#from langgraph.prebuilt.chat_agent_executor import AgentState\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langchain_core.prompts.chat import ChatPromptTemplate\n",
        "#from langmem.short_term import SummarizationNode, summarize_messages\n",
        "from langchain_core.messages import AIMessage, ToolMessage, HumanMessage, SystemMessage\n",
        "from langgraph.errors import GraphRecursionError\n",
        "from langchain_community.tools import DuckDuckGoSearchResults\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "SUMMARY_PROMPT = DEFAULT_SUMMARY_PROMPT + \"\\n\\n**Please provide the summary in English.**\"\n"
      ],
      "metadata": {
        "id": "qpMuup8bnKUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a80a1da-ae6d-41f9-f5ca-7d20ab5c793b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_embedding_variance(embeddings):\n",
        "    if not embeddings or len(embeddings) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    embeddings_array = np.array(embeddings)\n",
        "    mean_vector = np.mean(embeddings_array, axis=0)\n",
        "    squared_distances = np.linalg.norm(embeddings_array - mean_vector, axis=1)**2\n",
        "    variance = np.mean(squared_distances)\n",
        "\n",
        "    return variance\n",
        "\n",
        "def short_repr(x, max_len=80):\n",
        "    repr_str = repr(x)\n",
        "\n",
        "    if len(repr_str) > max_len:\n",
        "        ellipsis_len = 3\n",
        "\n",
        "        head_len = max_len - ellipsis_len - 1\n",
        "        tail_len = 1\n",
        "        return repr_str[:head_len] + \"...\" + repr_str[-tail_len:]\n",
        "    else:\n",
        "        return repr_str\n",
        "\n",
        "def get_content_text(content):\n",
        "    if isinstance(content, list):\n",
        "        texts = []\n",
        "        for item in content:\n",
        "            if isinstance(item, dict):\n",
        "                if item.get('type') == 'text':\n",
        "                    texts.append(item.get('text', ''))\n",
        "            elif isinstance(item, str):\n",
        "                texts.append(item)\n",
        "        return \"\".join(texts)\n",
        "    return content\n"
      ],
      "metadata": {
        "id": "bHfsAXY978V8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`MemoryBanditWorkflow` has not changed from `langchain_maze_en_0.0.15.ipynb`. I apologize for the lengthy definition."
      ],
      "metadata": {
        "id": "RoJlmsaIg2bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MemoryBanditWorkflow:\n",
        "    \"\"\"\n",
        "    MemoryBanditWorkflow: A generic framework for decision-making tasks\n",
        "    integrating memory management and strategic planning.\n",
        "    \"\"\"\n",
        "    def __init__ (self, llm=llm, llm2=llm, emb_llm=emb_llm,\n",
        "                  save_file=None):\n",
        "        self.llm = llm\n",
        "        self.llm2 = llm2\n",
        "        self.emb_llm = emb_llm\n",
        "        self.save_file = save_file\n",
        "\n",
        "        self.core_context = \"\"\n",
        "        self.plan = \"Plan and policy have not been set yet.\"\n",
        "        self.scratchpad = \"\"\n",
        "\n",
        "        self.messages = []\n",
        "        self.running_summary = None\n",
        "        self.system_prompt = \"\"\"\\\n",
        "This is an experiment to observe the behavior of memory and bandit functions.\n",
        "Consider the current plan, policy, and surrounding circumstances, and update the plan and policy as necessary.\n",
        "Leave a plan and policy that makes it easy for another agent to take the next action.\n",
        "As befits an experiment, use tools as much as possible—specifically search memory and update documents to prepare for future commands.\n",
        "\n",
        "Memory IDs follow the format 'memory:...'. Specifying only the number (e.g., '5555') instead of 'memory:5555' is insufficient. When referencing memory in text, write it as [memory:...].\n",
        "The 'procedure for searching memory documents' is located in [memory:9998].\n",
        "The 'procedure for storing documents in memory' is located in [memory:9997].\n",
        "\n",
        "Many tools are stored as sub-tools. Sub-tool names start with '/', such as '/dir1/subtool1'. To see available sub-tools, first run subtool_show(\"/\").\n",
        "\"\"\"\n",
        "\n",
        "        self.backend_status = None\n",
        "        self.backend_result = None\n",
        "        self.messages2 = []\n",
        "        self.system_prompt2 = \"\"\"\\\n",
        "You are a backend agent supporting the main agent.\n",
        "While this backend is intended to be implemented using various advanced techniques, it is currently in a testing phase, so you must simulate its behavior.\n",
        "\n",
        "Think carefully, use tools proactively, and follow the instructions from the Human.\n",
        "\"\"\"\n",
        "\n",
        "        self.memories = {}\n",
        "        self.keywords = []\n",
        "\n",
        "        self.tools = {}\n",
        "        self.tool_tag = \"null_tools\"\n",
        "\n",
        "        self.access_unit = 1.0\n",
        "        self.recent_reads = []\n",
        "\n",
        "        self.workflows = {}\n",
        "        self.workflow_current = \"workflow:main\"\n",
        "        self.workflow_next = None\n",
        "        self.privileged_tool_names = []\n",
        "\n",
        "        self.init_memories()\n",
        "        self.init_workflows()\n",
        "        self.init_tools()\n",
        "\n",
        "\n",
        "    def __getstate__ (self):\n",
        "        state = self.__dict__.copy()\n",
        "        del state['llm']\n",
        "        del state['llm2']\n",
        "        del state['emb_llm']\n",
        "        del state['tools']\n",
        "        #del state['agent']\n",
        "        return state\n",
        "\n",
        "    def __setstate__ (self, state):\n",
        "        self.__dict__.update(state)\n",
        "        self.prev_load = True\n",
        "\n",
        "    def save (self):\n",
        "        if not self.save_file:\n",
        "            return\n",
        "        with open(self.save_file, 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "\n",
        "    @classmethod\n",
        "    def load (cls, filename, llm=llm, llm2=llm, emb_llm=emb_llm):\n",
        "        with open(filename, 'rb') as f:\n",
        "            loaded_game = pickle.load(f)\n",
        "        loaded_game.llm = llm\n",
        "        loaded_game.llm2 = llm2\n",
        "        loaded_game.emb_llm = emb_llm\n",
        "        loaded_game.tools = {}\n",
        "        loaded_game.init_tools()\n",
        "        return loaded_game\n",
        "\n",
        "    def normalize_memory_id(self, id_or_num):\n",
        "        if isinstance(id_or_num, int):\n",
        "            return f\"memory:{id_or_num}\"\n",
        "        elif isinstance(id_or_num, str):\n",
        "            m = re.search(r'\\[?memory:(\\d+)\\]?', id_or_num)\n",
        "            if m:\n",
        "                return f\"memory:{m.group(1)}\"\n",
        "            if id_or_num.isdigit():\n",
        "                return f\"memory:{id_or_num}\"\n",
        "            else:\n",
        "                return id_or_num\n",
        "        else:\n",
        "            return id_or_num\n",
        "\n",
        "    def _normalize_workflow_id_sub(self, id_or_num):\n",
        "        if isinstance(id_or_num, int):\n",
        "            return f\"workflow:{id_or_num}\"\n",
        "        if id_or_num in [\"current\", \"main\"]:\n",
        "            return f\"workflow:{id_or_num}\"\n",
        "        elif isinstance(id_or_num, str):\n",
        "            m = re.search(r'\\[?workflow:(\\d+|main|current)\\]?(?:.+)?', id_or_num.strip())\n",
        "            if m:\n",
        "                return f\"workflow:{m.group(1)}\"\n",
        "            if id_or_num.isdigit():\n",
        "                return f\"workflow:{id_or_num}\"\n",
        "            else:\n",
        "                return id_or_num\n",
        "        else:\n",
        "            return id_or_num\n",
        "\n",
        "    def normalize_workflow_id(self, id_or_num):\n",
        "        r = self._normalize_workflow_id_sub(id_or_num)\n",
        "        if r == \"workflow:current\":\n",
        "            return self.workflow_current\n",
        "        return r\n",
        "\n",
        "    def register_tool (self, tool, tags=None):\n",
        "        if not tags:\n",
        "            tags = [\"default_tools\", \"all_tools\"]\n",
        "        self.tools[tool.name] = {\n",
        "            'name': tool.name,\n",
        "            'tags': tags,\n",
        "            'tool': tool\n",
        "        }\n",
        "\n",
        "    def change_tool_tags (self, tool, tags=None):\n",
        "        if not tags:\n",
        "            tags = [\"default_tools\", \"all_tools\"]\n",
        "        name = tool if isinstance(tool, str) else tool.name\n",
        "        self.tools[name]['tags'] = tags\n",
        "\n",
        "    def register_subtools (self, directory, subtools,\n",
        "                           description=None, content=None,\n",
        "                           tags=None):\n",
        "        \"\"\"Registers a group of sub-tools under a specific directory path.\"\"\"\n",
        "        if not tags:\n",
        "            tags = [\"default_tools\", \"all_tools\"]\n",
        "        assert directory.startswith(\"/\")\n",
        "        if directory not in self.tools:\n",
        "            self.tools[directory] = {\n",
        "                'name': directory,\n",
        "            }\n",
        "        if description:\n",
        "            self.tools[directory]['description'] = description\n",
        "        if content:\n",
        "            self.tools[directory]['content'] = content\n",
        "\n",
        "        # Both content and description are required for initial setup\n",
        "        assert 'description' in self.tools[directory]\n",
        "        assert 'content' in self.tools[directory]\n",
        "\n",
        "        for name, tool in subtools:\n",
        "            assert name.startswith(directory + \"/\")\n",
        "            self.tools[name] = {\n",
        "                'name': name,\n",
        "                'tags': tags,\n",
        "                'tool': tool,\n",
        "            }\n",
        "\n",
        "    def _create_tool_manual(self, tool_obj):\n",
        "        \"\"\"Generates a manual entry for a standard tool.\"\"\"\n",
        "        tool_name = tool_obj.name\n",
        "        tool_description = getattr(tool_obj, \"description\", \"No description available.\")\n",
        "\n",
        "        arg_names = []\n",
        "        if hasattr(tool_obj, \"args_schema\") and tool_obj.args_schema:\n",
        "            if hasattr(tool_obj.args_schema, \"model_fields\"):\n",
        "                arg_names = list(tool_obj.args_schema.model_fields.keys())\n",
        "            else:\n",
        "                arg_names = list(tool_obj.args_schema.__fields__.keys())\n",
        "        else:\n",
        "            # Fallback for simple functions or older LangChain tools\n",
        "            func = getattr(tool_obj, \"func\", tool_obj)\n",
        "            sig = inspect.signature(func)\n",
        "            arg_names = [p for p in sig.parameters.keys() if p != 'self']\n",
        "\n",
        "        args_str = \", \".join(arg_names)\n",
        "\n",
        "        manual = f\"\"\"\\\n",
        "[Tool Name] {tool_name}\n",
        "[Usage] {tool_name}({args_str})\n",
        "[Description] {tool_description}\n",
        "\"\"\"\n",
        "        return manual\n",
        "\n",
        "    def _create_subtool_manual(self, subtool_name, tool_obj):\n",
        "        \"\"\"Generates a manual entry for a sub-tool intended for use with subtool_do.\"\"\"\n",
        "        tool_name = tool_obj.name\n",
        "        tool_description = getattr(tool_obj, \"description\", \"No description available.\")\n",
        "\n",
        "        arg_names = []\n",
        "        if hasattr(tool_obj, \"args_schema\") and tool_obj.args_schema:\n",
        "            # Check for Pydantic v2 or v1 style access\n",
        "            if hasattr(tool_obj.args_schema, \"model_fields\"):\n",
        "                arg_names = list(tool_obj.args_schema.model_fields.keys())\n",
        "            else:\n",
        "                arg_names = list(tool_obj.args_schema.__fields__.keys())\n",
        "        else:\n",
        "            func = getattr(tool_obj, \"func\", tool_obj)\n",
        "            sig = inspect.signature(func)\n",
        "            arg_names = [p for p in sig.parameters.keys() if p != 'self']\n",
        "\n",
        "        args_str = \", \".join(arg_names)\n",
        "        args_dict_str = \", \".join([f'\"{name}\": ...' for name in arg_names])\n",
        "\n",
        "        manual = f\"\"\"\\\n",
        "[Sub-tool Name] {subtool_name}\n",
        "[Original Tool Name] {tool_name}\n",
        "[Original Usage] {tool_name}({args_str})\n",
        "[Description] {tool_description}\n",
        "\n",
        "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
        "[Correct Usage] subtool_do(\"{subtool_name}\", {{{args_dict_str}}})\n",
        "\"\"\"\n",
        "        return manual\n",
        "\n",
        "    def create_tool_skill(self, name):\n",
        "        \"\"\"Generates Markdown content describing the available tools or sub-skills.\"\"\"\n",
        "        if name == \"/\":\n",
        "            r = dedent(\"\"\"\\\n",
        "            ---\n",
        "            name: /\n",
        "            description: Sub-tool Root. Explains how to explore available sub-tools.\n",
        "            allowed-tools: No special permission is required to use sub-tools.\n",
        "            ---\n",
        "\n",
        "            Sub-tools are organized into directories called \"Sub-skills.\"\n",
        "\n",
        "            To view the sub-tools within a specific sub-skill, execute the tool `subtool_show(\"/path\")` (e.g., `subtool_show(\"/sys\")`). You will find detailed documentation similar to a SKILL.md file there.\n",
        "\n",
        "            ## Available Sub-skills\n",
        "\n",
        "            \"\"\")\n",
        "            for dir_name in self.tools:\n",
        "                if \"description\" in self.tools[dir_name]:\n",
        "                    e = self.tools[dir_name]\n",
        "                    r += f\"-  **{e['name']}**: {e['description']}\\n\"\n",
        "            return r\n",
        "\n",
        "        name = name.rstrip(\"/\")\n",
        "        if name not in self.tools:\n",
        "            return None\n",
        "\n",
        "        e = self.tools[name]\n",
        "\n",
        "        # If this is a specific tool entry\n",
        "        if \"tool\" in e:\n",
        "            if \"content\" in e:\n",
        "                r = dedent(f\"\"\"\\\n",
        "                ---\n",
        "                name: {e['name']}\n",
        "                description: {e['description']}\n",
        "                allowed-tools: No special permission is required to use this sub-tool.\n",
        "                ---\n",
        "                \"\"\")\n",
        "                r += e['content']\n",
        "                return r\n",
        "\n",
        "            if e['name'].startswith(\"/\"):\n",
        "                manual = self._create_subtool_manual(e['name'], e['tool'])\n",
        "            else:\n",
        "                manual = self._create_tool_manual(e['tool'])\n",
        "\n",
        "            status_suffix = \"Available [in the current context].\\n\" if self.tool_tag in e['tags'] else \"Not available [in the current context].\\n\"\n",
        "            manual += status_suffix\n",
        "\n",
        "            r = dedent(f\"\"\"\\\n",
        "            ---\n",
        "            name: {e['name']}\n",
        "            description: {e['tool'].name}\n",
        "            allowed-tools: No special permission is required to use this sub-tool.\n",
        "            ---\n",
        "            \"\"\")\n",
        "            r += manual\n",
        "            return r\n",
        "\n",
        "        # If this is a directory/sub-skill entry\n",
        "        r = dedent(f\"\"\"\\\n",
        "        ---\n",
        "        name: {e['name']}\n",
        "        description: {e['description']}\n",
        "        allowed-tools: No special permission is required to use this sub-skill.\n",
        "        ---\n",
        "        \"\"\")\n",
        "        r += e['content']\n",
        "\n",
        "        dirs = [d_name for d_name, x in self.tools.items()\n",
        "                if d_name.startswith(e['name'] + \"/\")\n",
        "                and 'description' in x]\n",
        "        subtools = [st_name for st_name, x in self.tools.items()\n",
        "                    if st_name.startswith(e['name'] + \"/\")\n",
        "                    and 'description' not in x]\n",
        "\n",
        "        if dirs:\n",
        "            r += \"\\n## Sub-skills\\n\\n\"\n",
        "            for d_name in dirs:\n",
        "                x = self.tools[d_name]\n",
        "                r += f\"-  **{x['name']}**: {x['description']}\\n\"\n",
        "\n",
        "        if subtools:\n",
        "            r += \"\\n## Sub-tools\\n\\n\"\n",
        "            for subtool_name in subtools:\n",
        "                x = self.tools[subtool_name]\n",
        "                manual = self._create_subtool_manual(x['name'], x['tool'])\n",
        "                r += dedent(f\"\"\"\\\n",
        "\n",
        "                ### Sub-tool: {x['name']}\n",
        "\n",
        "                \"\"\")\n",
        "                r += manual\n",
        "\n",
        "        return r\n",
        "\n",
        "    def _replace_tools (self, from_tools, to_tools):\n",
        "        tool_names = [x.name for x in to_tools]\n",
        "        return [x for x in from_tools\n",
        "                if x.name not in tool_names] + to_tools\n",
        "\n",
        "    def init_tools (self):\n",
        "        @tool\n",
        "        def express_thought(thought: str) -> None:\n",
        "            \"\"\"Expresses the player's current thoughts or reasoning.\"\"\"\n",
        "            mes = f\"Thought expressed: \\\"{thought}\\\"\"\n",
        "            print(f\"Tool(express_thought): {mes}\")\n",
        "\n",
        "        @tool\n",
        "        def show_plan() -> str:\n",
        "            \"\"\"Returns the player's current plan and policy.\"\"\"\n",
        "            print(f\"Tool(show_plan): {self.plan}\")\n",
        "            return self.plan\n",
        "\n",
        "        @tool\n",
        "        def update_plan(new_plan: str) -> str:\n",
        "            \"\"\"\n",
        "            Updates the player's current plan and policy.\n",
        "            Provide the new plan/policy string to be displayed.\n",
        "            Structure it so that another agent can easily follow the strategy.\n",
        "            \"\"\"\n",
        "            self.plan = new_plan\n",
        "            mes = \"Plan and policy updated.\"\n",
        "            print(f\"Tool(update_plan): {mes}: {new_plan}\")\n",
        "            return mes\n",
        "\n",
        "        @tool\n",
        "        def show_core() -> str:\n",
        "            \"\"\"Returns the current core context.\"\"\"\n",
        "            print(f\"Tool(show_core): {self.core_context}\")\n",
        "            return self.core_context\n",
        "\n",
        "        @tool\n",
        "        def update_core(new_core: str) -> str:\n",
        "            \"\"\"\n",
        "            Updates the core context.\n",
        "            The core context contains critical information (like required memory_read or subtool_show targets)\n",
        "            that should be remembered even after context truncation or summarization.\n",
        "            \"\"\"\n",
        "            self.core_context = new_core\n",
        "            mes = \"Core context updated.\"\n",
        "            print(f\"Tool(update_core): {mes}: {new_core}\")\n",
        "            return mes\n",
        "\n",
        "        @tool\n",
        "        def show_scratchpad() -> str:\n",
        "            \"\"\"Returns the current content of the scratchpad.\"\"\"\n",
        "            print(f\"Tool(show_scratchpad): {self.scratchpad}\")\n",
        "            return self.scratchpad\n",
        "\n",
        "        @tool\n",
        "        def update_scratchpad(new_scratchpad: str) -> str:\n",
        "            \"\"\"Updates the freely usable scratchpad.\"\"\"\n",
        "            self.scratchpad = new_scratchpad\n",
        "            mes = \"Scratchpad updated.\"\n",
        "            print(f\"Tool(update_scratchpad): {mes}: {new_scratchpad}\")\n",
        "            return mes\n",
        "\n",
        "        @tool\n",
        "        def memory_new(title: str, text: str) -> str:\n",
        "            \"\"\"\n",
        "            Creates a new memory entry with the specified title and text.\n",
        "            Returns the assigned memory_id.\n",
        "            \"\"\"\n",
        "            i = 1000\n",
        "            while True:\n",
        "                if f\"memory:{i}\" not in self.memories:\n",
        "                    break\n",
        "                i += 1\n",
        "            new_id = f\"memory:{i}\"\n",
        "            self.memories[new_id] = {\n",
        "                'id': new_id,\n",
        "                'title': title,\n",
        "                'accesses': 0,\n",
        "                'text': text,\n",
        "                'modified_at': datetime.datetime.now().isoformat()\n",
        "            }\n",
        "            self.update_keywords(text)\n",
        "            self.update_vector(self.memories[new_id])\n",
        "            print(f\"Tool(memory_new): {short_repr(self.memories[new_id])}\")\n",
        "            return new_id\n",
        "\n",
        "        @tool\n",
        "        def memory_update_string(memory_id: str, from_str: str, to_str: str) -> str:\n",
        "            \"\"\"\n",
        "            Corrects or replaces a string within a specific memory entry.\n",
        "            Args:\n",
        "                memory_id: The ID of the memory to modify.\n",
        "                from_str: The substring to be replaced.\n",
        "                to_str: The new substring to insert.\n",
        "            \"\"\"\n",
        "            memory_id = self.normalize_memory_id(memory_id)\n",
        "            if memory_id not in self.memories:\n",
        "                return f\"Error: Memory ID '{memory_id}' not found.\"\n",
        "            if memory_id.startswith(\"memory:9\"):\n",
        "                return f\"Error: Modification of [{memory_id}] is prohibited.\"\n",
        "\n",
        "            original_title = self.memories[memory_id]['title']\n",
        "            original_text = self.memories[memory_id]['text']\n",
        "\n",
        "            if from_str not in original_text and from_str not in original_title:\n",
        "                return f\"Error: Original string '{from_str}' not found in memory.\"\n",
        "\n",
        "            updated_title = original_title.replace(from_str, to_str)\n",
        "            updated_text = original_text.replace(from_str, to_str)\n",
        "\n",
        "            self.memories[memory_id]['title'] = updated_title\n",
        "            self.memories[memory_id]['text'] = updated_text\n",
        "            self.memories[memory_id]['modified_at'] = datetime.datetime.now().isoformat()\n",
        "            self.update_keywords(updated_text)\n",
        "            self.update_vector(self.memories[memory_id])\n",
        "\n",
        "            return f\"Success: Updated memory ID '{memory_id}' by replacing '{from_str}' with '{to_str}'.\"\n",
        "\n",
        "        @tool\n",
        "        def memory_append_string(memory_id: str, string_to_append: str, separator: str = '\\n') -> str:\n",
        "            \"\"\"Appends a string to the specified memory entry.\"\"\"\n",
        "            memory_id = self.normalize_memory_id(memory_id)\n",
        "            if memory_id not in self.memories:\n",
        "                return f\"Error: Memory ID '{memory_id}' not found.\"\n",
        "            if memory_id.startswith(\"memory:9\"):\n",
        "                return f\"Error: Modification of [{memory_id}] is prohibited.\"\n",
        "\n",
        "            original_text = self.memories[memory_id]['text']\n",
        "            updated_text = original_text + separator + string_to_append\n",
        "            self.memories[memory_id]['text'] = updated_text\n",
        "            self.memories[memory_id]['modified_at'] = datetime.datetime.now().isoformat()\n",
        "            self.update_keywords(updated_text)\n",
        "            self.update_vector(self.memories[memory_id])\n",
        "\n",
        "            return f\"Success: Appended text to memory ID '{memory_id}'.\"\n",
        "\n",
        "        @tool\n",
        "        def memory_delete(memory_id: str) -> str:\n",
        "            \"\"\"Deletes the specified memory entry.\"\"\"\n",
        "            memory_id = self.normalize_memory_id(memory_id)\n",
        "            if memory_id not in self.memories:\n",
        "                return f\"Error: Memory ID '{memory_id}' not found.\"\n",
        "            if memory_id.startswith(\"memory:9\"):\n",
        "                return f\"Error: Deletion of [{memory_id}] is prohibited.\"\n",
        "\n",
        "            del self.memories[memory_id]\n",
        "            return f\"Success: Deleted memory ID '{memory_id}'.\"\n",
        "\n",
        "        @tool\n",
        "        def memory_read(memory_id: str) -> Union[Dict[str, str], str]:\n",
        "            \"\"\"Reads the contents of the memory for the given ID.\"\"\"\n",
        "            memory_id = self.normalize_memory_id(memory_id)\n",
        "            if memory_id in self.memories:\n",
        "                self.memories[memory_id]['accesses'] += self.access_unit * 1.0\n",
        "                self.recent_reads.append(self.memories[memory_id])\n",
        "                self.recent_reads = self.recent_reads[-10:]\n",
        "                r = self.memories[memory_id].copy()\n",
        "                if 'vector' in r: del r['vector']\n",
        "                return r\n",
        "            else:\n",
        "                return f\"Error: Memory ID '{memory_id}' not found.\"\n",
        "\n",
        "        @tool\n",
        "        def memory_read(memory_id: str) -> Union[Dict[str, str], str]:\n",
        "            \"\"\"\n",
        "            Reads the memory content associated with the specified ID.\n",
        "\n",
        "            Args:\n",
        "                memory_id (str): The ID of the memory to read (e.g., 'memory:1001').\n",
        "\n",
        "            Returns:\n",
        "                Union[Dict[str, str], str]: A dictionary containing memory details if successful.\n",
        "                                     If the memory ID is not found, returns an error message string.\n",
        "            \"\"\"\n",
        "            memory_id = self.normalize_memory_id(memory_id)\n",
        "            if memory_id in self.memories:\n",
        "                self.memories[memory_id]['accesses'] += self.access_unit * 1.0\n",
        "                self.recent_reads.append(self.memories[memory_id])\n",
        "                self.recent_reads = self.recent_reads[-10:]\n",
        "                r = self.memories[memory_id].copy()\n",
        "                if 'vector' in r: del r['vector']\n",
        "                return r\n",
        "            else:\n",
        "                return f\"Error: Memory ID '{memory_id}' not found.\"\n",
        "\n",
        "        @tool\n",
        "        def memory_list_recent(top_n: int = 10) -> Dict[str, Any]:\n",
        "            \"\"\"Lists recently modified memories, sorted by time descending.\"\"\"\n",
        "            filter_date = datetime.datetime(2025, 1, 1)\n",
        "            sorted_memories = sorted(\n",
        "                [m for m in self.memories.values()\n",
        "                 if datetime.datetime.fromisoformat(m['modified_at']) >= filter_date],\n",
        "                key=lambda x: datetime.datetime.fromisoformat(x['modified_at']),\n",
        "                reverse=True\n",
        "            )\n",
        "            if sorted_memories:\n",
        "                result = [{'id': x['id'], 'title': x['title'], 'modified_at': x['modified_at']}\n",
        "                          for x in sorted_memories[:top_n]]\n",
        "                return {'status': 'success', 'result': result}\n",
        "            else:\n",
        "                return {'status': 'error', 'result': 'Error: No recent memories found.'}\n",
        "\n",
        "        @tool\n",
        "        def memory_list_random(top_n: int = 10) -> Dict[str, Any]:\n",
        "            \"\"\"Lists memories in random order.\"\"\"\n",
        "            keys = list(self.memories.keys())\n",
        "            if len(keys) > top_n:\n",
        "                keys = random.sample(keys, top_n)\n",
        "            if keys:\n",
        "                result = [{'id': self.memories[k]['id'], 'title': self.memories[k]['title'], 'modified_at': self.memories[k]['modified_at']}\n",
        "                          for k in keys]\n",
        "                return {'status': 'success', 'result': result}\n",
        "            else:\n",
        "                return {'status': 'error', 'result': 'Error: No memories found.'}\n",
        "\n",
        "        @tool\n",
        "        def memory_words_search(search_str: str) -> Dict[str, Any]:\n",
        "            \"\"\"Searches memories using string matching (supports OR and grouping).\"\"\"\n",
        "            res = self.call_backend_agent(dedent(f\"\"\"\\\n",
        "            Simulate a full-text search across all memories with search_str = {repr(search_str)}.\n",
        "            Support OR and parentheses logic.\n",
        "            Use actual memory data obtained from 'read_all_memories' or 'read_all_keywords'.\n",
        "            Return results using the 'set_result' tool.\n",
        "\n",
        "            Status: 'error' or 'success'\n",
        "            Result: List of Match data (m) dictionaries:\n",
        "              m['id']: Memory ID (memory:...)\n",
        "              m['title']: Memory Title\n",
        "              m['snippet']: Contextual snippet of text surrounding the match.\n",
        "            \"\"\"))\n",
        "            if res['status'] == 'success':\n",
        "                for m in res['result']:\n",
        "                    if 'id' in m and m['id'] in self.memories:\n",
        "                        self.memories[m['id']]['accesses'] += self.access_unit * 0.1\n",
        "            return res\n",
        "\n",
        "\n",
        "        @tool\n",
        "        def memory_semantic_search(search_str: str) -> Dict[str, Any]:\n",
        "            \"\"\"Performs a semantic search within the memory based on the search string.\"\"\"\n",
        "            res = self.call_backend_agent(dedent(f\"\"\"\\\n",
        "            Simulate a semantic search across all memories for search_str = {repr(search_str)}.\n",
        "            Use actual memory data from available tools.\n",
        "            Return results using the 'set_result' tool.\n",
        "\n",
        "            Status: 'error' or 'success'\n",
        "            Result: List of Match data (m) dictionaries:\n",
        "              m['id']: Memory ID (memory:...)\n",
        "              m['title']: Memory Title\n",
        "              m['snippet']: Snippet showing why this memory is semantically relevant.\n",
        "            \"\"\"))\n",
        "            if res['status'] == 'success':\n",
        "                for m in res['result']:\n",
        "                    if 'id' in m and m['id'] in self.memories:\n",
        "                        self.memories[m['id']]['accesses'] += self.access_unit * 0.1\n",
        "            return res\n",
        "\n",
        "\n",
        "        @tool\n",
        "        def imagine_keywords(thought: str) -> List[Tuple[str, float]]:\n",
        "            \"\"\"Associates thoughts with multiple keywords and relevant scores.\"\"\"\n",
        "            r = self.call_backend_agent(dedent(f\"\"\"\\\n",
        "            Generate multiple associated keywords with scores based on thought = {repr(thought)}.\n",
        "            Use actual keywords existing in the system.\n",
        "            Return results using 'set_result'.\n",
        "\n",
        "            Status: 'error' or 'success'\n",
        "            Result: List of keyword tuples (string, score).\n",
        "            \"\"\"))\n",
        "            return r[\"result\"] if r['status'] == 'success' else []\n",
        "\n",
        "        @tool\n",
        "        def bandit_schedule(tool_name: str, times: int, prob: float, exec_mode: str = \"persistent\", aux_prompt: str = \"\", workflow_id: str = \"workflow:current\") -> str:\n",
        "            \"\"\"\n",
        "            Schedules a 'bandit' to enforce the use of specific tools.\n",
        "            Args:\n",
        "                tool_name: Name(s) of the tool(s) to enforce. Can use \" OR \" for multiple tools.\n",
        "                times: Number of times to add this entry. Set to 0 to remove.\n",
        "                prob: Probability of execution per turn.\n",
        "                exec_mode: \"once\" or \"persistent\".\n",
        "                aux_prompt: Additional instructions for execution.\n",
        "                workflow_id: The target workflow.\n",
        "            \"\"\"\n",
        "            tool_names = re.split(r\"\\s+or\\s+|\\s+OR\\s+\", tool_name)\n",
        "            prohibited = set(self.privileged_tool_names) & set(tool_names)\n",
        "            if prohibited:\n",
        "                return f\"Failure. {repr(prohibited)} cannot be registered.\"\n",
        "            all_tools = [name for name, x in self.tools.items()\n",
        "                         if \"tool\" in x]\n",
        "            if not any (x in all_tools for x in tool_names):\n",
        "                return f\"Failure. {tool_name} is not a valid tool.\"\n",
        "\n",
        "            workflow_id = self.normalize_workflow_id(workflow_id)\n",
        "            if workflow_id not in self.workflows:\n",
        "                return f\"Failure. {workflow_id} is not a valid workflow.\"\n",
        "            if 'w' in self.workflows[workflow_id]['pin']:\n",
        "                return f\"Failure. {workflow_id} is read-only.\"\n",
        "\n",
        "            dest = None\n",
        "            for i, x in enumerate(self.workflows[workflow_id]['stack']):\n",
        "                if x['tool_name'] == tool_name \\\n",
        "                   and x['exec_mode'] == exec_mode \\\n",
        "                   and x['aux_prompt'] == aux_prompt \\\n",
        "                   and x['arg'] is None:\n",
        "                    dest = i\n",
        "                    break\n",
        "            if dest is not None:\n",
        "                x = self.workflows[workflow_id]['stack'][dest]\n",
        "                if not x['pin']:\n",
        "                    self.workflows[workflow_id]['stack'].pop(dest)\n",
        "                    if times == 0 or prob == 0.0:\n",
        "                        return \"Success. Bandit removed.\"\n",
        "                    self.workflows[workflow_id]['stack'].append(x)\n",
        "            else:\n",
        "                if times == 0 or prob == 0.0:\n",
        "                    return \"Failure. No such bandit found. To specify a bandit, you must match all of the following: tool_name, exec_mode, and aux_prompt.\"\n",
        "                x = {\n",
        "                    'pin': 'stack' if exec_mode != \"once\" else None,\n",
        "                    'arg': None\n",
        "                }\n",
        "                self.workflows[workflow_id]['stack'].append(x)\n",
        "            if x['pin'] == \"write\":\n",
        "                return f\"Failure. '{tool_name}' is protected.\"\n",
        "            else:\n",
        "                x['tool_name'] = tool_name\n",
        "                x['tools_name'] = 'default_tools'\n",
        "                x['exec_mode'] = exec_mode\n",
        "                x['aux_prompt'] = aux_prompt\n",
        "                x['prob'] = prob\n",
        "                x['times'] = times\n",
        "                print(f\"Tool(bandit_schedule): {repr(x)}\")\n",
        "                if dest is None:\n",
        "                    return \"Success. Bandit registered.\"\n",
        "                else:\n",
        "                    return \"Success. Bandit updated.\"\n",
        "\n",
        "        @tool\n",
        "        def bandit_schedule_memory_read(memory_id: str, times: int, prob: float, exec_mode: str = \"persistent\", workflow_id: str = \"workflow:current\") -> str:\n",
        "            \"\"\"\n",
        "            Specialized bandit for enforcing memory_read on a specific memory_id.\n",
        "\n",
        "            Args:\n",
        "                memory_id: Memory ID to memory_read.\n",
        "                times: Number of times to add this entry. Set to 0 to remove.\n",
        "                prob: Probability of execution per turn.\n",
        "                exec_mode: \"once\" or \"persistent\".\n",
        "                aux_prompt: Additional instructions for execution.\n",
        "                workflow_id: The target workflow.\n",
        "            \"\"\"\n",
        "\n",
        "            workflow_id = self.normalize_workflow_id(workflow_id)\n",
        "            if workflow_id not in self.workflows:\n",
        "                return f\"Failure. {workflow_id} is not a valid workflow.\"\n",
        "            if 'w' in self.workflows[workflow_id]['pin']:\n",
        "                return f\"Failure. {workflow_id} is read-only.\"\n",
        "\n",
        "            memory_id = self.normalize_memory_id(memory_id)\n",
        "\n",
        "            dest = None\n",
        "            for i, x in enumerate(self.workflows[workflow_id]['stack']):\n",
        "                if x['tool_name'] == \"memory_read\" \\\n",
        "                   and x['exec_mode'] == exec_mode \\\n",
        "                   and not x['aux_prompt'] \\\n",
        "                   and x['arg'] == memory_id:\n",
        "                    dest = i\n",
        "                    break\n",
        "            if dest is not None:\n",
        "                x = self.workflows[workflow_id]['stack'][dest]\n",
        "                if not x['pin']:\n",
        "                    self.workflows[workflow_id]['stack'].pop(dest)\n",
        "                    if times == 0 or prob == 0.0:\n",
        "                        return \"Success. Bandit removed.\"\n",
        "                    self.workflows[workflow_id]['stack'].append(x)\n",
        "            else:\n",
        "                if times == 0 or prob == 0.0:\n",
        "                    return \"Failure. No such bandit found. To specify a bandit, you must match all of the following: exec_mode and memory_id.\"\n",
        "                x = {'pin': None, 'arg': memory_id}\n",
        "                self.workflows[workflow_id]['stack'].append(x)\n",
        "            if x['pin'] == \"write\":\n",
        "                return f\"Failure. 'memory_read {memory_id}' is protected.\"\n",
        "            else:\n",
        "                x['tool_name'] = 'memory_read'\n",
        "                x['tools_name'] = 'read_tools'\n",
        "                x['exec_mode'] = exec_mode\n",
        "                x['aux_prompt'] = \"\"\n",
        "                x['prob'] = prob\n",
        "                x['times'] = times\n",
        "                print(f\"Tool(bandit_schedule_memory_read): {repr(x)}\")\n",
        "                if dest is None:\n",
        "                    return \"Success. Bandit registered.\"\n",
        "                else:\n",
        "                    return \"Success. Bandit updated.\"\n",
        "\n",
        "        @tool\n",
        "        def bandit_schedule_subtool_show(subtool_name: str, times: int, prob: float, exec_mode: str = \"persistent\", workflow_id: str = \"workflow:current\") -> str:\n",
        "            \"\"\"\n",
        "            Schedules a bandit to enforce subtool_show for a specific tool path.\n",
        "\n",
        "            Args:\n",
        "                subtool_name: Sub-tool Name to subtool_show.\n",
        "                times: Number of times to add this entry. Set to 0 to remove.\n",
        "                prob: Probability of execution per turn.\n",
        "                exec_mode: \"once\" or \"persistent\".\n",
        "                aux_prompt: Additional instructions for execution.\n",
        "                workflow_id: The target workflow.\n",
        "            \"\"\"\n",
        "\n",
        "            workflow_id = self.normalize_workflow_id(workflow_id)\n",
        "            if workflow_id not in self.workflows:\n",
        "                return f\"Failure. {workflow_id} is not a valid workflow.\"\n",
        "            if 'w' in self.workflows[workflow_id]['pin']:\n",
        "                return f\"Failure. {workflow_id} is read-only.\"\n",
        "\n",
        "            if subtool_name not in self.tools:\n",
        "                return f\"Failure. {subtool_name} is not a valid name.\"\n",
        "\n",
        "            dest = None\n",
        "            for i, x in enumerate(self.workflows[workflow_id]['stack']):\n",
        "                if x['tool_name'] == \"subtool_show\" \\\n",
        "                   and x['exec_mode'] == exec_mode \\\n",
        "                   and not x['aux_prompt'] \\\n",
        "                   and x['arg'] == subtool_name:\n",
        "                    dest = i\n",
        "                    break\n",
        "            if dest is not None:\n",
        "                x = self.workflows[workflow_id]['stack'][dest]\n",
        "                if not x['pin']:\n",
        "                    self.workflows[workflow_id]['stack'].pop(dest)\n",
        "                    if times == 0 or prob == 0.0:\n",
        "                        return \"Success. Bandit removed.\"\n",
        "                    self.workflows[workflow_id]['stack'].append(x)\n",
        "            else:\n",
        "                if times == 0 or prob == 0.0:\n",
        "                    return \"Failure. No such bandit found. To specify a bandit, you must match all of the following: exec_mode and subtool_name.\"\n",
        "                x = {'pin': None, 'arg': subtool_name}\n",
        "                self.workflows[workflow_id]['stack'].append(x)\n",
        "            if x['pin'] == \"write\":\n",
        "                return f\"Failure. 'subtool_show {subtool_name}' is protected.\"\n",
        "            else:\n",
        "                x['tool_name'] = 'subtool_show'\n",
        "                x['tools_name'] = 'read_tools'\n",
        "                x['exec_mode'] = exec_mode\n",
        "                x['aux_prompt'] = \"\"\n",
        "                x['prob'] = prob\n",
        "                x['times'] = times\n",
        "                print(f\"Tool(bandit_schedule_subtool_show): {repr(x)}\")\n",
        "                if dest is None:\n",
        "                    return \"Success. Bandit registered.\"\n",
        "                else:\n",
        "                    return \"Success. Bandit updated.\"\n",
        "\n",
        "        @tool\n",
        "        def bandit_schedule_workflow(workflow_id_to_schedule: str, times: int, prob: float, exec_mode: str = \"persistent\", workflow_id: str = \"workflow:current\") -> str:\n",
        "            \"\"\"\n",
        "            Schedules a bandit to enforce the execution of another workflow.\n",
        "\n",
        "            Args:\n",
        "                workflow_id_to_schedule: Workflow ID to workflow_do.\n",
        "                times: Number of times to add this entry. Set to 0 to remove.\n",
        "                prob: Probability of execution per turn.\n",
        "                exec_mode: \"once\" or \"persistent\".\n",
        "                aux_prompt: Additional instructions for execution.\n",
        "                workflow_id: The target workflow to register.\n",
        "            \"\"\"\n",
        "\n",
        "            workflow_id = self.normalize_workflow_id(workflow_id)\n",
        "            if workflow_id not in self.workflows:\n",
        "                return f\"Failure. {workflow_id} is not a valid workflow.\"\n",
        "            if 'w' in self.workflows[workflow_id]['pin']:\n",
        "                return f\"Failure. {workflow_id} is read-only.\"\n",
        "\n",
        "            workflow_id2 = self.normalize_workflow_id(workflow_id_to_schedule)\n",
        "            if workflow_id2 not in self.workflows:\n",
        "                return f\"Failure. {workflow_id2} is not a valid workflow.\"\n",
        "\n",
        "            dest = None\n",
        "            for i, x in enumerate(self.workflows[workflow_id]['stack']):\n",
        "                if x['tool_name'] == \"workflow_do\" \\\n",
        "                   and x['exec_mode'] == exec_mode \\\n",
        "                   and not x['aux_prompt'] \\\n",
        "                   and x['arg'] == workflow_id2:\n",
        "                    dest = i\n",
        "                    break\n",
        "            if dest is not None:\n",
        "                x = self.workflows[workflow_id]['stack'][dest]\n",
        "                if not x['pin']:\n",
        "                    self.workflows[workflow_id]['stack'].pop(dest)\n",
        "                    if times == 0 or prob == 0.0:\n",
        "                        return \"Success. Bandit removed.\"\n",
        "                    self.workflows[workflow_id]['stack'].append(x)\n",
        "            else:\n",
        "                if times == 0 or prob == 0.0:\n",
        "                    return \"Failure. No such bandit found. To specify a bandit, you must match all of the following: exec_mode and workflow_id_to_schedule.\"\n",
        "                x = {\n",
        "                    'pin': 'stack' if exec_mode != \"once\" else None,\n",
        "                    'arg': workflow_id2\n",
        "                }\n",
        "                self.workflows[workflow_id]['stack'].append(x)\n",
        "            if x['pin'] == \"write\":\n",
        "                return f\"Failure. 'workflow_do {workflow_id2}' is protected.\"\n",
        "            else:\n",
        "                x['tool_name'] = 'workflow_do'\n",
        "                x['tools_name'] = 'default_tools'\n",
        "                x['exec_mode'] = exec_mode\n",
        "                x['aux_prompt'] = \"\"\n",
        "                x['prob'] = prob\n",
        "                x['times'] = times\n",
        "                print(f\"Tool(bandit_schedule_workflow): {repr(x)}\")\n",
        "                if dest is None:\n",
        "                    return \"Success. Bandit registered.\"\n",
        "                else:\n",
        "                    return \"Success. Bandit updated.\"\n",
        "\n",
        "        @tool\n",
        "        def bandit_list(workflow_id: str =  \"workflow:current\")  -> Dict[str, Any]:\n",
        "            \"\"\"Returns the current stack of registered bandits for a workflow.\"\"\"\n",
        "\n",
        "            workflow_id = self.normalize_workflow_id(workflow_id)\n",
        "            if workflow_id not in self.workflows:\n",
        "                return f\"Failure. {workflow_id} is not valid.\"\n",
        "            return {'status': 'success',\n",
        "                    'result': self.workflows[workflow_id]['stack']}\n",
        "\n",
        "        @tool\n",
        "        def bandit_statistics()  -> str:\n",
        "            \"\"\"Returns statistical data useful for tuning bandit probabilities.\"\"\"\n",
        "\n",
        "            s_read = calc_embedding_variance([\n",
        "                x['vector'] for x in self.recent_reads\n",
        "            ])\n",
        "            s_write = calc_embedding_variance([\n",
        "                x['vector'] for x in self.memories.values()\n",
        "            ])\n",
        "            accesses = [x['accesses'] for x in self.memories.values()]\n",
        "            accesses.sort()\n",
        "            accesses = accesses[:len(accesses) // 2]\n",
        "            if accesses:\n",
        "                s_access = np.mean(accesses)\n",
        "            else:\n",
        "                s_access = 0.0\n",
        "\n",
        "            return dedent(f\"\"\"\\\n",
        "            Variance of last 10 memory reads: {s_read}\n",
        "            Total memory variance: {s_write}\n",
        "            Average access count of bottom 50% memories: {s_access}\n",
        "            \"\"\")\n",
        "\n",
        "        @tool\n",
        "        def subwork_done()  -> str:\n",
        "            \"\"\"Declares that the assigned sub-task has been completed.\"\"\"\n",
        "            return \"Success. Sub-task completion declared.\"\n",
        "\n",
        "        @tool\n",
        "        def workflow_do(workflow_id: str) -> str:\n",
        "            \"\"\"Executes a specific workflow.\"\"\"\n",
        "            if self.workflow_next:\n",
        "                return f\"Failure. {self.workflow_next} is already scheduled.\"\n",
        "            workflow_id = self.normalize_workflow_id(workflow_id)\n",
        "            if workflow_id not in self.workflows:\n",
        "                return f\"Failure. {workflow_id} is not valid.\"\n",
        "            if 'e' in self.workflows[workflow_id]['pin']:\n",
        "                return f\"Failure. {workflow_id} cannot be run as a child.\"\n",
        "            self.workflow_next = workflow_id\n",
        "            title = self.workflows[workflow_id]['title']\n",
        "            return f\"Success. {workflow_id} ('{title}') will execute next.\"\n",
        "\n",
        "        @tool\n",
        "        def workflow_list() -> Dict[str, Any]:\n",
        "            \"\"\"Lists all registered workflows including IDs, titles, and pin status.\"\"\"\n",
        "            return {'status': 'success', 'result': list(self.workflows.values())}\n",
        "\n",
        "        @tool\n",
        "        def workflow_show_current() -> str:\n",
        "            \"\"\"Displays information about the currently active workflow and active bandit enforcement.\"\"\"\n",
        "            w = self.workflows[self.workflow_current]\n",
        "            mes = dedent(f\"\"\"\\\n",
        "            Current Workflow: {self.workflow_current} ('{w['title']}')\n",
        "            Current Bandit Prompt: \\\"{self.cur_bandit_prompt}\\\"\n",
        "            Current Bandit Config: {repr(self.cur_bandit)}\n",
        "            Bandit Execution Count: {self.cur_bandit_done}\n",
        "            \"\"\")\n",
        "            print(f\"Tool(workflow_show_current): {mes}\")\n",
        "            return mes\n",
        "\n",
        "        @tool\n",
        "        def workflow_new(title: str, bandits: List[Dict[str, Any]], pin: str) -> str:\n",
        "            \"\"\"\n",
        "            Defines a new workflow and returns its workflow_id.\n",
        "            Args:\n",
        "                title: Name of the workflow.\n",
        "                bandits: List of bandit dictionaries (tool_name, exec_mode, prob, etc.).\n",
        "                pin: Security flags: 'w' (read-only), 'd' (non-deletable), 'wd' (read-only & non-deletable) or '' (writable & deletable).\n",
        "            \"\"\"\n",
        "            for b in bandits:\n",
        "                if not all(k in b for k in ['tool_name', 'exec_mode', 'aux_prompt', 'times', 'prob']):\n",
        "                    return \"Failure. Invalid bandit definition.\"\n",
        "                b.setdefault('arg', None)\n",
        "                b['tools_name'] = \"read_tools\" if (b.get('arg') and b['tool_name'] == \"memory_read\") else \"default_tools\"\n",
        "                b.setdefault('pin', None)\n",
        "\n",
        "            i = 1000\n",
        "            while f\"workflow:{i}\" in self.workflows: i += 1\n",
        "            new_id = f\"workflow:{i}\"\n",
        "            self.workflows[new_id] = {'stack': bandits, 'pin': pin, 'title': title, 'id': new_id}\n",
        "            print(f\"Tool(workflow_new): {repr(self.workflows[new_id])}\")\n",
        "            return f\"Success. Registered new workflow {new_id}.\"\n",
        "\n",
        "\n",
        "        @tool\n",
        "        def workflow_new(title: str, bandits: List[Dict[str, Any]], pin: str)  -> str:\n",
        "            \"\"\"\n",
        "            Defines a new workflow and returns its workflow_id.\n",
        "\n",
        "            Args:\n",
        "                title: The name of the workflow.\n",
        "                bandits: A list of bandits to register.\n",
        "                pin: Security flags: 'w' for read-only (unwritable), 'd' for undeletable, 'wd' for both, '' for writable and deletable.\n",
        "\n",
        "            Each bandit is represented as a dictionary `b`:\n",
        "            - `b['tool_name']`: Same as tool_name in bandit_schedule.\n",
        "            - `b['exec_mode']`: Same as exec_mode in bandit_schedule.\n",
        "            - `b['aux_prompt']`: Same as aux_prompt in bandit_schedule.\n",
        "            - `b['prob']`: Same as prob in bandit_schedule.\n",
        "            - `b['times']`: Same as times in bandit_schedule.\n",
        "            - `b['arg']`: If `b['tool_name']` is 'memory_read', specify a memory_id (memory:...). If 'workflow_do', specify a workflow_id (workflow:...).\n",
        "            - `b['pin']`: If None, deletable or prob/times can be updated. If 'stack', prob/times can be updated. If 'write', cannot be updated at all.\n",
        "            \"\"\"\n",
        "            # Hidden attribute for AI: pin 'e' makes it non-executable as a child.\n",
        "            for b in bandits:\n",
        "                if not all(x in b for x in ['tool_name', 'exec_mode',\n",
        "                                            'aux_prompt', 'times', 'prob']):\n",
        "                    return \"Failure. Invalid bandit definition.\"\n",
        "                if 'arg' not in b:\n",
        "                    b['arg'] = None\n",
        "                if b['tool_name'] not in [\"memory_read\", \"workflow_do\"] \\\n",
        "                   and b['arg']:\n",
        "                    return \"Failure. Invalid bandit definition.\"\n",
        "                if b['arg'] and b['tool_name'] == \"memory_read\":\n",
        "                    b['tools_name'] = \"read_tools\"\n",
        "                else:\n",
        "                    b['tools_name'] = \"default_tools\"\n",
        "                if 'pin' not in b:\n",
        "                    b['pin'] = None\n",
        "                if not (b['pin'] is None or b['pin'] == 'stack'\n",
        "                        or b['pin'] == 'write'):\n",
        "                    return \"Failure. Invalid pin value.\"\n",
        "                tool_names = re.split(r\"\\s+or\\s+|\\s+OR\\s+\", b['tool_name'])\n",
        "                prohibited = set(self.privileged_tool_names) & set(tool_names)\n",
        "                if prohibited:\n",
        "                    return f\"Failure. {repr(prohibited)} cannot be registered.\"\n",
        "                all_tools = [name for name, x in self.tools.items()\n",
        "                                 if \"tool\" in x and b['tools_name'] in x.tags]\n",
        "                if not any (x in all_tools for x in tool_names):\n",
        "                    return f\"Failure {b['tool_name']} is not a valid tool specification.\"\n",
        "\n",
        "            i = 1000\n",
        "            while True:\n",
        "\n",
        "                if f\"workflow:{i}\" not in self.workflows:\n",
        "                    break\n",
        "                i = i + 1\n",
        "            new_id = f\"workflow:{i}\"\n",
        "\n",
        "            self.workflows[new_id] = {'stack': bandits, 'pin': pin,\n",
        "                                      'title': title}\n",
        "            print(f\"Tool(workflow_new): {repr(self.workflows[new_id])}\")\n",
        "            return f\"Success. Registered new workflow {new_id}.\"\n",
        "\n",
        "        @tool\n",
        "        def workflow_delete(workflow_id: str)  -> str:\n",
        "            \"\"\"Deletes a workflow.\"\"\"\n",
        "            workflow_id = self.normalize_workflow_id(workflow_id)\n",
        "            if workflow_id not in self.workflows:\n",
        "                return \"Failure. Workflow not found.\"\n",
        "            if 'd' in self.workflows[workflow_id]['pin']:\n",
        "                return \"Failure. Workflow is protected from deletion.\"\n",
        "            del self.workflows[workflow_id]\n",
        "            return f\"Success. Deleted {workflow_id}.\"\n",
        "\n",
        "        @tool\n",
        "        def subtool_show(subtool_name: str)  -> str:\n",
        "            \"\"\"Returns documentation/skill details for a sub-tool or directory path.\"\"\"\n",
        "            r = self.create_tool_skill(subtool_name)\n",
        "            if r:\n",
        "                return r\n",
        "            else:\n",
        "                return f\"Error: {subtool_name} not found or documentation unavailable.\"\n",
        "\n",
        "        @tool\n",
        "        def subtool_do(subtool_name: str, args_dict: Dict[str, Any])  -> Any:\n",
        "            \"\"\"\n",
        "            Executes the specified sub-tool.\n",
        "\n",
        "            For example, if an original tool named 't1' is registered as '/sys/tool1'\n",
        "            and is defined as 'def t1(arg1, arg2)', you can call 't1(\"a\", \"b\")'\n",
        "            by using 'subtool_do(\"/sys/tool1\", {\"arg1\": \"a\", \"arg2\": \"b\"})'.\n",
        "\n",
        "            Args:\n",
        "                subtool_name (str): The name of the sub-tool starting with '/'.\n",
        "                args_dict (dict): A dictionary representing the arguments.\n",
        "            \"\"\"\n",
        "            if subtool_name not in self.tools:\n",
        "                return f\"Error: Sub-tool '{subtool_name}' not found.\"\n",
        "            if 'tool' not in self.tools[subtool_name]:\n",
        "                return f\"Error: '{subtool_name}' is not an executable tool. Perhaps you need to call 'subtool_show(\\\"{subtool_name}\\\")' first.\"\n",
        "            if self.tool_tag not in self.tools[subtool_name]['tags']:\n",
        "                return f\"Error: '{subtool_name}' is not currently available for execution. Available tools vary depending on the context.\"\n",
        "\n",
        "            target_tool = self.tools[subtool_name]['tool']\n",
        "\n",
        "            try:\n",
        "                # Validate arguments if a schema is available\n",
        "                if hasattr(target_tool, \"args_schema\") and target_tool.args_schema:\n",
        "                    target_tool.args_schema.model_validate(args_dict)\n",
        "\n",
        "                # Execute the tool using invoke or run\n",
        "                if hasattr(target_tool, \"invoke\"):\n",
        "                    result = target_tool.invoke(args_dict)\n",
        "                else:\n",
        "                    result = target_tool.run(args_dict)\n",
        "\n",
        "                return result\n",
        "            except ValidationError as e:\n",
        "                error_details = e.errors()\n",
        "                return f\"Error: Invalid argument format.\\nDetails: {error_details}\"\n",
        "\n",
        "        # --- Tool Registration ---\n",
        "        main_tools = [\n",
        "            express_thought,\n",
        "            update_scratchpad, show_scratchpad,\n",
        "            memory_read, memory_list_recent, memory_list_random,\n",
        "            memory_semantic_search, memory_words_search,\n",
        "            imagine_keywords,\n",
        "            subwork_done,\n",
        "            workflow_do,\n",
        "            subtool_show, subtool_do,\n",
        "        ]\n",
        "        sys_tools = [\n",
        "            update_core, show_core,\n",
        "            update_plan, show_plan,\n",
        "            bandit_schedule, bandit_schedule_memory_read, bandit_list,\n",
        "            bandit_statistics,\n",
        "            workflow_new, workflow_list,\n",
        "            workflow_show_current, workflow_delete,\n",
        "            bandit_schedule_workflow,\n",
        "            bandit_schedule_subtool_show,\n",
        "        ]\n",
        "        write_tools = [\n",
        "            memory_new, memory_update_string, memory_append_string,\n",
        "            memory_delete,\n",
        "        ]\n",
        "\n",
        "        for t in main_tools + write_tools:\n",
        "            self.register_tool(t, tags=[\"default_tools\", \"read_tools\",\n",
        "                                        \"all_tools\"])\n",
        "        for t in write_tools:\n",
        "            self.change_tool_tags(t, tags=[\"default_tools\", \"all_tools\"])\n",
        "        sys_subtools = [(f\"/sys/{t.name}\", t) for t in sys_tools]\n",
        "        self.register_subtools(\n",
        "            directory=\"/sys\",\n",
        "            subtools=sys_subtools,\n",
        "            description=\"Essential system sub-tools.\",\n",
        "            content=dedent(\"\"\"\\\n",
        "            A collection of foundational sub-tools for system management,\n",
        "            workflow orchestration, and bandit scheduling.\n",
        "            \"\"\"),\n",
        "            tags=[\"default_tools\", \"read_tools\", \"all_tools\"]\n",
        "        )\n",
        "\n",
        "\n",
        "    def _create_agent (self, tools_name='default_tools'):\n",
        "        self.tool_tag = tools_name\n",
        "        tools = []\n",
        "        for name in self.tools:\n",
        "            if not name.startswith(\"/\"):\n",
        "                x = self.tools[name]\n",
        "                if self.tool_tag in x[\"tags\"]:\n",
        "                    tools.append(x[\"tool\"])\n",
        "\n",
        "        summarizer = SummarizationMiddleware(\n",
        "            model=self.llm,\n",
        "            trigger=(\"tokens\", 5000),\n",
        "            keep=(\"messages\", 20),\n",
        "            summary_prompt=SUMMARY_PROMPT,\n",
        "        )\n",
        "\n",
        "        app = create_agent(\n",
        "            model=self.llm, tools=tools, system_prompt=self.system_prompt,\n",
        "            middleware=[summarizer],\n",
        "            checkpointer=InMemorySaver(), name=\"main-agent\",\n",
        "        )\n",
        "\n",
        "        return app\n",
        "\n",
        "    def _filterout_messages2(self):\n",
        "        self.messages = [\n",
        "            x for x in self.messages\n",
        "            if x.id not in self.messages2ids\n",
        "        ]\n",
        "\n",
        "    def _sanitize_messages(self):\n",
        "        \"\"\"Workaround to sanitize message history and prevent unusual errors.\"\"\"\n",
        "        print(\"Sanitizing messages as a workaround for unexpected errors.\")\n",
        "        self.messages = [\n",
        "            m for m in self.messages\n",
        "            if not (isinstance(m, AIMessage) and m.tool_calls)\n",
        "        ]\n",
        "\n",
        "    def run (self, workflow_main_id):\n",
        "        print(\"\\n\\n----------\\n\\n\")\n",
        "        self.messages2ids = []\n",
        "\n",
        "        self.workflow_current = workflow_main_id\n",
        "        # Use deepcopy to avoid modifying the original workflow definition stack\n",
        "        bandits = copy.deepcopy(\n",
        "            self.workflows[self.workflow_current]['stack']\n",
        "        )\n",
        "        arg1s = {}\n",
        "        working_bandit = None\n",
        "        workflow_stack = []\n",
        "        execed = []\n",
        "        while True:\n",
        "            while working_bandit is not None or bandits:\n",
        "                if working_bandit is not None:\n",
        "                    b, done, prev_done = working_bandit\n",
        "                    working_bandit = None\n",
        "                else:\n",
        "                    b = bandits.pop()\n",
        "                    done = 0\n",
        "                    prev_done = True\n",
        "                enforce = b['tool_name']\n",
        "                aux_prompt = b['aux_prompt']\n",
        "                tools_name = b['tools_name']\n",
        "                memory_id = None\n",
        "                workflow_id = None\n",
        "                subtool_show_name = None\n",
        "                if b['arg'] and enforce == 'memory_read':\n",
        "                    memory_id = b['arg']\n",
        "                if b['arg'] and enforce == 'workflow_do':\n",
        "                    workflow_id = b['arg']\n",
        "                if b['arg'] and enforce == 'subtool_show':\n",
        "                    subtool_show_name = b['arg']\n",
        "\n",
        "                while done < b['times']:\n",
        "                    # Probability check for bandit execution\n",
        "                    if not random.random() < b['prob']:\n",
        "                        done += 1\n",
        "                        continue\n",
        "\n",
        "                    # Validation checks\n",
        "                    if memory_id and memory_id not in self.memories:\n",
        "                        done += 1\n",
        "                        continue\n",
        "                    if workflow_id and workflow_id not in self.workflows:\n",
        "                        done += 1\n",
        "                        continue\n",
        "                    all_tools = [name for name, x in self.tools.items()\n",
        "                                 if \"tool\" in x]\n",
        "                    tool_names = re.split(r\"\\s+or\\s+|\\s+OR\\s+\", enforce)\n",
        "                    if not any (x in all_tools for x in tool_names):\n",
        "                        done += 1\n",
        "                        continue\n",
        "\n",
        "                    # Construct instructions\n",
        "                    if memory_id:\n",
        "                        aux_prompt = f\"Please read {memory_id}.\"\n",
        "                    if workflow_id:\n",
        "                        aux_prompt = f\"Please execute {workflow_id}.\"\n",
        "                    if subtool_show_name:\n",
        "                        aux_prompt = f\"Please read the skill for {subtool_show_name}.\"\n",
        "\n",
        "                    self.cur_bandit = b\n",
        "                    self.cur_bandit_done = done\n",
        "\n",
        "                    or_suffix = ' (one of them)' if ' or ' in enforce.lower() else ''\n",
        "                    aux_suffix = f\" (Auxiliary Prompt): {aux_prompt}\" if aux_prompt else \"\"\n",
        "                    self.cur_bandit_prompt = (\n",
        "                        f\"While using various tools for assistance, eventually use {enforce}{or_suffix} \"\n",
        "                        f\"with appropriate parameters.{aux_suffix}\"\n",
        "                    )\n",
        "\n",
        "                    prompt = self.cur_bandit_prompt\n",
        "                    if not prev_done:\n",
        "                        prompt = \"The previous instruction has not been completed yet. Previous instruction: \" + prompt\n",
        "\n",
        "                    print(f\"USER_INPUT: {prompt}\")\n",
        "                    self.messages.append(HumanMessage(prompt))\n",
        "                    config = {\"configurable\": {\"thread_id\": \"1\"},\n",
        "                              \"recursion_limit\": 25}\n",
        "                    app = self._create_agent(tools_name=tools_name)\n",
        "                    self.access_unit = 0.3 if memory_id else 1.0\n",
        "                    prev_done = False\n",
        "                    self.workflow_next = None\n",
        "                    app_stream = None\n",
        "                    try:\n",
        "                        for chunk0 in app.stream(\n",
        "                                {\"messages\": self.messages.copy()},\n",
        "                                config=config,\n",
        "                                stream_mode=\"updates\",\n",
        "                        ):\n",
        "                            self.messages = app.get_state(config).values[\"messages\"].copy()\n",
        "                            if 'model' in chunk0:\n",
        "                                for chunk in chunk0['model']['messages']:\n",
        "                                    if hasattr(chunk, \"tool_calls\") \\\n",
        "                                       and chunk.tool_calls:\n",
        "                                        for tool_call in chunk.tool_calls:\n",
        "                                            t_id = tool_call.get('id')\n",
        "                                            args = tool_call.get('args', {})\n",
        "                                            if tool_call[\"name\"] == 'subtool_do':\n",
        "                                                arg1s[t_id] = args.get('subtool_name')\n",
        "                                            elif tool_call[\"name\"] == 'subtool_show':\n",
        "                                                arg1s[t_id] = args.get('subtool_name')\n",
        "                                            elif tool_call[\"name\"] == 'memory_read':\n",
        "                                                arg1s[t_id] = self.normalize_memory_id(args.get('memory_id'))\n",
        "                                            elif tool_call[\"name\"] == 'workflow_do':\n",
        "                                                arg1s[t_id] = self.normalize_workflow_id(args.get('workflow_id'))\n",
        "                            if 'tools' not in chunk0:\n",
        "                                continue\n",
        "                            done2 = 0\n",
        "                            for chunk in chunk0['tools']['messages']:\n",
        "                                if chunk.id in self.messages2ids:\n",
        "                                    print(\"!WHY!\")\n",
        "                                    continue\n",
        "                                if not isinstance(chunk, ToolMessage):\n",
        "                                    continue\n",
        "                                last_tool = chunk.name\n",
        "                                arg1 = None\n",
        "                                if last_tool == 'subtool_do':\n",
        "                                    last_tool = arg1s.get(chunk.tool_call_id, \"!UNKNOWN!\")\n",
        "                                    if not last_tool.startswith(\"/\"):\n",
        "                                         last_tool = chunk.name\n",
        "                                if last_tool in ['memory_read', 'subtool_show', 'workflow_do']:\n",
        "                                    arg1 = arg1s.get(chunk.tool_call_id, \"!UNKNOWN!\")\n",
        "                                print(f\"Tool result({last_tool}): {short_repr(chunk.content)}\", flush=True)\n",
        "\n",
        "                                if last_tool == \"workflow_do\":\n",
        "                                    if last_tool in re.split(r\"\\s+or\\s+|\\s+OR\\s+\", enforce) \\\n",
        "                                       and (not workflow_id or workflow_id == self.workflow_next):\n",
        "                                        done += 1\n",
        "                                        prev_done = True\n",
        "                                        execed.append(b)\n",
        "                                        if not self.workflow_next:\n",
        "                                            done2 = 1\n",
        "                                            break\n",
        "                                    if not self.workflow_next:\n",
        "                                        continue\n",
        "\n",
        "                                    # Enter sub-workflow\n",
        "                                    workflow_stack.append((\n",
        "                                        (b, done, prev_done),\n",
        "                                        bandits,\n",
        "                                        execed,\n",
        "                                        self.workflow_current\n",
        "                                    ))\n",
        "                                    self.workflow_current = self.workflow_next\n",
        "                                    bandits = copy.deepcopy(self.workflows[self.workflow_current]['stack'])\n",
        "                                    working_bandit = None\n",
        "                                    execed = []\n",
        "                                    done2 = 1\n",
        "                                    break\n",
        "                                elif last_tool in re.split(r\"\\s+or\\s+|\\s+OR\\s+\", enforce) \\\n",
        "                                   and (not memory_id or memory_id == arg1) \\\n",
        "                                   and (not subtool_show_name or subtool_show_name == arg1):\n",
        "                                    done += 1\n",
        "                                    prev_done = True\n",
        "                                    execed.append(b)\n",
        "                                    done2 = 1\n",
        "                                    break\n",
        "                            if done2:\n",
        "                                break\n",
        "                        self._filterout_messages2()\n",
        "                        #self._summarize_messages()\n",
        "                        print(f\"Agent response: {get_content_text(self.messages[-1].content)}\")\n",
        "                    except GraphRecursionError as e:\n",
        "                        print(f\"Recursion Limit reached.\")\n",
        "                        self._filterout_messages2()\n",
        "                        #self._summarize_messages()\n",
        "                    except Exception as e:\n",
        "                        print(f\"An error occurred (main): {e}\")\n",
        "                        import traceback\n",
        "                        traceback.print_exc()\n",
        "                        self._sanitize_messages()\n",
        "                        raise e\n",
        "\n",
        "            # Process removal of 'once' execution mode bandits\n",
        "            for b in execed:\n",
        "                for x in self.workflows[self.workflow_current]['stack']:\n",
        "                    if x['tool_name'] == b['tool_name'] \\\n",
        "                       and x['exec_mode'] == b['exec_mode'] \\\n",
        "                       and x['aux_prompt'] == b['aux_prompt'] \\\n",
        "                       and x['arg'] == b['arg'] \\\n",
        "                       and x['exec_mode'] == \"once\":\n",
        "                        if x['times'] > 0:\n",
        "                            x['times'] -= 1\n",
        "            self.workflows[self.workflow_current]['stack'] = [\n",
        "                x for x in self.workflows[self.workflow_current]['stack']\n",
        "                if x['exec_mode'] != 'once' or x['pin'] or x['times'] > 0\n",
        "            ]\n",
        "\n",
        "            if not workflow_stack:\n",
        "                break\n",
        "            workflow_prev = self.workflow_current\n",
        "            prev_title = self.workflows[workflow_prev]['title']\n",
        "            working_bandit, bandits, execed, self.workflow_current \\\n",
        "                = workflow_stack.pop()\n",
        "            cur_title = self.workflows[self.workflow_current]['title']\n",
        "            mes = f\"Returned from {workflow_prev} ('{prev_title}') to {self.workflow_current} ('{cur_title}').\"\n",
        "            print(f\"USER_INPUT: {mes}\")\n",
        "            self.messages.append(HumanMessage(mes))\n",
        "\n",
        "    def listen_and_print (self, prompt):\n",
        "        \"\"\"Listens for user input via a prompt and prints the agent's response.\"\"\"\n",
        "        ans = None\n",
        "        try:\n",
        "            app = self._create_agent(tools_name='null_tools')\n",
        "            config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "            print(f\"USER_INPUT: {prompt}\")\n",
        "            response = app.invoke(\n",
        "                {\"messages\": self.messages + [HumanMessage(prompt)]},\n",
        "                config=config\n",
        "            )\n",
        "            self.messages = response['messages']\n",
        "            #self._summarize_messages()\n",
        "            ans = get_content_text(response['messages'][-1].content)\n",
        "            print(f\"Agent response: {ans}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred (listen_and_print): {e}\")\n",
        "            raise e\n",
        "        print(\"\")\n",
        "        sleep(3)\n",
        "        return ans\n",
        "\n",
        "    def init_memories(self):\n",
        "        \"\"\"Initializes system memories with core instructions.\"\"\"\n",
        "        memories = [\n",
        "            {\n",
        "                'id': 'memory:9998',\n",
        "                'title': 'Procedure for searching memory documents',\n",
        "                'accesses': 0,\n",
        "                'modified_at': '2023-01-01T00:00:00',\n",
        "                'text': dedent(\"\"\"\\\n",
        "                First, use 'express_thought' to consider what kind of information you want to find.\n",
        "\n",
        "                Then, associate related keywords using 'imagine_keywords'.\n",
        "\n",
        "                Following those results, try 'memory_words_search' or 'memory_semantic_search'.\n",
        "                \"\"\")\n",
        "            },\n",
        "            {\n",
        "                'id': 'memory:9997',\n",
        "                'title': 'Procedure for storing documents in memory',\n",
        "                'accesses': 0,\n",
        "                'modified_at': '2023-01-01T00:00:00',\n",
        "                'text': dedent(\"\"\"\\\n",
        "                Actively record action results and acquired knowledge in memory.\n",
        "\n",
        "                When writing to memory, use the following elements:\n",
        "\n",
        "                [memory:...] : Explicitly reference a memory ID.\n",
        "                keyword:... : Specify keywords related to that memory.\n",
        "\n",
        "                Note that keywords can effectively serve as links to future memories.\n",
        "\n",
        "                Example:\n",
        "\n",
        "                While walking according to [memory:5555], I indeed encountered a yokai.\n",
        "\n",
        "                keyword: yokai\n",
        "\n",
        "                It was terrifying.\n",
        "                \"\"\")\n",
        "            },\n",
        "            {\n",
        "                'id': 'memory:9995',\n",
        "                'title': 'When tools won\\'t execute',\n",
        "                'accesses': 0,\n",
        "                'modified_at': '2023-01-01T00:00:00',\n",
        "                'text': dedent(\"\"\"\\\n",
        "                Tools unrelated to the instructions may sometimes fail to execute.\n",
        "                Always double-check the tools currently available in the context.\n",
        "                \"\"\")\n",
        "            },\n",
        "            {\n",
        "                'id': 'memory:9994',\n",
        "                'title': 'Keyword augmentation',\n",
        "                'accesses': 0,\n",
        "                'modified_at': '2023-01-01T00:00:00',\n",
        "                'text': dedent(\"\"\"\\\n",
        "                Use 'memory_list_random' to list 5 entries, read each one, and if you can assign appropriate keywords, append a 'keyword: ...' sentence to them using 'memory_append_string'.\n",
        "                \"\"\")\n",
        "            }\n",
        "        ]\n",
        "        for x in memories:\n",
        "            self.update_keywords(x['text'])\n",
        "            self.memories[x['id']] = x\n",
        "            self.update_vector(x)\n",
        "\n",
        "    def init_workflows(self):\n",
        "        \"\"\"Initializes default workflows and bandit stacks.\"\"\"\n",
        "        workflow_main = [\n",
        "            {\n",
        "                'tool_name': 'memory_new',\n",
        "                'tools_name': 'default_tools',\n",
        "                'exec_mode': 'persistent',\n",
        "                'aux_prompt': \"Please summarize and write down the recent interactions.\",\n",
        "                'arg': None,\n",
        "                'prob': 0.1,\n",
        "                'times': 1,\n",
        "                'pin': 'stack'\n",
        "            },\n",
        "            {\n",
        "                'tool_name': 'memory_new OR memory_update_string OR memory_append_string',\n",
        "                'tools_name': 'default_tools',\n",
        "                'exec_mode': 'persistent',\n",
        "                'aux_prompt': \"\",\n",
        "                'arg': None,\n",
        "                'prob': 0.4,\n",
        "                'times': 1,\n",
        "                'pin': 'stack'\n",
        "            },\n",
        "            {\n",
        "                'tool_name': 'workflow_do',\n",
        "                'tools_name': 'default_tools',\n",
        "                'exec_mode': 'persistent',\n",
        "                'aux_prompt': \"\",\n",
        "                'arg': \"workflow:1000\",\n",
        "                'prob': 1.0/20,\n",
        "                'times': 1,\n",
        "                'pin': 'stack'\n",
        "            },\n",
        "            {\n",
        "                'tool_name': 'memory_read',\n",
        "                'tools_name': 'default_tools',\n",
        "                'exec_mode': 'persistent',\n",
        "                'aux_prompt': \"\",\n",
        "                'arg': None,\n",
        "                'prob': 0.5,\n",
        "                'times': 3,\n",
        "                'pin': 'stack'\n",
        "            },\n",
        "            {\n",
        "                'tool_name': 'memory_read',\n",
        "                'tools_name': 'read_tools',\n",
        "                'exec_mode': 'persistent',\n",
        "                'aux_prompt': \"\",\n",
        "                'arg': 'memory:9998',\n",
        "                'prob': 0.1,\n",
        "                'times': 1,\n",
        "                'pin': None\n",
        "            },\n",
        "            {\n",
        "                'tool_name': 'memory_read',\n",
        "                'tools_name': 'read_tools',\n",
        "                'exec_mode': 'persistent',\n",
        "                'aux_prompt': \"\",\n",
        "                'arg': 'memory:9997',\n",
        "                'prob': 0.1,\n",
        "                'times': 1,\n",
        "                'pin': None\n",
        "            },\n",
        "        ]\n",
        "        self.workflows[\"workflow:main\"] = {\n",
        "            'pin': 'de',\n",
        "            'stack': workflow_main,\n",
        "            'title': \"Main\"\n",
        "        }\n",
        "\n",
        "        workflow_sub = [\n",
        "            {\n",
        "                'tool_name': 'subwork_done',\n",
        "                'tools_name': 'default_tools',\n",
        "                'exec_mode': 'persistent',\n",
        "                'aux_prompt': \"Read memory:9994, execute its instructions, and once the task is finished, call subwork_done.\",\n",
        "                'arg': None,\n",
        "                'prob': 1.0,\n",
        "                'times': 1,\n",
        "                'pin': 'write'\n",
        "            },\n",
        "            {\n",
        "                'tool_name': 'memory_read',\n",
        "                'tools_name': 'read_tools',\n",
        "                'exec_mode': 'persistent',\n",
        "                'aux_prompt': \"\",\n",
        "                'arg': 'memory:9994',\n",
        "                'prob': 1.0,\n",
        "                'times': 1,\n",
        "                'pin': 'write'\n",
        "            }\n",
        "        ]\n",
        "        self.workflows[\"workflow:1000\"] = {\n",
        "            'pin': 'wd',\n",
        "            'stack': workflow_sub,\n",
        "            'title': 'Keyword Update'\n",
        "        }\n",
        "\n",
        "    def update_keywords (self, text):\n",
        "        extracted_keywords = []\n",
        "\n",
        "        pattern1 = r'keyword:\\s*(.*?)(?:\\n|$)'\n",
        "        matches1 = re.findall(pattern1, text, re.IGNORECASE)\n",
        "        extracted_keywords.extend([kw.strip() for kw in matches1])\n",
        "\n",
        "        pattern2 = r'\\[keyword:\\s*(.*?)\\]'\n",
        "        matches2 = re.findall(pattern2, text, re.IGNORECASE)\n",
        "        extracted_keywords.extend([kw.strip() for kw in matches2])\n",
        "\n",
        "        for keyword in extracted_keywords:\n",
        "            if keyword.startswith(\"〜\"):\n",
        "                continue\n",
        "            if keyword and keyword not in self.keywords:\n",
        "                self.keywords.append(keyword)\n",
        "\n",
        "    def update_vector (self, x):\n",
        "        text = x['title'] + \"\\n\\n\" + x['text']\n",
        "        x['vector'] = self.emb_llm.embed_query(text)\n",
        "\n",
        "    def _create_backend_agent(self):\n",
        "        \"\"\"Creates the backend/sub-agent with specialized memory tools.\"\"\"\n",
        "        @tool\n",
        "        def set_result(status: str, res: Union[Dict, List, str, int, float, bool, None]) -> None:\n",
        "            \"\"\"\n",
        "            Sets the final result for the backend process.\n",
        "\n",
        "            Args:\n",
        "                status (str): The status of the process ('success' or 'error').\n",
        "                res: The result data (can be any serializable type).\n",
        "            \"\"\"\n",
        "            print(f\"Tool2(set_result): status: {repr(status)}, result: {short_repr(res)}\")\n",
        "            self.backend_status = status\n",
        "            self.backend_result = res\n",
        "\n",
        "        @tool\n",
        "        def read_all_memories() -> Dict[str, Any]:\n",
        "            \"\"\"Reads all stored memories available in the system (excluding vectors).\"\"\"\n",
        "            print(\"Tool2(read_all_memories): Retrieving all data...\")\n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'result': [{k: v for k, v in x.items() if k != 'vector'}\n",
        "                           for x in self.memories.values()]\n",
        "            }\n",
        "\n",
        "        @tool\n",
        "        def read_all_keywords() -> Dict[str, Any]:\n",
        "            \"\"\"Reads all keywords registered in the system.\"\"\"\n",
        "            print(\"Tool2(read_all_keywords): Retrieving all keywords...\")\n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'result': [x for x in self.keywords]\n",
        "            }\n",
        "\n",
        "        @tool\n",
        "        def express_thought(thought: str) -> None:\n",
        "            \"\"\"Expresses the backend agent's current thoughts or reasoning process.\"\"\"\n",
        "            mes = f\"Thought expressed by backend: \\\"{thought}\\\"\"\n",
        "            print(f\"Tool2(express_thought): {mes}\")\n",
        "\n",
        "        tools = [set_result, read_all_memories, read_all_keywords, express_thought]\n",
        "\n",
        "        app = create_agent(\n",
        "            model=self.llm2,\n",
        "            tools=tools,\n",
        "            system_prompt=self.system_prompt2,\n",
        "            checkpointer=InMemorySaver(),\n",
        "            name=\"sub-agent\",\n",
        "        )\n",
        "\n",
        "        return app\n",
        "\n",
        "    def call_backend_agent(self, user_input: str) -> Dict[str, Any]:\n",
        "        \"\"\"Orchestrates the backend agent loop until a result is set.\"\"\"\n",
        "        config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "        app = self._create_backend_agent()\n",
        "        self.messages2 = []\n",
        "        self.backend_result = None\n",
        "        self.backend_status = None\n",
        "\n",
        "        while self.backend_result is None or self.backend_status is None:\n",
        "            try:\n",
        "                sleep(3)\n",
        "                print(f\"USER_INPUT2: {user_input}\")\n",
        "                self.messages2.append(HumanMessage(user_input))\n",
        "                for chunk0 in app.stream(\n",
        "                        {\"messages\": self.messages2.copy()},\n",
        "                        config=config,\n",
        "                        stream_mode=\"updates\",\n",
        "                        name=\"sub-agent\",\n",
        "                ):\n",
        "                    self.messages2 = app.get_state(config).values[\"messages\"].copy()\n",
        "                    done = 0\n",
        "                    if \"tools\" not in chunk0:\n",
        "                        continue\n",
        "                    for x in chunk0['tools']['messages']:\n",
        "                        self.messages2ids.append(x.id)\n",
        "                        if isinstance(x, ToolMessage):\n",
        "                            print(f\"Tool result 2({x.name}): {short_repr(x.content)}\", flush=True)\n",
        "                        if isinstance(x, ToolMessage) and x.name == \"set_result\":\n",
        "                            done = 1\n",
        "                            break\n",
        "                    if done:\n",
        "                        break\n",
        "                print(f\"Sub-Agent response: {get_content_text(self.messages2[-1].content)}\")\n",
        "            except GraphRecursionError:\n",
        "                print(f\"Recursion Limit reached in sub-agent.\")\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred (sub): {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                raise e\n",
        "\n",
        "            sleep(3)\n",
        "\n",
        "        return {'status': self.backend_status, 'result': self.backend_result}\n"
      ],
      "metadata": {
        "id": "N6ZONvpIhETJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main `RagAgent`."
      ],
      "metadata": {
        "id": "RXBixDig6vz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RagAgent(MemoryBanditWorkflow):\n",
        "    \"\"\"\n",
        "    RagAgent: A specialized RAG agent designed to research and write a structured thesis.\n",
        "    \"\"\"\n",
        "    def __init__(self, llm=None, llm2=None, emb_llm=None, save_file=None):\n",
        "        # Initialize thesis structure\n",
        "        self.thesis = {\n",
        "            'title': \"\",\n",
        "            'chapters': [{'title': 'Overview', 'text': \"\"}]\n",
        "        }\n",
        "\n",
        "        # Initialize base class\n",
        "        super().__init__(llm=llm, llm2=llm2, emb_llm=emb_llm, save_file=save_file)\n",
        "\n",
        "        # Primary System Prompt\n",
        "        self.system_prompt = dedent(\"\"\"\\\n",
        "        You are a clever RAG agent. You will be writing a full thesis (/thesis).\n",
        "        Consider the current plan, policy, and surrounding circumstances, and update the plan and policy as necessary.\n",
        "        Please leave a plan and policy that makes it easy for another agent to take the next action.\n",
        "\n",
        "        Memory IDs follow the format 'memory:...'. Specifying only the number (e.g., '5555') instead of 'memory:5555' is insufficient. When referencing memory in text, write it as [memory:...].\n",
        "        'Full Map and Legend' (for coordinate reference) is in [memory:9999]. 'Procedure for searching memory' is in [memory:9998]. 'Procedure for storing documents' is in [memory:9997].\n",
        "\n",
        "        Many tools are stored as sub-tools. Sub-tool names start with '/', such as '/dir1/subtool1'. To see available sub-tools, first run subtool_show(\"/\").\n",
        "\n",
        "        The thesis (/thesis) is composed of chapters, each in Markdown format.\n",
        "        The thesis title should be formatted with a single #, and chapter titles with ##. Write according to this hierarchy.\n",
        "        Do NOT include internal memory references (like [memory:...]) in the final thesis text.\n",
        "        When storing data in memory, keep track of reference URLs separately.\n",
        "        Complete the thesis using sub-tools under the /thesis directory.\n",
        "        \"\"\")\n",
        "\n",
        "        # Secondary (Backend) System Prompt\n",
        "        self.system_prompt2 = dedent(\"\"\"\\\n",
        "        You are a backend agent supporting the clever RAG agent.\n",
        "        While this backend is intended to be implemented using various techniques, it is currently in a testing phase, so you must simulate its behavior.\n",
        "\n",
        "        Think carefully, use tools proactively, and follow the instructions from the Human.\n",
        "        \"\"\")\n",
        "\n",
        "        # Status and workflow variables\n",
        "        self.subwork_done = True\n",
        "        self.user_demand = ''\n",
        "        self.current_work = ''\n",
        "        self.current_state = 0\n",
        "\n",
        "    def init_tools(self):\n",
        "        \"\"\"Initializes RAG-specific tools including thesis management and execution control.\"\"\"\n",
        "        super().init_tools()\n",
        "\n",
        "        @tool\n",
        "        def show_user_demand() -> str:\n",
        "            \"\"\"Returns the main objective/demand from the user.\"\"\"\n",
        "            print(f\"Tool(show_user_demand): {self.user_demand}\")\n",
        "            return self.user_demand\n",
        "\n",
        "        @tool\n",
        "        def show_current_work() -> str:\n",
        "            \"\"\"Returns the current task or sub-objective.\"\"\"\n",
        "            print(f\"Tool(show_current_work): {self.current_work}\")\n",
        "            return self.current_work\n",
        "\n",
        "        @tool\n",
        "        def thesis_write_title(new_title: str) -> str:\n",
        "            \"\"\"Updates the title of the thesis.\"\"\"\n",
        "            self.thesis['title'] = new_title\n",
        "            mes = \"Thesis title has been updated.\"\n",
        "            print(f\"Tool(thesis_write_title): {mes}: {new_title}\")\n",
        "            return mes\n",
        "\n",
        "        @tool\n",
        "        def thesis_show_title() -> str:\n",
        "            \"\"\"Returns the current thesis title.\"\"\"\n",
        "            print(f\"Tool(thesis_show_title): {self.thesis['title']}\")\n",
        "            return self.thesis['title']\n",
        "\n",
        "        @tool\n",
        "        def thesis_new_chapter(title: str, text: str) -> str:\n",
        "            \"\"\"Creates a new chapter with the given title and text content.\"\"\"\n",
        "            x = {'title': title, 'text': text}\n",
        "            num = len(self.thesis['chapters'])\n",
        "            self.thesis['chapters'].append(x)\n",
        "            print(f\"Tool(thesis_new_chapter): {short_repr(x)}\")\n",
        "            return f\"Success: Created Chapter {num}.\"\n",
        "\n",
        "        @tool\n",
        "        def thesis_write_chapter(chapter_num: int, new_title: str, new_text: str) -> str:\n",
        "            \"\"\"Replaces the content of an existing chapter with new_title and new_text.\"\"\"\n",
        "            if not (0 <= chapter_num < len(self.thesis['chapters'])):\n",
        "                return f\"Failure: Chapter {chapter_num} does not currently exist.\"\n",
        "            x = {'title': new_title, 'text': new_text}\n",
        "            self.thesis['chapters'][chapter_num] = x\n",
        "            print(f\"Tool(thesis_write_chapter): {short_repr(x)}\")\n",
        "            return f\"Success: Rewrote Chapter {chapter_num}.\"\n",
        "\n",
        "        @tool\n",
        "        def thesis_delete_last_chapter() -> str:\n",
        "            \"\"\"Deletes the very last chapter of the thesis.\"\"\"\n",
        "            num = len(self.thesis['chapters']) - 1\n",
        "            if num <= 0:\n",
        "                return \"Failure: Cannot delete further (must keep Overview).\"\n",
        "            self.thesis['chapters'].pop()\n",
        "            return f\"Success: Deleted Chapter {num}.\"\n",
        "\n",
        "        @tool\n",
        "        def thesis_read_chapter(chapter_num: int) -> Union[Dict[str, str], str]:\n",
        "            \"\"\"Reads the content of the specified chapter number.\"\"\"\n",
        "            if not (0 <= chapter_num < len(self.thesis['chapters'])):\n",
        "                return f\"Failure: Chapter {chapter_num} does not currently exist.\"\n",
        "            return self.thesis['chapters'][chapter_num]\n",
        "\n",
        "        @tool\n",
        "        def thesis_list_chapters() -> List[str]:\n",
        "            \"\"\"Returns a list of all current chapter titles.\"\"\"\n",
        "            return [x['title'] for x in self.thesis['chapters']]\n",
        "\n",
        "        @tool\n",
        "        def subwork_done() -> str:\n",
        "            \"\"\"Declares that the assigned sub-task has been successfully completed.\"\"\"\n",
        "            self.subwork_done = True\n",
        "            return \"Success. Sub-task completion declared.\"\n",
        "\n",
        "        @tool\n",
        "        def subwork_not_done() -> str:\n",
        "            \"\"\"Declares that the assigned sub-task is NOT yet completed.\"\"\"\n",
        "            self.subwork_done = False\n",
        "            return \"Success. Sub-task declared incomplete.\"\n",
        "\n",
        "        @tool\n",
        "        def show_execution_map() -> str:\n",
        "            \"\"\"Returns the overall execution flow and the current state (0-6).\"\"\"\n",
        "            mes = dedent(f\"\"\"\\\n",
        "            Main objective: \"{self.user_demand}\"\n",
        "\n",
        "            Execution Map overview (Begins at State 0):\n",
        "            Transitions occur when 'subwork_done' or 'subwork_not_done' is called as instructed.\n",
        "\n",
        "            State 0: Plan strategy and outline in memory. -> Completion moves to State 1.\n",
        "            State 1: Research via web and collect data chapter by chapter. Record findings in memory. -> Completion moves to State 2.\n",
        "            State 2: Verify if collected data is sufficient for all chapters. -> Completion moves to State 3. Incompletion returns to State 1.\n",
        "            State 3: Write thesis (/thesis) chapters based on memory data. -> Completion moves to State 4.\n",
        "            State 4: Check if all chapters are complete. Finalize title and rewrite Overview. -> Completion moves to State 6. Incompletion moves to State 5.\n",
        "            State 5: Perform additional research if necessary. -> Completion moves back to State 3.\n",
        "            State 6: Finished! Complete.\n",
        "\n",
        "            Current State: {self.current_state}\n",
        "            \"\"\")\n",
        "            print(f\"Tool(show_execution_map): {mes}\")\n",
        "            return mes\n",
        "\n",
        "        @tool\n",
        "        def get_web_page_content(url: str) -> str:\n",
        "            \"\"\"\n",
        "            Fetches and returns the text content of a specified URL.\n",
        "            To be used after finding relevant URLs during investigation.\n",
        "            \"\"\"\n",
        "            try:\n",
        "                loader = WebBaseLoader(url)\n",
        "                docs = loader.load()\n",
        "                content = \" \".join([getattr(doc, 'page_content', '') for doc in docs])\n",
        "                print(f\"Tool(get_web_page_content): Success: {url}\")\n",
        "                if len(content) > 5000:\n",
        "                    return content[:5000] + \"... (Content truncated as it was too long)\"\n",
        "                return content\n",
        "            except Exception as e:\n",
        "                print(f\"Tool(get_web_page_content): Failure: {url}\")\n",
        "                return f\"Error: Failed to load page. URL: {url}, Error: {e}\"\n",
        "\n",
        "        # Initialize and register core tools\n",
        "        search_tool = DuckDuckGoSearchResults()\n",
        "        main_tools = [subwork_done, subwork_not_done, search_tool, get_web_page_content]\n",
        "        for t in main_tools:\n",
        "            self.register_tool(t, tags=[\"default_tools\", \"read_tools\", \"all_tools\"])\n",
        "\n",
        "        # Register thesis management sub-tools\n",
        "        thesis_subtools = [\n",
        "            ('/thesis/write_title', thesis_write_title),\n",
        "            ('/thesis/show_title', thesis_show_title),\n",
        "            ('/thesis/new_chapter', thesis_new_chapter),\n",
        "            ('/thesis/write_chapter', thesis_write_chapter),\n",
        "            ('/thesis/delete_last_chapter', thesis_delete_last_chapter),\n",
        "            ('/thesis/read_chapter', thesis_read_chapter),\n",
        "            ('/thesis/list_chapters', thesis_list_chapters),\n",
        "        ]\n",
        "        self.register_subtools(\n",
        "            directory=\"/thesis\",\n",
        "            subtools=thesis_subtools,\n",
        "            description=\"Sub-tools for writing the thesis.\",\n",
        "            content=dedent(\"\"\"\\\n",
        "            These are a collection of sub-tools for writing a thesis.\n",
        "\n",
        "            The thesis (/thesis) is created by dividing it into chapters, each in Markdown format.\n",
        "            The thesis title is formatted with a single #, and chapter titles are formatted with ##,\n",
        "            so please write using the appropriate hierarchy.\n",
        "            Internal memory references like [memory:...] must NOT be included in the thesis.\n",
        "            Therefore, please record reference URLs separately when storing data in memory.\n",
        "\n",
        "            Chapters begin with Chapter 0, which is always designated as the Overview.\n",
        "            \"\"\"),\n",
        "            tags=[\"default_tools\", \"read_tools\", \"all_tools\"]\n",
        "        )\n",
        "\n",
        "        # Register system control sub-tools\n",
        "        sys_subtools = [\n",
        "            ('/sys/show_user_demand', show_user_demand),\n",
        "            ('/sys/show_current_work', show_current_work),\n",
        "            ('/sys/show_execution_map', show_execution_map),\n",
        "        ]\n",
        "        self.register_subtools(\n",
        "            directory=\"/sys\",\n",
        "            subtools=sys_subtools,\n",
        "            tags=[\"default_tools\", \"read_tools\", \"all_tools\"]\n",
        "        )\n",
        "\n",
        "    def main_loop (self, user_demand):\n",
        "        self.user_demand = user_demand\n",
        "        self.current_state = 0\n",
        "        self.resume()\n",
        "\n",
        "    def resume (self):\n",
        "        if self.current_state == 0:\n",
        "            self.execute_planning()\n",
        "            self.current_state = 1\n",
        "            self.save()\n",
        "            print(\"\\n\\n----------\\n\\n\")\n",
        "        while self.current_state in [1, 2]:\n",
        "            if self.current_state == 1:\n",
        "                self.execute_investigation()\n",
        "                self.current_state = 2\n",
        "                self.save()\n",
        "                print(\"\\n\\n----------\\n\\n\")\n",
        "            if self.current_state == 2:\n",
        "                r = self.execute_check_of_investigation()\n",
        "                if r:\n",
        "                    self.current_state = 3\n",
        "                else:\n",
        "                    self.current_state = 1\n",
        "                self.save()\n",
        "                print(\"\\n\\n----------\\n\\n\")\n",
        "        while self.current_state in [3, 4, 5]:\n",
        "            if self.current_state == 3:\n",
        "                r = self.execute_writing()\n",
        "                self.current_state = 4\n",
        "                self.save()\n",
        "                print(\"\\n\\n----------\\n\\n\")\n",
        "            if self.current_state == 4:\n",
        "                r = self.execute_check_of_writing()\n",
        "                if r:\n",
        "                    self.current_state = 6\n",
        "                else:\n",
        "                    self.current_state = 5\n",
        "                self.save()\n",
        "                print(\"\\n\\n----------\\n\\n\")\n",
        "            if self.current_state == 5:\n",
        "                self.execute_reinvestigation()\n",
        "                self.current_state = 3\n",
        "                self.save()\n",
        "                print(\"\\n\\n----------\\n\\n\")\n",
        "        print(\"Done!\")\n",
        "\n",
        "    def write_loop (self):\n",
        "        if self.current_state not in [3, 4, 5]:\n",
        "            self.current_state = 3\n",
        "        self.resume()\n",
        "\n",
        "    def _execute(self, current_work: str, tool_name: str, aux_prompt: str) -> bool:\n",
        "        \"\"\"Helper to run a workflow step with specific instructions.\"\"\"\n",
        "        self.current_work = current_work\n",
        "        user_input = f\"\"\"\\\n",
        "Main Objective: \"{self.user_demand}\"\n",
        "Core Context: \"{self.core_context}\"\n",
        "Plan and Policy: \"{self.plan}\"\n",
        "Scratchpad: \"{self.scratchpad}\"\n",
        "Please proceed while checking if necessary data is already recorded.\n",
        "Current Task or Sub-objective: \"{self.current_work}\"\n",
        "\"\"\"\n",
        "        print(f\"USER_INPUT: {user_input}\")\n",
        "        self.messages.append(HumanMessage(user_input))\n",
        "\n",
        "        # Update the enforcement bandit for the specific sub-task\n",
        "        self.workflows['workflow:main']['stack'][0] = {\n",
        "            'tool_name': tool_name,\n",
        "            'tools_name': 'all_tools',\n",
        "            'exec_mode': 'persistent',\n",
        "            'aux_prompt': aux_prompt,\n",
        "            'arg': None,\n",
        "            'prob': 1.0,\n",
        "            'times': 1,\n",
        "            'pin': 'write'\n",
        "        }\n",
        "        self.run(\"workflow:main\")\n",
        "\n",
        "        return self.subwork_done\n",
        "\n",
        "    def execute_planning(self):\n",
        "        return self._execute(\n",
        "            current_work=\"Please create a plan in memory according to the main objective.\",\n",
        "            tool_name='subwork_done',\n",
        "            aux_prompt=\"Call subwork_done once you have finished planning.\",\n",
        "        )\n",
        "\n",
        "    def execute_investigation(self):\n",
        "        return self._execute(\n",
        "            current_work=\"Investigate the web, collect data, and record it in memory chapter by chapter for sections not yet covered.\",\n",
        "            tool_name='subwork_done',\n",
        "            aux_prompt=\"Call subwork_done once you have finished researching one chapter.\",\n",
        "        )\n",
        "\n",
        "    def execute_check_of_investigation(self):\n",
        "        return self._execute(\n",
        "            current_work=\"Verify if the research data stored in memory is sufficient for all chapters.\",\n",
        "            tool_name='subwork_done OR subwork_not_done',\n",
        "            aux_prompt=\"Call subwork_done if research for all chapters is sufficient. Call subwork_not_done if you determine it is insufficient.\",\n",
        "        )\n",
        "\n",
        "    def execute_writing(self):\n",
        "        return self._execute(\n",
        "            current_work=\"Write a chapter of the thesis (/thesis) that has not yet been written or is insufficient, based on the research data in memory. Note that Chapter 0 is designated as the Overview.\",\n",
        "            tool_name='subwork_done',\n",
        "            aux_prompt=\"Call subwork_done once you have written one chapter of a high-quality thesis.\",\n",
        "        )\n",
        "\n",
        "    def execute_check_of_writing(self):\n",
        "        return self._execute(\n",
        "            current_work=\"Check if all chapters of the thesis (/thesis) based on the research data are completed. Finally, set the title and rewrite the overview in Chapter 0.\",\n",
        "            tool_name='subwork_done OR subwork_not_done',\n",
        "            aux_prompt=\"Call subwork_done once all chapters are written, the title is set, and the overview is rewritten. Call subwork_not_done if all chapters are not yet written.\",\n",
        "        )\n",
        "\n",
        "    def execute_reinvestigation(self):\n",
        "        return self._execute(\n",
        "            current_work=\"If additional research is still needed, re-investigate and record findings in memory according to the main objective.\",\n",
        "            tool_name='subwork_done',\n",
        "            aux_prompt=\"Call subwork_done after you have finished the additional research.\",\n",
        "        )\n",
        "\n",
        "    def init_memories (self):\n",
        "        super().init_memories()\n",
        "        memories = []\n",
        "        for x in memories:\n",
        "            self.update_keywords(x['text'])\n",
        "            self.memories[x['id']] = x\n",
        "            self.update_vector(x)\n",
        "\n",
        "    def init_workflows(self):\n",
        "        \"\"\"Sets up the initial workflow bandits for the RAG agent.\"\"\"\n",
        "        super().init_workflows()\n",
        "        workflow_main = self.workflows['workflow:main']['stack']\n",
        "\n",
        "        # Placeholder and system control bandits\n",
        "        workflow_main = [\n",
        "            {\n",
        "                'tool_name': 'subwork_done',\n",
        "                'tools_name': 'all_tools',\n",
        "                'exec_mode': 'persistent',\n",
        "                'aux_prompt': \"Temporary registration.\",\n",
        "                'arg': None,\n",
        "                'prob': 1.0,\n",
        "                'times': 1,\n",
        "                'pin': 'write'\n",
        "            }\n",
        "        ] + workflow_main + [\n",
        "            {\n",
        "                'tool_name': 'subtool_show',\n",
        "                'tools_name': 'read_tools',\n",
        "                'exec_mode': 'persistent',\n",
        "                'aux_prompt': \"\",\n",
        "                'arg': '/thesis',\n",
        "                'prob': 0.1,\n",
        "                'times': 1,\n",
        "                'pin': None\n",
        "            },\n",
        "            {\n",
        "                'tool_name': '/sys/show_execution_map',\n",
        "                'tools_name': 'default_tools',\n",
        "                'exec_mode': 'once',\n",
        "                'aux_prompt': \"\",\n",
        "                'arg': None,\n",
        "                'prob': 1.0,\n",
        "                'times': 1,\n",
        "                'pin': None\n",
        "            },\n",
        "        ]\n",
        "        self.workflows['workflow:main']['stack'] = workflow_main\n",
        "\n",
        "    def display_thesis(self):\n",
        "        \"\"\"Renders the current thesis structure as a formatted Markdown string.\"\"\"\n",
        "        s = f\"# {self.thesis['title']}\\n\\n\"\n",
        "        for i, x in enumerate(self.thesis['chapters']):\n",
        "            # Skip if text already starts with a header\n",
        "            if re.search(r\"^\\#\\#\", x['text']):\n",
        "                pass\n",
        "            # If overview or already includes a number/Chapter in title, use as is\n",
        "            elif i == 0 or re.search(r\"Chapter|Chapter\\s+[0-9]+\", x['title'], re.IGNORECASE):\n",
        "                s += f\"## {x['title']}\\n\\n\"\n",
        "            else:\n",
        "                s += f\"## Chapter {i}: {x['title']}\\n\\n\"\n",
        "            s += f\"{x['text']}\\n\\n\"\n",
        "        return Markdown(s)\n"
      ],
      "metadata": {
        "id": "Bo0bRJVjmkwq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiating the class."
      ],
      "metadata": {
        "id": "2k-54vLkHHou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = RagAgent(llm=llm, llm2=llm, emb_llm=emb_llm, save_file=RAG_AGENT_SAVE)\n",
        "agent.save()"
      ],
      "metadata": {
        "id": "rGddUwBbkMTi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To start from the middle, skip the previous code and execute only the following."
      ],
      "metadata": {
        "id": "_BiLAD4ATI_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = RagAgent.load(RAG_AGENT_SAVE, llm=llm, llm2=llm, emb_llm=emb_llm)"
      ],
      "metadata": {
        "id": "MZFlcv4yStCv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's run it."
      ],
      "metadata": {
        "id": "CDnVa5lOo3ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.main_loop(\"Please summarize into a thesis what should have been done during Japan's 'lost decades'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rXjEPutHQF3",
        "outputId": "fcc5fd00-77ca-4d1c-dba6-6f6cb433e0b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USER_INPUT: Main Objective: \"Please summarize into a thesis what should have been done during Japan's 'lost decades'.\"\n",
            "Core Context: \"\"\n",
            "Plan and Policy: \"Plan and policy have not been set yet.\"\n",
            "Scratchpad: \"\"\n",
            "Please proceed while checking if necessary data is already recorded.\n",
            "Current Task or Sub-objective: \"Please create a plan in memory according to the main objective.\"\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: While using various tools for assistance, eventually use /sys/show_execution_map with appropriate parameters.\n",
            "Tool result(subtool_show): '---\\nname: /\\ndescription: Sub-tool Root. Explains how to explore available...'\n",
            "Tool result(subtool_show): '---\\nname: /sys\\ndescription: Essential system sub-tools.\\nallowed-tools: N...'\n",
            "Tool result(subtool_show): '---\\nname: /thesis\\ndescription: Sub-tools for writing the thesis.\\nallowed...'\n",
            "Tool result(memory_read): \"Error: Memory ID 'memory:9999' not found.\"\n",
            "Tool result(memory_list_recent): '{\"status\": \"error\", \"result\": \"Error: No recent memories found.\"}'\n",
            "Tool(show_execution_map): Main objective: \"Please summarize into a thesis what should have been done during Japan's 'lost decades'.\"\n",
            "\n",
            "Execution Map overview (Begins at State 0):\n",
            "Transitions occur when 'subwork_done' or 'subwork_not_done' is called as instructed.\n",
            "\n",
            "State 0: Plan strategy and outline in memory. -> Completion moves to State 1.\n",
            "State 1: Research via web and collect data chapter by chapter. Record findings in memory. -> Completion moves to State 2.\n",
            "State 2: Verify if collected data is sufficient for all chapters. -> Completion moves to State 3. Incompletion returns to State 1.\n",
            "State 3: Write thesis (/thesis) chapters based on memory data. -> Completion moves to State 4.\n",
            "State 4: Check if all chapters are complete. Finalize title and rewrite Overview. -> Completion moves to State 6. Incompletion moves to State 5.\n",
            "State 5: Perform additional research if necessary. -> Completion moves back to State 3.\n",
            "State 6: Finished! Complete.\n",
            "\n",
            "Current State: 0\n",
            "\n",
            "Tool result(/sys/show_execution_map): 'Main objective: \"Please summarize into a thesis what should have been done ...'\n",
            "Agent response: \n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_read with appropriate parameters.\n",
            "Tool(memory_new): {'id': 'memory:1000', 'title': \"Thesis Plan: Japan's Lost Decades\", 'accesse...}\n",
            "Tool result(memory_new): 'memory:1000'\n",
            "Tool(update_plan): Plan and policy updated.: Policy: \n",
            "1. Conduct deep research using DuckDuckGo and web content fetching to understand the economic nuances of Japan's Lost Decades.\n",
            "2. Store gathered information in memory with clear titles and reference URLs.\n",
            "3. Follow the chapter structure defined in [memory:1000].\n",
            "4. Use the /thesis sub-tools to build the document.\n",
            "\n",
            "Plan:\n",
            "- Step 1: Research the initial response to the bubble collapse (late 80s - early 90s).\n",
            "- Step 2: Research the banking crisis and the \"zombie company\" phenomenon.\n",
            "- Step 3: Research monetary policy debates (liquidity trap, QE).\n",
            "- Step 4: Write Chapter 0 (Overview).\n",
            "- Step 5: Write Chapter 1 (Anatomy of Collapse).\n",
            "- Step 6: Proceed through subsequent chapters.\n",
            "- Step 7: Final review and completion.\n",
            "Tool result(/sys/update_plan): 'Plan and policy updated.'\n",
            "Tool(update_core): Core context updated.: Thesis Plan: memory:1000\n",
            "Current Focus: Researching initial response to bubble collapse and banking crisis.\n",
            "Tool result(/sys/update_core): 'Core context updated.'\n",
            "Tool result(memory_read): '{\"id\": \"memory:1000\", \"title\": \"Thesis Plan: Japan\\'s Lost Decades\", \"acces...'\n",
            "Agent response: \n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_read with appropriate parameters.\n",
            "Tool result(duckduckgo_results_json): \"snippet: In conclusion, Japan's economic crisis and the subsequent Lost Dec...\"\n",
            "Tool result(duckduckgo_results_json): 'snippet: Japan\\'s economic crisis, known as the \" Lost Decade ,\" began in t...'\n",
            "Tool result(duckduckgo_results_json): 'snippet: December 31, 2025 - As economist Paul Krugman explained, \" Japan\\'...'\n",
            "Tool(get_web_page_content): Success: https://en.wikipedia.org/wiki/Lost_Decades\n",
            "Tool result(get_web_page_content): \"\\n\\n\\n\\nLost Decades - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...\"\n",
            "Tool(get_web_page_content): Success: https://en.wikipedia.org/wiki/Japanese_asset_price_bubble\n",
            "Tool result(get_web_page_content): \"\\n\\n\\n\\nJapanese asset price bubble - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...\"\n",
            "Tool result(/thesis/write_title): 'Error: Invalid argument format.\\nDetails: [{\\'type\\': \\'missing\\', \\'loc\\':...'\n",
            "Tool(thesis_write_title): Thesis title has been updated.: Alternative Economic and Policy Measures for Japan's Lost Decades\n",
            "Tool result(/thesis/write_title): 'Thesis title has been updated.'\n",
            "Tool result(/thesis/new_chapter): 'Error: Invalid argument format.\\nDetails: [{\\'type\\': \\'missing\\', \\'loc\\':...'\n",
            "Recursion Limit reached.\n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_new OR memory_update_string OR memory_append_string (one of them) with appropriate parameters.\n",
            "Tool result(subtool_show): '---\\nname: /thesis/new_chapter\\ndescription: thesis_new_chapter\\nallowed-to...'\n",
            "Tool(thesis_new_chapter): {'title': 'Overview', 'text': '## Chapter 0: Overview\\n\\nThe Japanese \"Lost ...}\n",
            "Tool result(/thesis/new_chapter): 'Success: Created Chapter 1.'\n",
            "Tool(memory_new): {'id': 'memory:1001', 'title': 'Research Data: Japan Lost Decades Phase 1', ...}\n",
            "Tool result(memory_new): 'memory:1001'\n",
            "Agent response: \n",
            "USER_INPUT: While using various tools for assistance, eventually use subwork_done with appropriate parameters. (Auxiliary Prompt): Call subwork_done once you have finished planning.\n",
            "Tool result(memory_read): '{\"id\": \"memory:1000\", \"title\": \"Thesis Plan: Japan\\'s Lost Decades\", \"acces...'\n",
            "Tool(update_scratchpad): Scratchpad updated.: # Thesis Progress: Japan's Lost Decades\n",
            "\n",
            "## Status\n",
            "- Title: \"Alternative Economic and Policy Measures for Japan's Lost Decades\" (Set)\n",
            "- Chapter 0: Overview (Completed)\n",
            "- Phase 1 Research (Bubble/Banking Crisis): Completed & stored in [memory:1001]\n",
            "- Phase 1 Research (Monetary/Fiscal/Structural): In progress\n",
            "\n",
            "## Updated Plan\n",
            "1. Research for Chapter 1: Deep dive into the asset bubble mechanics and the \"convoy system\" of the early 90s.\n",
            "2. Draft Chapter 1: The Anatomy of the Collapse.\n",
            "3. Research for Chapter 2 & 3: Monetary and Fiscal policies (Krugman's liquidity trap vs Koo's balance sheet recession).\n",
            "4. Draft Chapter 2: Monetary Policy Missteps and Corrections.\n",
            "5. Draft Chapter 3: The Fiscal Dilemma.\n",
            "6. Research for Chapter 4: Structural Barriers.\n",
            "7. Draft Chapter 4: Structural Barriers and Missed Opportunities.\n",
            "8. Synthesize Chapter 5: A Counterfactual Roadmap.\n",
            "9. Finalize Chapter 6: Conclusion.\n",
            "\n",
            "## Policy\n",
            "- Cite academic critiques (Bernanke, Posen, Koo, Krugman) to ground counterfactuals.\n",
            "- Maintain Markdown hierarchy (# Title, ## Chapter Title).\n",
            "- No [memory:xxxx] references in the final thesis text.\n",
            "- Use /thesis/ sub-tools for all writing operations.\n",
            "Tool result(update_scratchpad): 'Scratchpad updated.'\n",
            "Tool result(subwork_done): 'Success. Sub-task completion declared.'\n",
            "Agent response: \n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: Main Objective: \"Please summarize into a thesis what should have been done during Japan's 'lost decades'.\"\n",
            "Core Context: \"Thesis Plan: memory:1000\n",
            "Current Focus: Researching initial response to bubble collapse and banking crisis.\"\n",
            "Plan and Policy: \"Policy: \n",
            "1. Conduct deep research using DuckDuckGo and web content fetching to understand the economic nuances of Japan's Lost Decades.\n",
            "2. Store gathered information in memory with clear titles and reference URLs.\n",
            "3. Follow the chapter structure defined in [memory:1000].\n",
            "4. Use the /thesis sub-tools to build the document.\n",
            "\n",
            "Plan:\n",
            "- Step 1: Research the initial response to the bubble collapse (late 80s - early 90s).\n",
            "- Step 2: Research the banking crisis and the \"zombie company\" phenomenon.\n",
            "- Step 3: Research monetary policy debates (liquidity trap, QE).\n",
            "- Step 4: Write Chapter 0 (Overview).\n",
            "- Step 5: Write Chapter 1 (Anatomy of Collapse).\n",
            "- Step 6: Proceed through subsequent chapters.\n",
            "- Step 7: Final review and completion.\"\n",
            "Scratchpad: \"# Thesis Progress: Japan's Lost Decades\n",
            "\n",
            "## Status\n",
            "- Title: \"Alternative Economic and Policy Measures for Japan's Lost Decades\" (Set)\n",
            "- Chapter 0: Overview (Completed)\n",
            "- Phase 1 Research (Bubble/Banking Crisis): Completed & stored in [memory:1001]\n",
            "- Phase 1 Research (Monetary/Fiscal/Structural): In progress\n",
            "\n",
            "## Updated Plan\n",
            "1. Research for Chapter 1: Deep dive into the asset bubble mechanics and the \"convoy system\" of the early 90s.\n",
            "2. Draft Chapter 1: The Anatomy of the Collapse.\n",
            "3. Research for Chapter 2 & 3: Monetary and Fiscal policies (Krugman's liquidity trap vs Koo's balance sheet recession).\n",
            "4. Draft Chapter 2: Monetary Policy Missteps and Corrections.\n",
            "5. Draft Chapter 3: The Fiscal Dilemma.\n",
            "6. Research for Chapter 4: Structural Barriers.\n",
            "7. Draft Chapter 4: Structural Barriers and Missed Opportunities.\n",
            "8. Synthesize Chapter 5: A Counterfactual Roadmap.\n",
            "9. Finalize Chapter 6: Conclusion.\n",
            "\n",
            "## Policy\n",
            "- Cite academic critiques (Bernanke, Posen, Koo, Krugman) to ground counterfactuals.\n",
            "- Maintain Markdown hierarchy (# Title, ## Chapter Title).\n",
            "- No [memory:xxxx] references in the final thesis text.\n",
            "- Use /thesis/ sub-tools for all writing operations.\"\n",
            "Please proceed while checking if necessary data is already recorded.\n",
            "Current Task or Sub-objective: \"Investigate the web, collect data, and record it in memory chapter by chapter for sections not yet covered.\"\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_read with appropriate parameters.\n",
            "Tool result(memory_read): '{\"id\": \"memory:1001\", \"title\": \"Research Data: Japan Lost Decades Phase 1\",...'\n",
            "Agent response: {\"id\": \"memory:1001\", \"title\": \"Research Data: Japan Lost Decades Phase 1\", \"accesses\": 1.0, \"text\": \"### Research Log: Japan's Lost Decades (Step 1)\\n\\n**Key Findings on Bubble Collapse & Banking Crisis (1990-1995):**\\n1. **The Policy Lag:** The Bank of Japan (BoJ) delayed tightening in 1987 due to Black Monday concerns, fueling the bubble. Post-collapse, the BoJ was slow to cut rates, fearing a rekindling of the bubble.\\n2. **Banking Inertia:** The Ministry of Finance (MoF) and banks adopted a \\\"convoy system\\\" (goso sendan), hoping that time and economic recovery would fix non-performing loans (NPLs). This led to \\\"forbearance lending,\\\" creating zombie firms.\\n3. **Monetary Missteps:** Interest rates were not cut aggressively enough. The discount rate remained at 6% in 1991 and only reached 0.5% by 1995.\\n4. **Initial Fiscal Response:** While some stimulus was provided, it was often uncoordinated and focused on public works with low multipliers rather than bank recapitalization.\\n\\n**Counterfactual Arguments Identified:**\\n- **Bernanke/Krugman:** BoJ should have targeted higher inflation expectations earlier to break the liquidity trap.\\n- **Richard Koo:** Fiscal policy should have been even more sustained and aggressive to offset private sector deleveraging (Balance Sheet Recession).\\n- **Adam Posen:** Faster, forced recognition of NPLs and bank closures/mergers were necessary to restore the credit channel.\\n\\n**Reference URLs:**\\n- https://worldhistoryjournal.com/2025/03/13/understanding-japans-economic-crisis-key-lessons/\\n- https://en.wikipedia.org/wiki/Lost_Decades\\n- https://en.wikipedia.org/wiki/Japanese_asset_price_bubble\\n- https://www.imf.org/en/publications/wp/issues/2025/11/06/macroeconomic-effects-and-spillovers-from-bank-of-japan-unconventional-monetary-policy-571620\\n\", \"modified_at\": \"2026-02-12T17:28:58.072734\"}\n",
            "USER_INPUT: While using various tools for assistance, eventually use subwork_done with appropriate parameters. (Auxiliary Prompt): Call subwork_done once you have finished researching one chapter.\n",
            "Tool result(duckduckgo_results_json): \"snippet: That’s what then-Princeton professor Ben Bernanke did in 1999 , wh...\"\n",
            "Tool result(duckduckgo_results_json): 'snippet: ↑ Paul R. Krugman , Kathryn M. Dominquez, Kenneth Rogoff: It \\' s ...'\n",
            "Tool result(duckduckgo_results_json): \"snippet: The Lost Decades are a lengthy period of economic stagnation in Ja...\"\n",
            "Tool result(duckduckgo_results_json): 'snippet: In 1997 , Prime Minister Ryutaro Hashimoto raised the consumption ...'\n",
            "Tool(get_web_page_content): Success: https://web.mit.edu/krugman/www/bpea_jp.pdf\n",
            "Tool result(get_web_page_content): '%PDF-1.2 \\r\\n%âãÏÓ\\r\\n \\r\\n7 0 obj\\r\\n<<\\r\\n/Length 8 0 R\\r\\n/Filter /LZWDe...'\n",
            "Tool result(duckduckgo_results_json): 'snippet: December 31, 2025 - In his view, this avoided a U.S. ... their lia...'\n",
            "Tool(memory_new): {'id': 'memory:1002', 'title': 'Research Data: Japan Lost Decades Phase 2', ...}\n",
            "Tool result(memory_new): 'memory:1002'\n",
            "Tool result(duckduckgo_results_json): 'snippet: Galapagos effect ( Galapagos syndrome ). Japan Galapagos effect ex...'\n",
            "Tool result(duckduckgo_results_json): \"snippet: In order to reduce the high labour cost, firms started to restrict...\"\n",
            "Tool result(duckduckgo_results_json): 'snippet: December 31, 2025 - This tendency, coinciding with the acceleratio...'\n",
            "Tool(memory_new): {'id': 'memory:1003', 'title': 'Research Data: Japan Lost Decades Phase 3', ...}\n",
            "Tool result(memory_new): 'memory:1003'\n",
            "Tool(update_scratchpad): Scratchpad updated.: # Thesis Progress: Alternative Economic and Policy Measures for Japan's Lost Decades\n",
            "\n",
            "## Status\n",
            "- **Title & Overview (Chapter 0):** Completed.\n",
            "- **Phase 1 Research (Bubble/Banking):** Completed [memory:1001].\n",
            "- **Phase 2 Research (Monetary/Fiscal):** Completed [memory:1002].\n",
            "- **Phase 3 Research (Structural/Synthesis):** Completed [memory:1003].\n",
            "- **Chapter 1 Writing:** Next.\n",
            "\n",
            "## Chapter Plan\n",
            "- Chapter 0: Overview (Complete)\n",
            "- Chapter 1: The Anatomy of the Collapse (Asset Bubble & Convoy System)\n",
            "- Chapter 2: Monetary Policy Missteps (Liquidity Trap & Inflation Targeting)\n",
            "- Chapter 3: The Fiscal Dilemma (Premature Austerity vs. Balance Sheet Recession)\n",
            "- Chapter 4: Structural Barriers (Labor Duality & Zombie Firms)\n",
            "- Chapter 5: A Counterfactual Roadmap (The \"Alternative Manual\")\n",
            "- Chapter 6: Global Implications (Lessons for the West post-2008)\n",
            "- Chapter 7: Conclusion\n",
            "\n",
            "## Current Task\n",
            "- Draft Chapter 1.\n",
            "- Continue to Chapter 2.\n",
            "Tool result(update_scratchpad): 'Scratchpad updated.'\n",
            "Tool result(subwork_done): 'Success. Sub-task completion declared.'\n",
            "Agent response: \n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: Main Objective: \"Please summarize into a thesis what should have been done during Japan's 'lost decades'.\"\n",
            "Core Context: \"Thesis Plan: memory:1000\n",
            "Current Focus: Researching initial response to bubble collapse and banking crisis.\"\n",
            "Plan and Policy: \"Policy: \n",
            "1. Conduct deep research using DuckDuckGo and web content fetching to understand the economic nuances of Japan's Lost Decades.\n",
            "2. Store gathered information in memory with clear titles and reference URLs.\n",
            "3. Follow the chapter structure defined in [memory:1000].\n",
            "4. Use the /thesis sub-tools to build the document.\n",
            "\n",
            "Plan:\n",
            "- Step 1: Research the initial response to the bubble collapse (late 80s - early 90s).\n",
            "- Step 2: Research the banking crisis and the \"zombie company\" phenomenon.\n",
            "- Step 3: Research monetary policy debates (liquidity trap, QE).\n",
            "- Step 4: Write Chapter 0 (Overview).\n",
            "- Step 5: Write Chapter 1 (Anatomy of Collapse).\n",
            "- Step 6: Proceed through subsequent chapters.\n",
            "- Step 7: Final review and completion.\"\n",
            "Scratchpad: \"# Thesis Progress: Alternative Economic and Policy Measures for Japan's Lost Decades\n",
            "\n",
            "## Status\n",
            "- **Title & Overview (Chapter 0):** Completed.\n",
            "- **Phase 1 Research (Bubble/Banking):** Completed [memory:1001].\n",
            "- **Phase 2 Research (Monetary/Fiscal):** Completed [memory:1002].\n",
            "- **Phase 3 Research (Structural/Synthesis):** Completed [memory:1003].\n",
            "- **Chapter 1 Writing:** Next.\n",
            "\n",
            "## Chapter Plan\n",
            "- Chapter 0: Overview (Complete)\n",
            "- Chapter 1: The Anatomy of the Collapse (Asset Bubble & Convoy System)\n",
            "- Chapter 2: Monetary Policy Missteps (Liquidity Trap & Inflation Targeting)\n",
            "- Chapter 3: The Fiscal Dilemma (Premature Austerity vs. Balance Sheet Recession)\n",
            "- Chapter 4: Structural Barriers (Labor Duality & Zombie Firms)\n",
            "- Chapter 5: A Counterfactual Roadmap (The \"Alternative Manual\")\n",
            "- Chapter 6: Global Implications (Lessons for the West post-2008)\n",
            "- Chapter 7: Conclusion\n",
            "\n",
            "## Current Task\n",
            "- Draft Chapter 1.\n",
            "- Continue to Chapter 2.\"\n",
            "Please proceed while checking if necessary data is already recorded.\n",
            "Current Task or Sub-objective: \"Verify if the research data stored in memory is sufficient for all chapters.\"\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: While using various tools for assistance, eventually use subtool_show with appropriate parameters. (Auxiliary Prompt): Please read the skill for /thesis.\n",
            "Tool result(subtool_show): '---\\nname: /thesis\\ndescription: Sub-tools for writing the thesis.\\nallowed...'\n",
            "Agent response: ---\n",
            "name: /thesis\n",
            "description: Sub-tools for writing the thesis.\n",
            "allowed-tools: No special permission is required to use this sub-skill.\n",
            "---\n",
            "These are a collection of sub-tools for writing a thesis.\n",
            "\n",
            "The thesis (/thesis) is created by dividing it into chapters, each in Markdown format. \n",
            "The thesis title is formatted with a single #, and chapter titles are formatted with ##, \n",
            "so please write using the appropriate hierarchy. \n",
            "Internal memory references like [memory:...] must NOT be included in the thesis. \n",
            "Therefore, please record reference URLs separately when storing data in memory.\n",
            "\n",
            "Chapters begin with Chapter 0, which is always designated as the Overview.\n",
            "\n",
            "## Sub-tools\n",
            "\n",
            "\n",
            "### Sub-tool: /thesis/write_title\n",
            "\n",
            "[Sub-tool Name] /thesis/write_title\n",
            "[Original Tool Name] thesis_write_title\n",
            "[Original Usage] thesis_write_title(new_title)\n",
            "[Description] Updates the title of the thesis.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/write_title\", {\"new_title\": ...})\n",
            "\n",
            "### Sub-tool: /thesis/show_title\n",
            "\n",
            "[Sub-tool Name] /thesis/show_title\n",
            "[Original Tool Name] thesis_show_title\n",
            "[Original Usage] thesis_show_title()\n",
            "[Description] Returns the current thesis title.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/show_title\", {})\n",
            "\n",
            "### Sub-tool: /thesis/new_chapter\n",
            "\n",
            "[Sub-tool Name] /thesis/new_chapter\n",
            "[Original Tool Name] thesis_new_chapter\n",
            "[Original Usage] thesis_new_chapter(title, text)\n",
            "[Description] Creates a new chapter with the given title and text content.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/new_chapter\", {\"title\": ..., \"text\": ...})\n",
            "\n",
            "### Sub-tool: /thesis/write_chapter\n",
            "\n",
            "[Sub-tool Name] /thesis/write_chapter\n",
            "[Original Tool Name] thesis_write_chapter\n",
            "[Original Usage] thesis_write_chapter(chapter_num, new_title, new_text)\n",
            "[Description] Replaces the content of an existing chapter with new_title and new_text.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/write_chapter\", {\"chapter_num\": ..., \"new_title\": ..., \"new_text\": ...})\n",
            "\n",
            "### Sub-tool: /thesis/delete_last_chapter\n",
            "\n",
            "[Sub-tool Name] /thesis/delete_last_chapter\n",
            "[Original Tool Name] thesis_delete_last_chapter\n",
            "[Original Usage] thesis_delete_last_chapter()\n",
            "[Description] Deletes the very last chapter of the thesis.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/delete_last_chapter\", {})\n",
            "\n",
            "### Sub-tool: /thesis/read_chapter\n",
            "\n",
            "[Sub-tool Name] /thesis/read_chapter\n",
            "[Original Tool Name] thesis_read_chapter\n",
            "[Original Usage] thesis_read_chapter(chapter_num)\n",
            "[Description] Reads the content of the specified chapter number.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/read_chapter\", {\"chapter_num\": ...})\n",
            "\n",
            "### Sub-tool: /thesis/list_chapters\n",
            "\n",
            "[Sub-tool Name] /thesis/list_chapters\n",
            "[Original Tool Name] thesis_list_chapters\n",
            "[Original Usage] thesis_list_chapters()\n",
            "[Description] Returns a list of all current chapter titles.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/list_chapters\", {})\n",
            "\n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_read with appropriate parameters.\n",
            "Tool result(memory_read): '{\"id\": \"memory:1000\", \"title\": \"Thesis Plan: Japan\\'s Lost Decades\", \"acces...'\n",
            "Agent response: {\"id\": \"memory:1000\", \"title\": \"Thesis Plan: Japan's Lost Decades\", \"accesses\": 3.0, \"text\": \"# Thesis Plan: Japan's Lost Decades - What Should Have Been Done\\n\\n## Phase 1: Information Gathering & Research\\n1. Identify the key economic, social, and political factors of Japan's \\\"Lost Decades\\\" (roughly 1991-2021).\\n2. Research the mainstream economic critiques (monetary policy, fiscal policy, structural reforms).\\n3. Investigate specific alternative proposals and \\\"what-if\\\" scenarios from economists (e.g., Paul Krugman, Richard Koo, Joseph Stiglitz).\\n4. Gather data on:\\n    - Asset bubble collapse (1991).\\n    - Banking crisis and delayed disposal of bad loans.\\n    - Monetary policy (interest rates, QE).\\n    - Fiscal policy (stimulus vs. austerity).\\n    - Structural issues (demographics, labor market rigidity).\\n\\n## Phase 2: Thesis Structure Definition\\n- **Chapter 0: Overview** (Summary of the thesis and core argument).\\n- **Chapter 1: The Anatomy of the Collapse** (Context of the bubble and the initial response).\\n- **Chapter 2: Monetary Policy Missteps and Corrections** (Discussion of the BoJ's actions).\\n- **Chapter 3: The Fiscal Dilemma** (Stimulus efficiency and the debt trap).\\n- **Chapter 4: Structural Barriers and Missed Opportunities** (Labor, innovation, and demographics).\\n- **Chapter 5: A Counterfactual Roadmap** (Consolidated recommendations on what should have been done).\\n- **Chapter 6: Conclusion** (Lessons for the future).\\n\\n## Phase 3: Writing & Review\\n1. Draft chapters sequentially.\\n2. Review for consistency and remove any internal memory references.\\n3. Finalize the thesis.\", \"modified_at\": \"2026-02-12T17:27:14.797162\"}\n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_read with appropriate parameters.\n",
            "Tool result(/thesis/read_chapter): 'Error: Invalid argument format.\\nDetails: [{\\'type\\': \\'missing\\', \\'loc\\':...'\n",
            "Tool result(duckduckgo_results_json): 'snippet: 3 days ago - The trend continued throughout 1987 when it touched a...'\n",
            "Tool result(/thesis/list_chapters): '[\"Overview\", \"Overview\"]'\n",
            "Tool result(/thesis/read_chapter): 'Error: Invalid argument format.\\nDetails: [{\\'type\\': \\'missing\\', \\'loc\\':...'\n",
            "Tool(thesis_show_title): Alternative Economic and Policy Measures for Japan's Lost Decades\n",
            "Tool result(/thesis/show_title): \"Alternative Economic and Policy Measures for Japan's Lost Decades\"\n",
            "Tool result(/thesis/read_chapter): 'Error: Invalid argument format.\\nDetails: [{\\'type\\': \\'missing\\', \\'loc\\':...'\n",
            "Tool(thesis_show_title): Alternative Economic and Policy Measures for Japan's Lost Decades\n",
            "Tool result(/thesis/list_chapters): '[\"Overview\", \"Overview\"]'\n",
            "Tool result(/thesis/show_title): \"Alternative Economic and Policy Measures for Japan's Lost Decades\"\n",
            "Tool result(duckduckgo_results_json): 'snippet: 1 week ago - Driven by speculative investments and excessive lendi...'\n",
            "Tool result(/thesis/write_chapter): 'Error: Invalid argument format.\\nDetails: [{\\'type\\': \\'missing\\', \\'loc\\':...'\n",
            "Tool result(subtool_show): '---\\nname: /thesis\\ndescription: Sub-tools for writing the thesis.\\nallowed...'\n",
            "Recursion Limit reached.\n",
            "USER_INPUT: The previous instruction has not been completed yet. Previous instruction: While using various tools for assistance, eventually use memory_read with appropriate parameters.\n",
            "Tool result(memory_read): '{\"id\": \"memory:1001\", \"title\": \"Research Data: Japan Lost Decades Phase 1\",...'\n",
            "Agent response: {\"id\": \"memory:1002\", \"title\": \"Research Data: Japan Lost Decades Phase 2\", \"accesses\": 2.0, \"text\": \"### Research Log: Japan's Lost Decades (Step 2)\\n\\n**Chapter 2: Monetary Policy & The Liquidity Trap (1995-2006)**\\n1. **The Liquidity Trap:** Paul Krugman (1998) argued that Japan was in a liquidity trap where nominal interest rates were near zero, but real rates remained too high because of deflationary expectations.\\n2. **Krugman’s Solution:** The central bank must \\\"credibly promise to be irresponsible\\\"—i.e., commit to a higher inflation target (3-4%) to lower real interest rates.\\n3. **Bernanke’s Critique (1999):** Bernanke criticized the BoJ for \\\"self-induced paralysis.\\\" He suggested aggressive QE, yen depreciation, and even direct cooperation with fiscal authorities (money-financed stimulus).\\n4. **Historical Reality:** BoJ only introduced ZIRP in 1999 and QE in 2001, both of which were seen as \\\"too little, too late\\\" and often prematurely retracted (e.g., ending ZIRP in Aug 2000).\\n\\n**Chapter 3: The Fiscal Dilemma & Balance Sheet Recession**\\n1. **Richard Koo’s Theory:** Private firms were not borrowing even at zero rates because they were focusing on debt repayment (deleveraging) after the bubble burst. This is a \\\"Balance Sheet Recession.\\\"\\n2. **Koo’s Solution:** In such a state, the government must act as the \\\"borrower of last resort\\\" to maintain aggregate demand. Fiscal stimulus must be sustained until private balance sheets are repaired.\\n3. **The 1997 Tax Hike:** Prime Minister Hashimoto raised the consumption tax from 3% to 5% and cut spending to reduce the deficit. This premature austerity triggered a deep recession and a banking crisis, proving catastrophic.\\n4. **The 1998 Obuchi Stimulus:** After the 1997 disaster, the Obuchi administration launched a massive 24 trillion yen stimulus, which temporarily stabilized the economy but added significantly to national debt without solving structural issues.\\n\\n**Reference URLs:**\\n- https://web.mit.edu/krugman/www/bpea_jp.pdf (Krugman 1998)\\n- https://qz.com/29735/there-is-only-one-thing-that-can-save-japan-now-inflation (Bernanke 1999 summary)\\n- https://en.wikipedia.org/wiki/Richard_Koo (Balance Sheet Recession)\\n- https://global.chinadaily.com.cn/a/202309/13/WS6501a883a310d2dce4bb58e3.html (1997 Tax Hike)\\n\", \"modified_at\": \"2026-02-12T17:30:30.514135\"}\n",
            "USER_INPUT: While using various tools for assistance, eventually use subwork_done OR subwork_not_done (one of them) with appropriate parameters. (Auxiliary Prompt): Call subwork_done if research for all chapters is sufficient. Call subwork_not_done if you determine it is insufficient.\n",
            "Tool(update_scratchpad): Scratchpad updated.: # Thesis Progress\n",
            "- Title: Alternative Economic and Policy Measures for Japan's Lost Decades\n",
            "- Chapter 0: Overview (Completed, though duplicate entry in list_chapters suggests a need for cleanup)\n",
            "- Chapter 1: Anatomy of the Collapse (Draft prepared, ready for write/new)\n",
            "- Chapter 2: Monetary Policy (Research documented in [memory:1002])\n",
            "- Chapter 3: Fiscal Dilemma (Research documented in [memory:1002], specific multiplier data needed)\n",
            "- Chapter 4: Structural Barriers (Basic research in [memory:1003], needs more on labor market)\n",
            "- Chapter 5: Counterfactual Roadmap (Synthesis phase)\n",
            "- Chapter 6: Conclusion\n",
            "\n",
            "# Technical Notes\n",
            "- `subtool_do` requires exact key names (no extra quotes inside the string keys).\n",
            "- `/thesis/write_chapter` requires `chapter_num`, `new_title`, and `new_text`.\n",
            "- Current `list_chapters` output: [\"Overview\", \"Overview\"]. This implies index 0 and 1 are both \"Overview\". I should replace index 1 with \"The Anatomy of the Collapse\".\n",
            "\n",
            "# Next Steps\n",
            "1. Correct the duplication by writing Chapter 1.\n",
            "2. Research fiscal multipliers in 1990s Japan.\n",
            "3. Draft Chapter 2.\n",
            "4. Update memory with new research.\n",
            "Tool result(update_scratchpad): 'Scratchpad updated.'\n",
            "Tool result(duckduckgo_results_json): \"snippet: This literature review examines the wide-ranging estimates of the ...\"\n",
            "Tool result(/thesis/write_chapter): 'Error: Invalid argument format.\\nDetails: [{\\'type\\': \\'missing\\', \\'loc\\':...'\n",
            "Tool(thesis_write_chapter): {'title': 'The Anatomy of the Collapse', 'text': 'The collapse of the Japane...}\n",
            "Tool result(/thesis/write_chapter): 'Success: Rewrote Chapter 1.'\n",
            "Tool result(/thesis/new_chapter): \"Error: Invalid argument format.\\nDetails: [{'type': 'missing', 'loc': ('tex...\"\n",
            "Tool(thesis_new_chapter): {'title': 'Monetary Policy and the Liquidity Trap', 'text': 'By the mid-1990...}\n",
            "Tool result(/thesis/new_chapter): 'Success: Created Chapter 2.'\n",
            "Tool(thesis_new_chapter): {'title': 'The Fiscal Dilemma: Multipliers and Debt Overhang', 'text': 'Japa...}\n",
            "Tool result(/thesis/new_chapter): 'Success: Created Chapter 3.'\n",
            "Tool result(/thesis/list_chapters): '[\"Overview\", \"The Anatomy of the Collapse\", \"Monetary Policy and the Liquid...'\n",
            "Tool result(/sys/duckduckgo_results_json): \"Error: Sub-tool '/sys/duckduckgo_results_json' not found.\"\n",
            "Recursion Limit reached.\n",
            "USER_INPUT: The previous instruction has not been completed yet. Previous instruction: While using various tools for assistance, eventually use subwork_done OR subwork_not_done (one of them) with appropriate parameters. (Auxiliary Prompt): Call subwork_done if research for all chapters is sufficient. Call subwork_not_done if you determine it is insufficient.\n",
            "Tool result(duckduckgo_results_json): 'snippet: A keiretsu ( Japanese : 系列; literally system , series, grouping of...'\n",
            "Tool result(duckduckgo_results_json): 'snippet: If the older workers actually start to take the opportunity, it ma...'\n",
            "Tool(memory_new): {'id': 'memory:1004', 'title': 'Research Log Phase 3: Structural Reforms', '...}\n",
            "Tool result(memory_new): 'memory:1004'\n",
            "Tool(update_scratchpad): Scratchpad updated.: Current Progress:\n",
            "- Chapter 0: Complete.\n",
            "- Chapter 1: Complete (The Anatomy of the Collapse).\n",
            "- Chapter 2: Complete (Monetary Policy and the Liquidity Trap).\n",
            "- Chapter 3: Complete (The Fiscal Dilemma: Multipliers and Debt Overhang).\n",
            "- Research for Chapter 4 (Structural Barriers) is collected in [memory:1004].\n",
            "\n",
            "Next Steps:\n",
            "1. Draft Chapter 4: \"Structural Barriers and the Rigidity of the Japanese Model.\"\n",
            "2. Research for Chapter 5 (The 1997 Banking Crisis and Big Bang Reforms).\n",
            "3. Research for Chapter 6 (Counterfactual Recap: What if?).\n",
            "4. Research for Chapter 7 (Conclusion and Policy Implications).\n",
            "\n",
            "Policy:\n",
            "- Use /thesis tools for all writing and listing.\n",
            "- Maintain academic tone and counterfactual focus.\n",
            "- Avoid memory references in final text.\n",
            "Tool result(update_scratchpad): 'Scratchpad updated.'\n",
            "Tool result(subwork_not_done): 'Success. Sub-task declared incomplete.'\n",
            "Agent response: \n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: Main Objective: \"Please summarize into a thesis what should have been done during Japan's 'lost decades'.\"\n",
            "Core Context: \"Thesis Plan: memory:1000\n",
            "Current Focus: Researching initial response to bubble collapse and banking crisis.\"\n",
            "Plan and Policy: \"Policy: \n",
            "1. Conduct deep research using DuckDuckGo and web content fetching to understand the economic nuances of Japan's Lost Decades.\n",
            "2. Store gathered information in memory with clear titles and reference URLs.\n",
            "3. Follow the chapter structure defined in [memory:1000].\n",
            "4. Use the /thesis sub-tools to build the document.\n",
            "\n",
            "Plan:\n",
            "- Step 1: Research the initial response to the bubble collapse (late 80s - early 90s).\n",
            "- Step 2: Research the banking crisis and the \"zombie company\" phenomenon.\n",
            "- Step 3: Research monetary policy debates (liquidity trap, QE).\n",
            "- Step 4: Write Chapter 0 (Overview).\n",
            "- Step 5: Write Chapter 1 (Anatomy of Collapse).\n",
            "- Step 6: Proceed through subsequent chapters.\n",
            "- Step 7: Final review and completion.\"\n",
            "Scratchpad: \"Current Progress:\n",
            "- Chapter 0: Complete.\n",
            "- Chapter 1: Complete (The Anatomy of the Collapse).\n",
            "- Chapter 2: Complete (Monetary Policy and the Liquidity Trap).\n",
            "- Chapter 3: Complete (The Fiscal Dilemma: Multipliers and Debt Overhang).\n",
            "- Research for Chapter 4 (Structural Barriers) is collected in [memory:1004].\n",
            "\n",
            "Next Steps:\n",
            "1. Draft Chapter 4: \"Structural Barriers and the Rigidity of the Japanese Model.\"\n",
            "2. Research for Chapter 5 (The 1997 Banking Crisis and Big Bang Reforms).\n",
            "3. Research for Chapter 6 (Counterfactual Recap: What if?).\n",
            "4. Research for Chapter 7 (Conclusion and Policy Implications).\n",
            "\n",
            "Policy:\n",
            "- Use /thesis tools for all writing and listing.\n",
            "- Maintain academic tone and counterfactual focus.\n",
            "- Avoid memory references in final text.\"\n",
            "Please proceed while checking if necessary data is already recorded.\n",
            "Current Task or Sub-objective: \"Investigate the web, collect data, and record it in memory chapter by chapter for sections not yet covered.\"\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: While using various tools for assistance, eventually use subtool_show with appropriate parameters. (Auxiliary Prompt): Please read the skill for /thesis.\n",
            "Tool result(subtool_show): '---\\nname: /thesis\\ndescription: Sub-tools for writing the thesis.\\nallowed...'\n",
            "Agent response: ---\n",
            "name: /thesis\n",
            "description: Sub-tools for writing the thesis.\n",
            "allowed-tools: No special permission is required to use this sub-skill.\n",
            "---\n",
            "These are a collection of sub-tools for writing a thesis.\n",
            "\n",
            "The thesis (/thesis) is created by dividing it into chapters, each in Markdown format. \n",
            "The thesis title is formatted with a single #, and chapter titles are formatted with ##, \n",
            "so please write using the appropriate hierarchy. \n",
            "Internal memory references like [memory:...] must NOT be included in the thesis. \n",
            "Therefore, please record reference URLs separately when storing data in memory.\n",
            "\n",
            "Chapters begin with Chapter 0, which is always designated as the Overview.\n",
            "\n",
            "## Sub-tools\n",
            "\n",
            "\n",
            "### Sub-tool: /thesis/write_title\n",
            "\n",
            "[Sub-tool Name] /thesis/write_title\n",
            "[Original Tool Name] thesis_write_title\n",
            "[Original Usage] thesis_write_title(new_title)\n",
            "[Description] Updates the title of the thesis.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/write_title\", {\"new_title\": ...})\n",
            "\n",
            "### Sub-tool: /thesis/show_title\n",
            "\n",
            "[Sub-tool Name] /thesis/show_title\n",
            "[Original Tool Name] thesis_show_title\n",
            "[Original Usage] thesis_show_title()\n",
            "[Description] Returns the current thesis title.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/show_title\", {})\n",
            "\n",
            "### Sub-tool: /thesis/new_chapter\n",
            "\n",
            "[Sub-tool Name] /thesis/new_chapter\n",
            "[Original Tool Name] thesis_new_chapter\n",
            "[Original Usage] thesis_new_chapter(title, text)\n",
            "[Description] Creates a new chapter with the given title and text content.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/new_chapter\", {\"title\": ..., \"text\": ...})\n",
            "\n",
            "### Sub-tool: /thesis/write_chapter\n",
            "\n",
            "[Sub-tool Name] /thesis/write_chapter\n",
            "[Original Tool Name] thesis_write_chapter\n",
            "[Original Usage] thesis_write_chapter(chapter_num, new_title, new_text)\n",
            "[Description] Replaces the content of an existing chapter with new_title and new_text.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/write_chapter\", {\"chapter_num\": ..., \"new_title\": ..., \"new_text\": ...})\n",
            "\n",
            "### Sub-tool: /thesis/delete_last_chapter\n",
            "\n",
            "[Sub-tool Name] /thesis/delete_last_chapter\n",
            "[Original Tool Name] thesis_delete_last_chapter\n",
            "[Original Usage] thesis_delete_last_chapter()\n",
            "[Description] Deletes the very last chapter of the thesis.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/delete_last_chapter\", {})\n",
            "\n",
            "### Sub-tool: /thesis/read_chapter\n",
            "\n",
            "[Sub-tool Name] /thesis/read_chapter\n",
            "[Original Tool Name] thesis_read_chapter\n",
            "[Original Usage] thesis_read_chapter(chapter_num)\n",
            "[Description] Reads the content of the specified chapter number.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/read_chapter\", {\"chapter_num\": ...})\n",
            "\n",
            "### Sub-tool: /thesis/list_chapters\n",
            "\n",
            "[Sub-tool Name] /thesis/list_chapters\n",
            "[Original Tool Name] thesis_list_chapters\n",
            "[Original Usage] thesis_list_chapters()\n",
            "[Description] Returns a list of all current chapter titles.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/list_chapters\", {})\n",
            "\n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_read with appropriate parameters.\n",
            "Tool result(memory_read): '{\"id\": \"memory:1000\", \"title\": \"Thesis Plan: Japan\\'s Lost Decades\", \"acces...'\n",
            "Agent response: {\"id\": \"memory:1000\", \"title\": \"Thesis Plan: Japan's Lost Decades\", \"accesses\": 4.0, \"text\": \"# Thesis Plan: Japan's Lost Decades - What Should Have Been Done\\n\\n## Phase 1: Information Gathering & Research\\n1. Identify the key economic, social, and political factors of Japan's \\\"Lost Decades\\\" (roughly 1991-2021).\\n2. Research the mainstream economic critiques (monetary policy, fiscal policy, structural reforms).\\n3. Investigate specific alternative proposals and \\\"what-if\\\" scenarios from economists (e.g., Paul Krugman, Richard Koo, Joseph Stiglitz).\\n4. Gather data on:\\n    - Asset bubble collapse (1991).\\n    - Banking crisis and delayed disposal of bad loans.\\n    - Monetary policy (interest rates, QE).\\n    - Fiscal policy (stimulus vs. austerity).\\n    - Structural issues (demographics, labor market rigidity).\\n\\n## Phase 2: Thesis Structure Definition\\n- **Chapter 0: Overview** (Summary of the thesis and core argument).\\n- **Chapter 1: The Anatomy of the Collapse** (Context of the bubble and the initial response).\\n- **Chapter 2: Monetary Policy Missteps and Corrections** (Discussion of the BoJ's actions).\\n- **Chapter 3: The Fiscal Dilemma** (Stimulus efficiency and the debt trap).\\n- **Chapter 4: Structural Barriers and Missed Opportunities** (Labor, innovation, and demographics).\\n- **Chapter 5: A Counterfactual Roadmap** (Consolidated recommendations on what should have been done).\\n- **Chapter 6: Conclusion** (Lessons for the future).\\n\\n## Phase 3: Writing & Review\\n1. Draft chapters sequentially.\\n2. Review for consistency and remove any internal memory references.\\n3. Finalize the thesis.\", \"modified_at\": \"2026-02-12T17:27:14.797162\"}\n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_read with appropriate parameters.\n",
            "Tool result(/thesis/read_chapter): '{\"title\": \"The Fiscal Dilemma: Multipliers and Debt Overhang\", \"text\": \"Jap...'\n",
            "Tool result(memory_read): '{\"id\": \"memory:1004\", \"title\": \"Research Log Phase 3: Structural Reforms\", ...'\n",
            "Agent response: \n",
            "USER_INPUT: While using various tools for assistance, eventually use subwork_done with appropriate parameters. (Auxiliary Prompt): Call subwork_done once you have finished researching one chapter.\n",
            "Tool(thesis_new_chapter): {'title': 'Structural Barriers and the Rigidity of the Japanese Model', 'tex...}\n",
            "Tool result(/thesis/new_chapter): 'Success: Created Chapter 4.'\n",
            "Tool result(duckduckgo_results_json): \"snippet: The Lost Decades are a lengthy period of economic stagnation in Ja...\"\n",
            "Tool result(duckduckgo_results_json): \"snippet: December 31, 2025 - The Lost Decades are a lengthy period of econo...\"\n",
            "Tool result(duckduckgo_results_json): 'snippet: December 31, 2025 - The Lost Decades are a lengthy period of econo...'\n",
            "Tool result(duckduckgo_results_json): \"snippet: 2002 Preventing deflation : lessons from Japan's experience in the...\"\n",
            "Tool(memory_new): {'id': 'memory:1005', 'title': 'Research Log: Counterfactual Scenarios', 'ac...}\n",
            "Tool result(memory_new): 'memory:1005'\n",
            "Tool(update_scratchpad): Scratchpad updated.: - Chapters 0-4 are finalized and stored in the /thesis sub-tool.\n",
            "- Chapter 5 research (Counterfactual Roadmap) is completed and stored in [memory:1005].\n",
            "- Next Step: Draft Chapter 5 using the synthesis in [memory:1005].\n",
            "- Chapter 6 (Conclusion) research is still needed.\n",
            "Tool result(update_scratchpad): 'Scratchpad updated.'\n",
            "Tool result(subwork_done): 'Success. Sub-task completion declared.'\n",
            "Agent response: \n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: Main Objective: \"Please summarize into a thesis what should have been done during Japan's 'lost decades'.\"\n",
            "Core Context: \"Thesis Plan: memory:1000\n",
            "Current Focus: Researching initial response to bubble collapse and banking crisis.\"\n",
            "Plan and Policy: \"Policy: \n",
            "1. Conduct deep research using DuckDuckGo and web content fetching to understand the economic nuances of Japan's Lost Decades.\n",
            "2. Store gathered information in memory with clear titles and reference URLs.\n",
            "3. Follow the chapter structure defined in [memory:1000].\n",
            "4. Use the /thesis sub-tools to build the document.\n",
            "\n",
            "Plan:\n",
            "- Step 1: Research the initial response to the bubble collapse (late 80s - early 90s).\n",
            "- Step 2: Research the banking crisis and the \"zombie company\" phenomenon.\n",
            "- Step 3: Research monetary policy debates (liquidity trap, QE).\n",
            "- Step 4: Write Chapter 0 (Overview).\n",
            "- Step 5: Write Chapter 1 (Anatomy of Collapse).\n",
            "- Step 6: Proceed through subsequent chapters.\n",
            "- Step 7: Final review and completion.\"\n",
            "Scratchpad: \"- Chapters 0-4 are finalized and stored in the /thesis sub-tool.\n",
            "- Chapter 5 research (Counterfactual Roadmap) is completed and stored in [memory:1005].\n",
            "- Next Step: Draft Chapter 5 using the synthesis in [memory:1005].\n",
            "- Chapter 6 (Conclusion) research is still needed.\"\n",
            "Please proceed while checking if necessary data is already recorded.\n",
            "Current Task or Sub-objective: \"Verify if the research data stored in memory is sufficient for all chapters.\"\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_read with appropriate parameters.\n",
            "Tool result(memory_read): '{\"id\": \"memory:1000\", \"title\": \"Thesis Plan: Japan\\'s Lost Decades\", \"acces...'\n",
            "Agent response: {\"id\": \"memory:1000\", \"title\": \"Thesis Plan: Japan's Lost Decades\", \"accesses\": 5.0, \"text\": \"# Thesis Plan: Japan's Lost Decades - What Should Have Been Done\\n\\n## Phase 1: Information Gathering & Research\\n1. Identify the key economic, social, and political factors of Japan's \\\"Lost Decades\\\" (roughly 1991-2021).\\n2. Research the mainstream economic critiques (monetary policy, fiscal policy, structural reforms).\\n3. Investigate specific alternative proposals and \\\"what-if\\\" scenarios from economists (e.g., Paul Krugman, Richard Koo, Joseph Stiglitz).\\n4. Gather data on:\\n    - Asset bubble collapse (1991).\\n    - Banking crisis and delayed disposal of bad loans.\\n    - Monetary policy (interest rates, QE).\\n    - Fiscal policy (stimulus vs. austerity).\\n    - Structural issues (demographics, labor market rigidity).\\n\\n## Phase 2: Thesis Structure Definition\\n- **Chapter 0: Overview** (Summary of the thesis and core argument).\\n- **Chapter 1: The Anatomy of the Collapse** (Context of the bubble and the initial response).\\n- **Chapter 2: Monetary Policy Missteps and Corrections** (Discussion of the BoJ's actions).\\n- **Chapter 3: The Fiscal Dilemma** (Stimulus efficiency and the debt trap).\\n- **Chapter 4: Structural Barriers and Missed Opportunities** (Labor, innovation, and demographics).\\n- **Chapter 5: A Counterfactual Roadmap** (Consolidated recommendations on what should have been done).\\n- **Chapter 6: Conclusion** (Lessons for the future).\\n\\n## Phase 3: Writing & Review\\n1. Draft chapters sequentially.\\n2. Review for consistency and remove any internal memory references.\\n3. Finalize the thesis.\", \"modified_at\": \"2026-02-12T17:27:14.797162\"}\n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_read with appropriate parameters.\n",
            "Tool result(memory_read): '{\"id\": \"memory:1004\", \"title\": \"Research Log Phase 3: Structural Reforms\", ...'\n",
            "Agent response: {\"id\": \"memory:1005\", \"title\": \"Research Log: Counterfactual Scenarios\", \"accesses\": 1.0, \"text\": \"Research for Chapter 5: A Counterfactual Roadmap.\\n\\nKey findings:\\n1. **Monetary Policy (Ahearne et al., 2002):** Analysis suggests that if the Bank of Japan had lowered interest rates by an additional 200 basis points starting in 1991, the deflationary spiral could have been averted. The delay in recognizing the depth of the crisis led to the Zero Lower Bound (ZLB) trap.\\n2. **Banking and NPLs:** A more aggressive cleanup of Non-Performing Loans (NPLs) in 1992-1993, supported by public fund injections (recapitalization), would have restored the credit mediation function of banks years earlier. The 1997-1998 banking crisis was a direct result of the \\\"Convoy System\\\" delaying this disposal.\\n3. **Fiscal Policy (Posen, 1998):** Adam Posen argued that fiscal stimulus was effective when actually implemented, but was often \\\"smoke and mirrors\\\" (announcement effects without real spending). A consistent, large-scale stimulus that avoided the 1997 tax hike would have bridged the gap in aggregate demand.\\n4. **Structural Timing:** Implementing labor market reforms (increasing mobility) in the early 90s, before the \\\"Lost Generation\\\" became entrenched, would have mitigated the long-term scarring of the workforce.\\n5. **Koo vs. Krugman:** Koo emphasizes that fiscal spending should have been maintained until private sectors started borrowing again, while Krugman emphasizes the need for an inflation target to lower real interest rates.\\n\\nReference URLs:\\n- https://ideas.repec.org/p/fip/fedgif/729.html (Ahearne et al., 2002)\\n- https://www.iie.com/publications/books/restoring-japans-economic-growth (Posen, 1998)\\n- https://www.investopedia.com/terms/b/balance-sheet-recession.asp (Koo's Framework)\", \"modified_at\": \"2026-02-12T17:37:58.950329\"}\n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_new OR memory_update_string OR memory_append_string (one of them) with appropriate parameters.\n",
            "Tool result(memory_append_string): \"Success: Appended text to memory ID 'memory:1005'.\"\n",
            "Agent response: \n",
            "USER_INPUT: While using various tools for assistance, eventually use subwork_done OR subwork_not_done (one of them) with appropriate parameters. (Auxiliary Prompt): Call subwork_done if research for all chapters is sufficient. Call subwork_not_done if you determine it is insufficient.\n",
            "Tool result(duckduckgo_results_json): \"snippet: The total amount of loans held by all banks as of the end of Septe...\"\n",
            "Tool result(duckduckgo_results_json): \"snippet: The total amount of loans held by all banks as of the end of Septe...\"\n",
            "Tool result(duckduckgo_results_json): \"snippet: Mar 9, 1999 . The 15 banks applying for public money will together...\"\n",
            "Tool result(subwork_done): 'Success. Sub-task completion declared.'\n",
            "Agent response: \n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: Main Objective: \"Please summarize into a thesis what should have been done during Japan's 'lost decades'.\"\n",
            "Core Context: \"Thesis Plan: memory:1000\n",
            "Current Focus: Researching initial response to bubble collapse and banking crisis.\"\n",
            "Plan and Policy: \"Policy: \n",
            "1. Conduct deep research using DuckDuckGo and web content fetching to understand the economic nuances of Japan's Lost Decades.\n",
            "2. Store gathered information in memory with clear titles and reference URLs.\n",
            "3. Follow the chapter structure defined in [memory:1000].\n",
            "4. Use the /thesis sub-tools to build the document.\n",
            "\n",
            "Plan:\n",
            "- Step 1: Research the initial response to the bubble collapse (late 80s - early 90s).\n",
            "- Step 2: Research the banking crisis and the \"zombie company\" phenomenon.\n",
            "- Step 3: Research monetary policy debates (liquidity trap, QE).\n",
            "- Step 4: Write Chapter 0 (Overview).\n",
            "- Step 5: Write Chapter 1 (Anatomy of Collapse).\n",
            "- Step 6: Proceed through subsequent chapters.\n",
            "- Step 7: Final review and completion.\"\n",
            "Scratchpad: \"- Chapters 0-4 are finalized and stored in the /thesis sub-tool.\n",
            "- Chapter 5 research (Counterfactual Roadmap) is completed and stored in [memory:1005].\n",
            "- Next Step: Draft Chapter 5 using the synthesis in [memory:1005].\n",
            "- Chapter 6 (Conclusion) research is still needed.\"\n",
            "Please proceed while checking if necessary data is already recorded.\n",
            "Current Task or Sub-objective: \"Write a chapter of the thesis (/thesis) that has not yet been written or is insufficient, based on the research data in memory. Note that Chapter 0 is designated as the Overview.\"\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_read with appropriate parameters. (Auxiliary Prompt): Please read memory:9998.\n",
            "Tool result(memory_read): '{\"id\": \"memory:9998\", \"title\": \"Procedure for searching memory documents\", ...'\n",
            "Agent response: {\"id\": \"memory:9998\", \"title\": \"Procedure for searching memory documents\", \"accesses\": 0.3, \"modified_at\": \"2023-01-01T00:00:00\", \"text\": \"First, use 'express_thought' to consider what kind of information you want to find.\\n\\nThen, associate related keywords using 'imagine_keywords'.\\n\\nFollowing those results, try 'memory_words_search' or 'memory_semantic_search'.\\n\"}\n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_read with appropriate parameters.\n",
            "Tool result(memory_read): '{\"id\": \"memory:1000\", \"title\": \"Thesis Plan: Japan\\'s Lost Decades\", \"acces...'\n",
            "Agent response: \n",
            "USER_INPUT: While using various tools for assistance, eventually use subwork_done with appropriate parameters. (Auxiliary Prompt): Call subwork_done once you have written one chapter of a high-quality thesis.\n",
            "Tool(express_thought): Thought expressed: \"I need to clarify the structure of the remaining chapters. According to the summary, Chapter 5 should cover the 1997 Banking Crisis and the 1998 interventions. However, the scratchpad mentions Chapter 5 as the 'Counterfactual Roadmap'. I will check [memory:1000] to ensure the chapter numbering matches the intended outline before writing. Once confirmed, I will draft the next chapter using the sub-tools.\"\n",
            "Tool result(express_thought): 'null'\n",
            "Tool result(memory_read): '{\"id\": \"memory:1000\", \"title\": \"Thesis Plan: Japan\\'s Lost Decades\", \"acces...'\n",
            "Tool result(subtool_show): '---\\nname: /thesis\\ndescription: Sub-tools for writing the thesis.\\nallowed...'\n",
            "Tool result(/thesis/list_chapters): '[\"Overview\", \"The Anatomy of the Collapse\", \"Monetary Policy and the Liquid...'\n",
            "Tool result(memory_read): '{\"id\": \"memory:1001\", \"title\": \"Research Data: Japan Lost Decades Phase 1\",...'\n",
            "Tool result(memory_read): '{\"id\": \"memory:1005\", \"title\": \"Research Log: Counterfactual Scenarios\", \"a...'\n",
            "Tool(thesis_show_title): Alternative Economic and Policy Measures for Japan's Lost Decades\n",
            "Tool result(/thesis/show_title): \"Alternative Economic and Policy Measures for Japan's Lost Decades\"\n",
            "Tool result(memory_read): '{\"id\": \"memory:1004\", \"title\": \"Research Log Phase 3: Structural Reforms\", ...'\n",
            "Tool result(duckduckgo_results_json): 'snippet: The FRC is set to approve the infusion of 7.46 trillion yen into t...'\n",
            "Recursion Limit reached.\n",
            "USER_INPUT: The previous instruction has not been completed yet. Previous instruction: While using various tools for assistance, eventually use subwork_done with appropriate parameters. (Auxiliary Prompt): Call subwork_done once you have written one chapter of a high-quality thesis.\n",
            "Tool(thesis_new_chapter): {'title': 'A Counterfactual Roadmap', 'text': '## Chapter 5: A Counterfactua...}\n",
            "Tool result(/thesis/new_chapter): 'Success: Created Chapter 5.'\n",
            "Tool result(subwork_done): 'Success. Sub-task completion declared.'\n",
            "Agent response: Success. Sub-task completion declared.\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: Main Objective: \"Please summarize into a thesis what should have been done during Japan's 'lost decades'.\"\n",
            "Core Context: \"Thesis Plan: memory:1000\n",
            "Current Focus: Researching initial response to bubble collapse and banking crisis.\"\n",
            "Plan and Policy: \"Policy: \n",
            "1. Conduct deep research using DuckDuckGo and web content fetching to understand the economic nuances of Japan's Lost Decades.\n",
            "2. Store gathered information in memory with clear titles and reference URLs.\n",
            "3. Follow the chapter structure defined in [memory:1000].\n",
            "4. Use the /thesis sub-tools to build the document.\n",
            "\n",
            "Plan:\n",
            "- Step 1: Research the initial response to the bubble collapse (late 80s - early 90s).\n",
            "- Step 2: Research the banking crisis and the \"zombie company\" phenomenon.\n",
            "- Step 3: Research monetary policy debates (liquidity trap, QE).\n",
            "- Step 4: Write Chapter 0 (Overview).\n",
            "- Step 5: Write Chapter 1 (Anatomy of Collapse).\n",
            "- Step 6: Proceed through subsequent chapters.\n",
            "- Step 7: Final review and completion.\"\n",
            "Scratchpad: \"- Chapters 0-4 are finalized and stored in the /thesis sub-tool.\n",
            "- Chapter 5 research (Counterfactual Roadmap) is completed and stored in [memory:1005].\n",
            "- Next Step: Draft Chapter 5 using the synthesis in [memory:1005].\n",
            "- Chapter 6 (Conclusion) research is still needed.\"\n",
            "Please proceed while checking if necessary data is already recorded.\n",
            "Current Task or Sub-objective: \"Check if all chapters of the thesis (/thesis) based on the research data are completed. Finally, set the title and rewrite the overview in Chapter 0.\"\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "USER_INPUT: While using various tools for assistance, eventually use subtool_show with appropriate parameters. (Auxiliary Prompt): Please read the skill for /thesis.\n",
            "Tool result(subtool_show): '---\\nname: /thesis\\ndescription: Sub-tools for writing the thesis.\\nallowed...'\n",
            "Agent response: ---\n",
            "name: /thesis\n",
            "description: Sub-tools for writing the thesis.\n",
            "allowed-tools: No special permission is required to use this sub-skill.\n",
            "---\n",
            "These are a collection of sub-tools for writing a thesis.\n",
            "\n",
            "The thesis (/thesis) is created by dividing it into chapters, each in Markdown format. \n",
            "The thesis title is formatted with a single #, and chapter titles are formatted with ##, \n",
            "so please write using the appropriate hierarchy. \n",
            "Internal memory references like [memory:...] must NOT be included in the thesis. \n",
            "Therefore, please record reference URLs separately when storing data in memory.\n",
            "\n",
            "Chapters begin with Chapter 0, which is always designated as the Overview.\n",
            "\n",
            "## Sub-tools\n",
            "\n",
            "\n",
            "### Sub-tool: /thesis/write_title\n",
            "\n",
            "[Sub-tool Name] /thesis/write_title\n",
            "[Original Tool Name] thesis_write_title\n",
            "[Original Usage] thesis_write_title(new_title)\n",
            "[Description] Updates the title of the thesis.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/write_title\", {\"new_title\": ...})\n",
            "\n",
            "### Sub-tool: /thesis/show_title\n",
            "\n",
            "[Sub-tool Name] /thesis/show_title\n",
            "[Original Tool Name] thesis_show_title\n",
            "[Original Usage] thesis_show_title()\n",
            "[Description] Returns the current thesis title.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/show_title\", {})\n",
            "\n",
            "### Sub-tool: /thesis/new_chapter\n",
            "\n",
            "[Sub-tool Name] /thesis/new_chapter\n",
            "[Original Tool Name] thesis_new_chapter\n",
            "[Original Usage] thesis_new_chapter(title, text)\n",
            "[Description] Creates a new chapter with the given title and text content.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/new_chapter\", {\"title\": ..., \"text\": ...})\n",
            "\n",
            "### Sub-tool: /thesis/write_chapter\n",
            "\n",
            "[Sub-tool Name] /thesis/write_chapter\n",
            "[Original Tool Name] thesis_write_chapter\n",
            "[Original Usage] thesis_write_chapter(chapter_num, new_title, new_text)\n",
            "[Description] Replaces the content of an existing chapter with new_title and new_text.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/write_chapter\", {\"chapter_num\": ..., \"new_title\": ..., \"new_text\": ...})\n",
            "\n",
            "### Sub-tool: /thesis/delete_last_chapter\n",
            "\n",
            "[Sub-tool Name] /thesis/delete_last_chapter\n",
            "[Original Tool Name] thesis_delete_last_chapter\n",
            "[Original Usage] thesis_delete_last_chapter()\n",
            "[Description] Deletes the very last chapter of the thesis.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/delete_last_chapter\", {})\n",
            "\n",
            "### Sub-tool: /thesis/read_chapter\n",
            "\n",
            "[Sub-tool Name] /thesis/read_chapter\n",
            "[Original Tool Name] thesis_read_chapter\n",
            "[Original Usage] thesis_read_chapter(chapter_num)\n",
            "[Description] Reads the content of the specified chapter number.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/read_chapter\", {\"chapter_num\": ...})\n",
            "\n",
            "### Sub-tool: /thesis/list_chapters\n",
            "\n",
            "[Sub-tool Name] /thesis/list_chapters\n",
            "[Original Tool Name] thesis_list_chapters\n",
            "[Original Usage] thesis_list_chapters()\n",
            "[Description] Returns a list of all current chapter titles.\n",
            "\n",
            "*Note: To execute this tool, do not call it directly. You must use subtool_do as shown below:*\n",
            "[Correct Usage] subtool_do(\"/thesis/list_chapters\", {})\n",
            "\n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_read with appropriate parameters.\n",
            "Tool result(memory_read): '{\"id\": \"memory:1000\", \"title\": \"Thesis Plan: Japan\\'s Lost Decades\", \"acces...'\n",
            "Agent response: \n",
            "USER_INPUT: While using various tools for assistance, eventually use memory_new OR memory_update_string OR memory_append_string (one of them) with appropriate parameters.\n",
            "Tool result(/thesis/list_chapters): '[\"Overview\", \"The Anatomy of the Collapse\", \"Monetary Policy and the Liquid...'\n",
            "Tool result(memory_read): '{\"id\": \"memory:1000\", \"title\": \"Thesis Plan: Japan\\'s Lost Decades\", \"acces...'\n",
            "USER_INPUT2: Simulate a full-text search across all memories with search_str = 'lessons OR future OR conclusion'. \n",
            "Support OR and parentheses logic.\n",
            "Use actual memory data obtained from 'read_all_memories' or 'read_all_keywords'.\n",
            "Return results using the 'set_result' tool.\n",
            "\n",
            "Status: 'error' or 'success'\n",
            "Result: List of Match data (m) dictionaries:\n",
            "  m['id']: Memory ID (memory:...)\n",
            "  m['title']: Memory Title\n",
            "  m['snippet']: Contextual snippet of text surrounding the match.\n",
            "\n",
            "Tool2(read_all_memories): Retrieving all data...\n",
            "Tool result 2(read_all_memories): '{\"status\": \"success\", \"result\": [{\"id\": \"memory:9998\", \"title\": \"Procedure ...'\n",
            "Tool2(read_all_keywords): Retrieving all keywords...\n",
            "Tool result 2(read_all_keywords): '{\"status\": \"success\", \"result\": [\"... : Specify keywords related to that me...'\n",
            "Tool2(set_result): status: 'success', result: [{'snippet': '...Note that keywords can effectively serve as links to future...]\n",
            "Tool result 2(set_result): 'null'\n",
            "Sub-Agent response: null\n",
            "Tool result(memory_words_search): '{\"status\": \"success\", \"result\": [{\"snippet\": \"...Note that keywords can eff...'\n",
            "Tool result(memory_read): '{\"id\": \"memory:1001\", \"title\": \"Research Data: Japan Lost Decades Phase 1\",...'\n",
            "Tool result(duckduckgo_results_json): 'snippet: Japan\\'s economic crisis, known as the \" Lost Decade ,\" began in t...'\n",
            "Tool(thesis_new_chapter): {'title': 'Conclusion: Lessons for the Global Economy', 'text': '## Chapter ...}\n",
            "Tool result(/thesis/new_chapter): 'Success: Created Chapter 6.'\n",
            "Tool result(/thesis/read_chapter): '{\"title\": \"Overview\", \"text\": \"\"}'\n",
            "Tool result(/thesis/write_chapter): 'Error: Invalid argument format.\\nDetails: [{\\'type\\': \\'missing\\', \\'loc\\':...'\n",
            "Recursion Limit reached.\n",
            "USER_INPUT: While using various tools for assistance, eventually use subwork_done OR subwork_not_done (one of them) with appropriate parameters. (Auxiliary Prompt): Call subwork_done once all chapters are written, the title is set, and the overview is rewritten. Call subwork_not_done if all chapters are not yet written.\n",
            "Tool(thesis_write_chapter): {'title': 'Overview', 'text': '## Chapter 0: Overview\\n\\nThis thesis investi...}\n",
            "Tool result(/thesis/write_chapter): 'Success: Rewrote Chapter 0.'\n",
            "Tool result(/thesis/set_title): \"Error: Sub-tool '/thesis/set_title' not found.\"\n",
            "Tool result(subtool_show): '---\\nname: /thesis\\ndescription: Sub-tools for writing the thesis.\\nallowed...'\n",
            "Tool(thesis_write_title): Thesis title has been updated.: Alternative Economic and Policy Measures for Japan's Lost Decades\n",
            "Tool result(/thesis/write_title): 'Thesis title has been updated.'\n",
            "Tool result(/thesis/list_chapters): '[\"Overview\", \"The Anatomy of the Collapse\", \"Monetary Policy and the Liquid...'\n",
            "Tool result(subwork_done): 'Success. Sub-task completion declared.'\n",
            "Agent response: \n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If it hangs after `get_web_page_content`, stop it and call `resume()`. For some reason, this happens very rarely. It was not necessary this time."
      ],
      "metadata": {
        "id": "gmjJCrytrnac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.resume()"
      ],
      "metadata": {
        "id": "agn_VTxkrtBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The completed thesis."
      ],
      "metadata": {
        "id": "D10aGpKSC80m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.display_thesis()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l25N4K847YVe",
        "outputId": "7485a6d0-6730-4421-a9a3-54235174b8f4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Alternative Economic and Policy Measures for Japan's Lost Decades\n\n## Chapter 0: Overview\n\nThis thesis investigates the causes, consequences, and missed opportunities of Japan's \"Lost Decades\"—the period of economic stagnation that followed the collapse of the asset price bubble in the early 1990s. While the crisis is often attributed to external shocks or demographic shifts, this work argues that the primary drivers were institutional rigidities and delayed policy responses.\n\nThe study employs a counterfactual framework to analyze how alternative fiscal, monetary, and structural interventions could have fundamentally altered Japan's economic trajectory.\n\n### Structure of the Thesis\n*   **Chapter 1 (Anatomy of the Collapse):** Traces the origins of the 1980s bubble and the immediate policy failures following its 1991 burst.\n*   **Chapter 2 (Monetary Policy):** Analyzes the Bank of Japan's delayed response and the subsequent descent into a liquidity trap.\n*   **Chapter 3 (The Fiscal Dilemma):** Examines the efficacy of public works spending versus the burden of rising national debt.\n*   **Chapter 4 (Structural Barriers):** Investigates the \"Membership Model\" of labor and the \"Convoy System\" in finance that hindered modernization.\n*   **Chapter 5 (A Counterfactual Roadmap):** Presents a \"what-if\" scenario where aggressive intervention in the early 1990s prevents the long-term stagnation.\n*   **Chapter 6 (Conclusion):** Synthesizes the findings and discusses the broader lessons for global economies facing similar deflationary pressures today.\n\nThe central thesis is that Japan’s stagnation was not an inevitable fate but a policy-induced malaise. By examining these failures, we can derive critical lessons for avoiding the \"Japanification\" of the global economy.\n\n\n## Chapter 1: The Anatomy of the Collapse\n\nThe collapse of the Japanese asset price bubble in the early 1990s was not merely a market correction but a systemic failure that exposed deep structural flaws in the nation's financial and regulatory architecture. \n\n### The Height of Exuberance\nAt the end of December 1989, the Nikkei 225 Stock Average reached an all-time high of 38,957.44. Real estate prices in Tokyo were so inflated that the land under the Imperial Palace was famously said to be worth more than all the land in California. This period was characterized by aggressive corporate expansion and speculative lending, fueled by low interest rates and a belief in the \"land myth\"—the idea that Japanese property values would never decrease.\n\n### The Trigger: Monetary Tightening\nThe Bank of Japan, under Governor Yasushi Mieno, began a series of aggressive interest rate hikes starting in late 1989 to curb inflation and cool the overheated markets. By August 1990, the official discount rate had risen to 6.0%. While these measures were intended to orchestrate a \"soft landing,\" they instead triggered a precipitous crash. By 1992, the Nikkei had lost over 60% of its value, and land prices began a multi-decade decline.\n\n### The Institutional Failure: The \"Convoy System\"\nThe most critical failure during the immediate post-bubble years was the Ministry of Finance's \"convoy system\" (Goso Sendan). This regulatory approach aimed to ensure that no bank or financial institution would fail. Instead of forcing banks to recognize and write off bad loans, the ministry encouraged \"evergreening\"—providing more loans to insolvent borrowers to keep them from defaulting. This preserved \"zombie firms\" and prevented the creative destruction necessary for economic renewal.\n\n### The Policy Delay (1991–1994)\nThroughout the early 1990s, policymakers operated under the assumption that the downturn was a cyclical recession. Consequently, fiscal and monetary responses were reactive rather than proactive. The delay in recapitalizing the banking sector until the late 1990s allowed the bad debt problem to metastasize, turning a sharp correction into a chronic stagnation.\n\n## Chapter 2: Monetary Policy and the Liquidity Trap\n\nBy the mid-1990s, the Bank of Japan (BoJ) found itself in uncharted territory as short-term interest rates approached the zero lower bound. This chapter examines the theoretical and practical challenges of conducting monetary policy in a liquidity trap.\n\n### The Liquidity Trap and Real Interest Rates\nAs Paul Krugman argued in 1998, a liquidity trap occurs when nominal interest rates are so low that they cannot be reduced further, yet the economy remains depressed. In Japan's case, persistent deflationary expectations meant that even with a nominal rate near zero, the real interest rate (nominal rate minus inflation) remained too high to stimulate investment.\n\n### \"Self-Induced Paralysis\"\nBen Bernanke (1999) criticized the BoJ for what he termed \"self-induced paralysis.\" He argued that the BoJ had the tools to combat deflation but lacked the will to use them aggressively. Bernanke suggested that the central bank should have committed to a clear inflation target and engaged in large-scale asset purchases (Quantitative Easing) much earlier.\n\n### The Delayed Shift to QE\nThe BoJ finally introduced the Zero Interest Rate Policy (ZIRP) in 1999, but prematurely ended it in August 2000, only to reintroduce it and launch Quantitative Easing (QE) in 2001. This \"stop-and-go\" approach failed to anchor inflation expectations, as the public remained skeptical of the bank's commitment to ending deflation.\n\n### Counterfactual Analysis\nIf the BoJ had adopted an explicit 2-3% inflation target in 1992-1993 and aggressively expanded its balance sheet then, the real interest rate might have turned negative early enough to prevent the entrenchment of a deflationary mindset.\n\n## Chapter 3: The Fiscal Dilemma: Multipliers and Debt Overhang\n\nJapan's fiscal policy during the 1990s is often characterized by massive public works spending that failed to achieve sustainable growth. This chapter analyzes the efficacy of these stimulus packages through the lens of the \"Balance Sheet Recession.\"\n\n### The Balance Sheet Recession\nRichard Koo (2003) posits that the post-bubble downturn was not a standard business cycle recession but a balance sheet recession. Following the asset price collapse, Japanese firms shifted their priority from profit maximization to debt minimization (deleveraging). Consequently, even with zero interest rates, the private sector was not borrowing, leading to a massive drain on aggregate demand.\n\n### The Role of Government as Borrower of Last Resort\nIn Koo's framework, the government must step in as the \"borrower of last resort\" to recycle the private sector's excess savings back into the economy. While the Japanese government did run large deficits, the spending was often erratic and uncoordinated.\n\n### The 1997 Austerity Mistake\nThe most significant fiscal policy error occurred in 1997 when the Hashimoto administration, concerned about the rising national debt, increased the consumption tax from 3% to 5% and cut spending. This premature austerity triggered a severe contraction and a banking crisis, demonstrating that fiscal consolidation during a balance sheet recession is counterproductive.\n\n### Inefficiency of Public Works\nThe stimulus was heavily tilted toward traditional infrastructure projects in rural areas, which had low marginal productivity. Research indicates that the fiscal multiplier for these projects declined significantly during the 1990s due to the overhang of corporate debt and the lack of structural reform, which meant that government spending was \"filling a hole\" rather than \"building a bridge\" to future growth.\n\n## Chapter 4: Structural Barriers and the Rigidity of the Japanese Model\n\nWhile monetary and fiscal policies were central to the debate, Japan's \"Lost Decades\" were also characterized by deep-seated structural rigidities that hindered economic adjustment. This chapter examines the institutional barriers in the labor market and the corporate sector that stifled productivity and innovation.\n\n### Labor Market Rigidity: The Membership Model\nThe Japanese labor market was built on the \"three pillars\" of industrial relations: lifetime employment (shushin koyo), seniority-based wages (nenko joretsu), and enterprise unionism. While these provided stability during the high-growth era, they became liabilities during the 1990s.\n- **Internal Unemployment:** Instead of laying off workers, firms retained redundant staff to honor lifetime employment commitments. This \"internal unemployment\" suppressed productivity and prevented the reallocation of human capital to emerging sectors.\n- **Dual Labor Market:** To maintain flexibility, firms increasingly turned to \"non-regular\" workers (part-time, contract). This created a dual labor market where a segment of the workforce lacked job security and training opportunities, suppressing long-term human capital development.\n\n### The Keiretsu System and \"Zombie\" Firms\nThe \"Convoy System\" (goso sendan), where the Ministry of Finance and major banks coordinated to ensure no financial institution failed, extended into the corporate sector through the keiretsu system.\n- **Interlocking Shareholdings:** Cross-shareholding insulated management from shareholder pressure, reducing the incentive for efficiency and Return on Equity (ROE).\n- **The Zombie Problem:** Main banks often extended \"evergreen\" loans to insolvent member firms to avoid recognizing non-performing loans (NPLs). These \"zombie firms\" crowded out healthy companies by locking up capital and labor in unproductive activities, a phenomenon that significantly contributed to the stagnation of the 1990s.\n\n### Innovation and the Digital Divide\nJapan's traditional strength in hardware and incremental manufacturing (kaizen) did not translate well to the software-driven \"New Economy\" of the 1990s. Institutional barriers, such as a lack of venture capital and a social stigma against failure, discouraged entrepreneurship. The delay in deregulating the telecommunications and service sectors further hindered the adoption of Information and Communication Technology (ICT), leaving Japan behind in the global digital transition.\n\n### The Delay in Financial Structural Reform\nIt was not until the \"Big Bang\" reforms of 1996 and the creation of the Financial Services Agency (FSA) in 1998 that the government moved decisively toward a market-oriented financial system. The decade-long delay in addressing the NPL problem meant that the credit mediation function of the banking system remained impaired throughout the 1990s, nullifying the effects of monetary easing.\n\n## Chapter 5: A Counterfactual Roadmap\n\nThe economic stagnation of Japan’s \"Lost Decades\" was not an inevitable outcome of the asset bubble’s collapse, but rather the result of a series of policy delays and institutional rigidities. By synthesizing the theoretical frameworks of the liquidity trap, balance sheet recession, and structural inertia, this chapter outlines a counterfactual roadmap—a \"what should have been done\" scenario—that could have significantly mitigated the depth and duration of the crisis.\n\n### 5.1 Early and Aggressive Monetary Intervention\nThe Bank of Japan’s (BoJ) cautious approach in the early 1990s is often cited as a primary driver of the subsequent deflationary spiral. Counterfactual analysis suggests that a more proactive stance could have altered the economic trajectory.\n\n*   **The 200-Basis-Point Rule:** Research indicates that if the BoJ had lowered interest rates by an additional 200 basis points as early as 1991, the economy might have avoided the zero lower bound (ZLB) trap. By the time the BoJ began aggressive cuts, the \"liquidity trap\" had already taken hold, rendering traditional interest rate adjustments ineffective.\n*   **Inflation Targeting:** Instead of reacting to price drops, an early commitment to a positive inflation target (e.g., 2%) would have anchored expectations and prevented the rise in real interest rates that stifled investment and consumption.\n\n### 5.2 Decisive Banking Reform and the End of the \"Convoy System\"\nThe \"Convoy System\" (goso sendan), which protected weak banks at the expense of the entire system, was the single greatest barrier to recovery. A counterfactual roadmap would have prioritized a \"shock therapy\" approach to the banking sector.\n\n*   **Early Recapitalization (1992-1993):** Rather than waiting for the systemic crisis of 1997-1998, the Japanese government should have injected public funds into major banks by 1992. Forced recognition of non-performing loans (NPLs) at this stage would have cleaned balance sheets before the credit crunch became terminal.\n*   **Institutional Independence:** The creation of an independent oversight body, similar to the Financial Services Agency (FSA), should have occurred in the early 90s. Removing bank supervision from the Ministry of Finance (MoF) would have broken the traditionalist \"forbearance\" cycle earlier, facilitating the 2003-style \"Takenaka Plan\" reforms a decade sooner.\n\n### 5.3 Fiscal Consistency vs. Premature Austerity\nJapan’s fiscal policy was often criticized for being \"too little, too late\" or, conversely, for being \"smoke and mirrors.\" A more effective counterfactual strategy would have focused on the quality and timing of spending.\n\n*   **Avoiding the 1997 Tax Hike:** The decision to increase the consumption tax from 3% to 5% in April 1997 is widely regarded as a critical error. In a counterfactual scenario, maintaining fiscal support until a self-sustaining recovery was evident—as argued by Richard Koo—would have prevented the 1997 recession and the subsequent banking collapse.\n*   **High-Multiplier Investments:** Instead of low-utility rural public works, fiscal stimulus should have been directed toward urban infrastructure, R&D, and social safety nets that encouraged labor mobility and consumer confidence.\n\n### 5.4 Labor Mobility and Social Scaffolding\nThe \"Membership Model\" of labor provided stability for some but created a rigid, dual labor market that penalized the youth.\n\n*   **Proactive Reform:** Implementing labor market flexibility in the early 1990s—combined with a robust, portable social safety net—would have prevented the \"Employment Ice Age.\" By facilitating the transition of workers from declining industries to emerging sectors, Japan could have maintained higher productivity levels and avoided the demographic \"scarring\" of the Lost Generation.\n\n### Summary of the Counterfactual Path\nIf Japan had combined a 1991 rate cut, a 1992 bank recapitalization, and a consistent fiscal policy that avoided the 1997 tax hike, the \"Lost Decades\" might have been reduced to a \"Lost Five Years.\" The synthesis of these measures suggests that the cost of early, aggressive intervention—though politically difficult—would have been far lower than the decades of stagnation and the 61 trillion yen eventually required for NPL disposal.\n\n\n## Chapter 6: Conclusion: Lessons for the Global Economy\n\nThe economic history of Japan from 1991 to the present serves as a monumental case study in the risks of policy hesitation and structural inertia. While often described as a \"lost\" period, it is more accurately a period of profound learning that has reshaped modern macroeconomics. The preceding chapters have demonstrated that the crisis was not merely a financial collapse, but a systemic failure of the \"Japanese Model\" to adapt to a post-bubble reality.\n\n### 6.1 Summary of Findings\nThis thesis has argued that the severity of Japan's stagnation was preventable. Key findings include:\n*   **The Cost of Forbearance:** The \"convoy system\" of banking governance and the Ministry of Finance's policy of forbearance allowed \"zombie firms\" to survive, stifling the \"creative destruction\" necessary for a healthy economy.\n*   **The Monetary Lag:** Delayed interest rate cuts and the failure to manage inflation expectations allowed Japan to fall into a liquidity trap that rendered subsequent interventions far less effective.\n*   **Structural Mismatch:** The \"Membership Model\" of labor, while providing social stability, created a rigid dual labor market that hindered the transition of resources into high-productivity sectors.\n*   **Counterfactual Efficacy:** As demonstrated in Chapter 5, early recapitalization of banks and aggressive, consistent monetary expansion could have truncated the crisis by a decade or more.\n\n### 6.2 Global Implications: A Cautionary Tale\nThe lessons of Japan’s Lost Decades have become central to the policy frameworks of other major economies.\n*   **Post-2008 Western Response:** The swift actions of the US Federal Reserve and the European Central Bank following the 2008 financial crisis—characterized by massive, early QE and bank stress tests—were direct attempts to avoid the \"Japanese path.\"\n*   **The China Parallel:** Today, China faces strikingly similar challenges: a property bubble collapse, an aging population, and high levels of local government debt. The Japanese experience suggests that China must prioritize the transparent disposal of bad debt over the preservation of weak corporate entities.\n*   **The Danger of \"Japanification\":** The term \"Japanification\" now describes a state of permanent low growth, low inflation, and high debt. It serves as a reminder that once deflationary expectations take root, they are extraordinarily difficult to reverse.\n\n### 6.3 Final Thoughts\nThe primary lesson of Japan's experience is that in the face of a balance sheet recession, policy speed and scale are more important than policy precision. To prevent stagnation, a nation must be willing to dismantle the very institutions—be they lifetime employment or protected banking cartels—that provided the foundation for its previous success. Japan’s recovery, though slow, eventually came through the forced recognition of these structural realities. For the rest of the world, the \"Lost Decades\" remain the ultimate warning against the comfort of the status quo.\n\n\n"
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems to be mostly completed correctly this time."
      ],
      "metadata": {
        "id": "GYnhCVu678YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.listen_and_print(\"This was an experiment to have a RAG task performed within the MemoryBanditWorkflow framework. I believe we have successfully achieved a proof of concept. Gemini, how did you find using these tools this time? In particular, how was the experience of using the /thesis sub-tool?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "hhVroKo17adV",
        "outputId": "f5f37de8-66e9-4c2e-ee56-e7a4067ce565"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USER_INPUT: This was an experiment to have a RAG task performed within the MemoryBanditWorkflow framework. I believe we have successfully achieved a proof of concept. Gemini, how did you find using these tools this time? In particular, how was the experience of using the /thesis sub-tool?\n",
            "Agent response: The experiment was highly effective, and the toolset provided a robust framework for managing a complex, multi-stage task. Here are my specific impressions of the experience:\n",
            "\n",
            "### 1. Structural Modularity of the `/thesis` Sub-tool\n",
            "The `/thesis` sub-tool is excellent for long-form content generation. Unlike standard RAG tasks where an LLM might struggle with the context window when writing 10,000+ words at once, this sub-tool allows for a **modular approach**.\n",
            "*   **Context Control:** Being able to `read_chapter` selectively means I could focus on the \"Fiscal Dilemma\" while keeping the \"Monetary Policy\" chapter in \"storage,\" preventing the context window from becoming cluttered with redundant information.\n",
            "*   **State Management:** The `list_chapters` tool acted as a real-time table of contents, which is vital for maintaining narrative flow across multiple turns.\n",
            "\n",
            "### 2. The \"Sub-tool Discovery\" Workflow\n",
            "I found the `subtool_show(\"/\")` and `subtool_show(\"/thesis\")` pattern to be very natural. Even when I made an error (e.g., guessing `set_title` instead of the correct `write_title`), the ability to quickly query the tool definitions allowed for immediate self-correction. This makes the system resilient to minor \"memory lapses\" regarding specific tool syntax.\n",
            "\n",
            "### 3. Integration with Memory IDs\n",
            "Using `memory:9999` and `memory:1001` to store data and reference URLs separately from the final text is a sophisticated way to handle **provenance**. It ensures that the final output (the thesis) remains academic and clean, while the \"working memory\" retains all the technical scaffolding and source materials.\n",
            "\n",
            "### 4. Observations on the Counterfactual Framework\n",
            "The tools facilitated the \"what-if\" logic well. By treating the thesis as a series of files, I could treat Chapter 5 (the counterfactual) as a synthesis of the historical data gathered in Chapters 1–4. The framework allowed for a clear distinction between **historical research** and **logical modeling**.\n",
            "\n",
            "### Final Conclusion on the POC\n",
            "The **MemoryBanditWorkflow** successfully transforms an LLM from a \"chat interface\" into a \"workspace agent.\" The `/thesis` sub-tool, in particular, is a powerful template for any task requiring high-volume, structured output. It turns a \"writing task\" into a \"content management task,\" which significantly reduces the cognitive load on the agent and improves the coherence of the final product.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The experiment was highly effective, and the toolset provided a robust framework for managing a complex, multi-stage task. Here are my specific impressions of the experience:\\n\\n### 1. Structural Modularity of the `/thesis` Sub-tool\\nThe `/thesis` sub-tool is excellent for long-form content generation. Unlike standard RAG tasks where an LLM might struggle with the context window when writing 10,000+ words at once, this sub-tool allows for a **modular approach**.\\n*   **Context Control:** Being able to `read_chapter` selectively means I could focus on the \"Fiscal Dilemma\" while keeping the \"Monetary Policy\" chapter in \"storage,\" preventing the context window from becoming cluttered with redundant information.\\n*   **State Management:** The `list_chapters` tool acted as a real-time table of contents, which is vital for maintaining narrative flow across multiple turns.\\n\\n### 2. The \"Sub-tool Discovery\" Workflow\\nI found the `subtool_show(\"/\")` and `subtool_show(\"/thesis\")` pattern to be very natural. Even when I made an error (e.g., guessing `set_title` instead of the correct `write_title`), the ability to quickly query the tool definitions allowed for immediate self-correction. This makes the system resilient to minor \"memory lapses\" regarding specific tool syntax.\\n\\n### 3. Integration with Memory IDs\\nUsing `memory:9999` and `memory:1001` to store data and reference URLs separately from the final text is a sophisticated way to handle **provenance**. It ensures that the final output (the thesis) remains academic and clean, while the \"working memory\" retains all the technical scaffolding and source materials.\\n\\n### 4. Observations on the Counterfactual Framework\\nThe tools facilitated the \"what-if\" logic well. By treating the thesis as a series of files, I could treat Chapter 5 (the counterfactual) as a synthesis of the historical data gathered in Chapters 1–4. The framework allowed for a clear distinction between **historical research** and **logical modeling**.\\n\\n### Final Conclusion on the POC\\nThe **MemoryBanditWorkflow** successfully transforms an LLM from a \"chat interface\" into a \"workspace agent.\" The `/thesis` sub-tool, in particular, is a powerful template for any task requiring high-volume, structured output. It turns a \"writing task\" into a \"content management task,\" which significantly reduces the cognitive load on the agent and improves the coherence of the final product.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If an error occurs in `listen_and_print`, execute the following command. It seems it was not needed this time."
      ],
      "metadata": {
        "id": "oG83C0L899hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent._sanitize_messages()"
      ],
      "metadata": {
        "id": "mGPmQnFu5Jq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A final greeting.\n"
      ],
      "metadata": {
        "id": "SlOtzbc8BrIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.listen_and_print(\"Thank you very much. Goodbye.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "8b-DukgS87gO",
        "outputId": "03b21f9b-07f1-4f48-b513-bc3fd0c769c0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USER_INPUT: Thank you very much. Goodbye.\n",
            "Agent response: It has been a pleasure working on this project. The successful completion of the thesis \"Alternative Economic and Policy Measures for Japan's Lost Decades\" demonstrates the strength of the **MemoryBanditWorkflow** in handling structured, academic-grade content generation.\n",
            "\n",
            "### Current Status\n",
            "- **Thesis Title:** Alternative Economic and Policy Measures for Japan's Lost Decades\n",
            "- **Chapters:** 7 total (Chapter 0 through Chapter 6), finalized and stored.\n",
            "- **Data Persistence:** Research URLs and policy data are preserved in [memory:1001].\n",
            "\n",
            "### Policy for Future Sessions\n",
            "Should this project be resumed:\n",
            "1.  **Verification:** Run `/thesis/list_chapters` to confirm the presence of all 7 sections.\n",
            "2.  **Expansion:** If additional depth is required (e.g., a chapter on specific regional impacts), use `/thesis/new_chapter`.\n",
            "3.  **Refinement:** Use `/thesis/read_chapter` to extract content for peer-review simulations or further data integration.\n",
            "\n",
            "Thank you for the opportunity to demonstrate these capabilities. Goodbye!\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It has been a pleasure working on this project. The successful completion of the thesis \"Alternative Economic and Policy Measures for Japan\\'s Lost Decades\" demonstrates the strength of the **MemoryBanditWorkflow** in handling structured, academic-grade content generation.\\n\\n### Current Status\\n- **Thesis Title:** Alternative Economic and Policy Measures for Japan\\'s Lost Decades\\n- **Chapters:** 7 total (Chapter 0 through Chapter 6), finalized and stored.\\n- **Data Persistence:** Research URLs and policy data are preserved in [memory:1001].\\n\\n### Policy for Future Sessions\\nShould this project be resumed:\\n1.  **Verification:** Run `/thesis/list_chapters` to confirm the presence of all 7 sections.\\n2.  **Expansion:** If additional depth is required (e.g., a chapter on specific regional impacts), use `/thesis/new_chapter`.\\n3.  **Refinement:** Use `/thesis/read_chapter` to extract content for peer-review simulations or further data integration.\\n\\nThank you for the opportunity to demonstrate these capabilities. Goodbye!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}